#!/usr/bin/env python3

# -*- coding: utf-8 -*-

"""

å·¨æ½®ç½‘å¹´æŠ¥ä¸‹è½½å™¨

æ”¯æŒAè‚¡ä¸»æ¿ã€ç§‘åˆ›æ¿ã€åˆ›ä¸šæ¿å’Œæ¸¯è‚¡å¹´æŠ¥ä¸‹è½½

"""



import os

import sys

import re

import json

import time

import requests

import argparse

from pathlib import Path

from typing import List, Dict, Tuple, Optional

from selenium import webdriver

from selenium.webdriver.common.by import By

from selenium.webdriver.support.ui import WebDriverWait

from selenium.webdriver.support import expected_conditions as EC

from selenium.webdriver.chrome.options import Options

from selenium.webdriver.chrome.service import Service

from selenium.common.exceptions import TimeoutException, NoSuchElementException

from webdriver_manager.chrome import ChromeDriverManager

import urllib.parse

from selenium.webdriver.common.keys import Keys





class StockType:

    """è‚¡ç¥¨ç±»å‹æšä¸¾"""

    A_MAIN = "Aè‚¡ä¸»æ¿"

    A_STAR = "Aè‚¡ç§‘åˆ›æ¿" 

    A_GEM = "Aè‚¡åˆ›ä¸šæ¿"

    HK = "æ¸¯è‚¡"

    US = "ç¾è‚¡"

    UNKNOWN = "æœªçŸ¥"





def enhanced_year_matching(title: str, target_years: List[int]) -> Optional[int]:
    """
    å¢å¼ºçš„å¹´ä»½åŒ¹é…å‡½æ•°ï¼Œæ”¯æŒæ•°å­—å’Œä¸­æ–‡å¹´ä»½æ ¼å¼
    
    Args:
        title: æ ‡é¢˜æ–‡æœ¬
        target_years: ç›®æ ‡å¹´ä»½åˆ—è¡¨
        
    Returns:
        åŒ¹é…åˆ°çš„å¹´ä»½ï¼Œå¦‚æœæœªåŒ¹é…è¿”å›None
    """
    # å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯åº”è¯¥æ’é™¤çš„æŠ¥å‘Šç±»å‹
    if ('åŠå¹´' in title or 'åŠå¹´åº¦' in title or 'ä¸­æœŸ' in title or 
        'å­£åº¦' in title or 'å­£æŠ¥' in title):
        return None
    
    # ä¸­æ–‡æ•°å­—æ˜ å°„ï¼ˆåŒ…å«å¤§å†™å’Œå°å†™ï¼‰
    chinese_digits = {
        '0': ['ã€‡', 'é›¶', 'O', 'o'],
        '1': ['ä¸€', 'å£¹'],
        '2': ['äºŒ', 'è´°', 'è²³'], 
        '3': ['ä¸‰', 'å', 'åƒ'],
        '4': ['å››', 'è‚†'],
        '5': ['äº”', 'ä¼'],
        '6': ['å…­', 'é™†', 'é™¸'],
        '7': ['ä¸ƒ', 'æŸ’'],
        '8': ['å…«', 'æŒ'],
        '9': ['ä¹', 'ç–']
    }
    
    for year in target_years:
        year_str = str(year)
        
        # æ£€æŸ¥æ•°å­—æ ¼å¼
        if year_str in title:
            return year
        
        # æ£€æŸ¥ä¸­æ–‡æ ¼å¼ - ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ä¸­æ–‡å¹´ä»½ç»„åˆ
        def generate_chinese_patterns(digits, pos=0, current=""):
            if pos == len(digits):
                if current in title:
                    return True
                return False
            
            digit = digits[pos]
            for chinese_char in chinese_digits[digit]:
                if generate_chinese_patterns(digits, pos + 1, current + chinese_char):
                    return True
            return False
        
        if generate_chinese_patterns(year_str):
            return year
    
    return None


def enhanced_year_matching_with_date(title: str, target_years: List[int], pub_date: str = None) -> Optional[int]:
    """
    å¸¦æ—¥æœŸè¾…åŠ©çš„å¢å¼ºå¹´ä»½åŒ¹é…å‡½æ•°
    
    Args:
        title: æ ‡é¢˜æ–‡æœ¬
        target_years: ç›®æ ‡å¹´ä»½åˆ—è¡¨
        pub_date: å‘å¸ƒæ—¥æœŸ (æ ¼å¼å¦‚ "2025-04-23")
        
    Returns:
        åŒ¹é…åˆ°çš„å¹´ä»½ï¼Œå¦‚æœæœªåŒ¹é…è¿”å›None
    """
    # å…ˆå°è¯•ä»æ ‡é¢˜ä¸­åŒ¹é…å¹´ä»½
    matched_year = enhanced_year_matching(title, target_years)
    if matched_year:
        return matched_year
    
    # å¦‚æœæ ‡é¢˜ä¸­æ²¡æœ‰å¹´ä»½ï¼Œä½†æ ‡é¢˜ç¡®å®æ˜¯å¹´æŠ¥ï¼Œå°è¯•ä»å‘å¸ƒæ—¥æœŸæ¨æ–­
    if pub_date and ('å¹´æŠ¥' in title or 'å¹´åº¦æŠ¥å‘Š' in title):
        try:
            # å¤„ç†å‘å¸ƒæ—¥æœŸï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æ•´æ•°æ—¶é—´æˆ³ï¼‰
            if isinstance(pub_date, str) and '-' in pub_date:
                # å­—ç¬¦ä¸²æ ¼å¼ï¼šYYYY-MM-DD
                pub_year = int(pub_date.split('-')[0])
            elif isinstance(pub_date, (int, float)):
                # æ—¶é—´æˆ³æ ¼å¼ï¼Œè½¬æ¢ä¸ºå¹´ä»½
                import datetime
                pub_year = datetime.datetime.fromtimestamp(pub_date / 1000).year
            else:
                # å…¶ä»–æ ¼å¼ï¼Œæ— æ³•å¤„ç†
                return None
            
            # å¹´æŠ¥é€šå¸¸åœ¨æ¬¡å¹´å‘å¸ƒï¼Œæ‰€ä»¥å¹´æŠ¥å¹´ä»½ = å‘å¸ƒå¹´ä»½ - 1
            report_year = pub_year - 1
            
            # æ£€æŸ¥æ¨æ–­çš„å¹´ä»½æ˜¯å¦åœ¨ç›®æ ‡å¹´ä»½ä¸­
            if report_year in target_years:
                print(f"    ğŸ’¡ é€šè¿‡æ—¥æœŸæ¨æ–­å¹´ä»½: {pub_date} -> {report_year}å¹´å¹´æŠ¥")
                return report_year
                
        except (ValueError, IndexError, TypeError):
            pass
    
    return None


class AnnualReportDownloader:

    """å¹´æŠ¥ä¸‹è½½å™¨ä¸»ç±»"""

    

    def __init__(self, download_dir: str = "annual_reports", headless: bool = True):

        """

        åˆå§‹åŒ–ä¸‹è½½å™¨

        

        Args:

            download_dir: ä¸‹è½½ç›®å½•
            headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼

        """

        self.download_dir = Path(download_dir)

        self.download_dir.mkdir(exist_ok=True)
        self.headless = headless

        

        # ç»Ÿè®¡ä¿¡æ¯

        self.stats = {

            "total": 0,

            "success": 0,

            "failed": 0,

            "details": []

        }

        

        # åˆå§‹åŒ–selenium driverï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰

        self.driver = None

        

    def __enter__(self):

        return self

    

    def __del__(self):

        if self.driver:

            try:

                self.driver.quit()

            except:

                pass

    

    def __exit__(self, exc_type, exc_val, exc_tb):

        if self.driver:

            try:

                self.driver.quit()

            except:

                pass

    

    def init_selenium_driver(self):

        """åˆå§‹åŒ–Selenium WebDriver"""

        if self.driver is None:

            # Chromeé€‰é¡¹é…ç½®

            chrome_options = Options()
            
            # æ ¹æ®è®¾ç½®å†³å®šæ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼
            if self.headless:
                chrome_options.add_argument('--headless')  # æ— å¤´æ¨¡å¼

            chrome_options.add_argument('--no-sandbox')

            chrome_options.add_argument('--disable-dev-shm-usage')

            chrome_options.add_argument('--disable-gpu')  # ç¦ç”¨GPUåŠ é€Ÿ

            chrome_options.add_argument('--disable-web-security')  # ç¦ç”¨webå®‰å…¨

            chrome_options.add_argument('--disable-features=VizDisplayCompositor')  # ç¦ç”¨æ˜¾ç¤ºåˆæˆ

            chrome_options.add_argument('--disable-extensions')  # ç¦ç”¨æ‰©å±•

            chrome_options.add_argument('--disable-plugins')  # ç¦ç”¨æ’ä»¶

            chrome_options.add_argument('--disable-images')  # ç¦ç”¨å›¾ç‰‡åŠ è½½
            # è§£å†³WebGLè­¦å‘Š
            chrome_options.add_argument('--disable-webgl')
            chrome_options.add_argument('--disable-webgl2')
            chrome_options.add_argument('--disable-3d-apis')
            chrome_options.add_argument('--disable-accelerated-2d-canvas')
            chrome_options.add_argument('--disable-accelerated-jpeg-decoding')
            chrome_options.add_argument('--disable-accelerated-mjpeg-decode')
            chrome_options.add_argument('--disable-accelerated-video-decode')
            chrome_options.add_argument('--disable-gpu-sandbox')
            chrome_options.add_argument('--disable-software-rasterizer')
            chrome_options.add_argument('--disable-background-timer-throttling')
            chrome_options.add_argument('--disable-renderer-backgrounding')
            chrome_options.add_argument('--disable-features=TranslateUI')
            chrome_options.add_argument('--disable-ipc-flooding-protection')

            chrome_options.add_argument('--log-level=3')  # åªæ˜¾ç¤ºè‡´å‘½é”™è¯¯

            chrome_options.add_argument('--silent')  # é™é»˜æ¨¡å¼

            chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])  # æ’é™¤æ—¥å¿—å¼€å…³

            chrome_options.add_experimental_option('useAutomationExtension', False)  # ç¦ç”¨è‡ªåŠ¨åŒ–æ‰©å±•

            chrome_options.add_argument('--disable-blink-features=AutomationControlled')  # ç¦ç”¨è‡ªåŠ¨åŒ–æ§åˆ¶ç‰¹å¾

            

            # è®¾ç½®ä¸‹è½½è·¯å¾„å’Œæµè§ˆå™¨ä¸‹è½½é…ç½®

            prefs = {

                "download.default_directory": str(self.download_dir.absolute()),

                "download.prompt_for_download": False,

                "download.directory_upgrade": True,

                "safebrowsing.enabled": True,

                "profile.default_content_settings.popups": 0,

                "profile.default_content_setting_values.automatic_downloads": 1,

                # å…è®¸ä¸‹è½½å¤šä¸ªæ–‡ä»¶

                "profile.default_content_setting_values.notifications": 2,

                # PDFå¤„ç†è®¾ç½®

                "plugins.always_open_pdf_externally": True,

            }

            chrome_options.add_experimental_option("prefs", prefs)

            

            # å°è¯•å¤šç§æ–¹å¼åˆå§‹åŒ–ChromeDriver

            try:

                # æ–¹æ³•1: ä½¿ç”¨å½“å‰ç›®å½•æˆ–ä¸Šçº§ç›®å½•ä¸‹çš„ChromeDriver

                local_chromedriver_paths = [

                    Path("./chromedriver.exe"),          # å½“å‰ç›®å½•

                    Path("../chromedriver.exe"),         # ä¸Šçº§ç›®å½•

                ]

                

                local_chromedriver = None

                for path in local_chromedriver_paths:

                    if path.exists():

                        local_chromedriver = path

                        break

                

                if local_chromedriver:

                    print(f"  ğŸ”§ ä½¿ç”¨ChromeDriver: {local_chromedriver}")

                    service = Service(str(local_chromedriver.absolute()))

                    self.driver = webdriver.Chrome(service=service, options=chrome_options)

                    print("ğŸ”§ Selenium WebDriver åˆå§‹åŒ–æˆåŠŸ(æœ¬åœ°æ–‡ä»¶)")

                else:

                    raise Exception("æœ¬åœ°ChromeDriverä¸å­˜åœ¨")

                

            except Exception as e1:

                print(f"  æœ¬åœ°ChromeDriverå¤±è´¥: {e1}")

                try:

                    # æ–¹æ³•2: ä½¿ç”¨webdriver-managerè‡ªåŠ¨ç®¡ç†ChromeDriver

                    print("  ğŸ”§ å°è¯•è‡ªåŠ¨ä¸‹è½½/æ›´æ–°ChromeDriver...")

                    service = Service(ChromeDriverManager().install())

                    self.driver = webdriver.Chrome(service=service, options=chrome_options)

                    print("ğŸ”§ Selenium WebDriver åˆå§‹åŒ–æˆåŠŸ(è‡ªåŠ¨ç®¡ç†)")

                    

                except Exception as e2:

                    print(f"  è‡ªåŠ¨ç®¡ç†ChromeDriverå¤±è´¥: {e2}")

                    try:

                        # æ–¹æ³•3: ä½¿ç”¨ç³»ç»ŸPATHä¸­çš„ChromeDriver

                        print("  ğŸ”§ å°è¯•ä½¿ç”¨ç³»ç»ŸPATHä¸­çš„ChromeDriver...")

                        self.driver = webdriver.Chrome(options=chrome_options)

                        print("ğŸ”§ Selenium WebDriver åˆå§‹åŒ–æˆåŠŸ(ç³»ç»ŸPATH)")

                        

                    except Exception as e3:

                        print(f"æ‰€æœ‰ChromeDriveråˆå§‹åŒ–æ–¹å¼éƒ½å¤±è´¥:")

                        print(f"  æœ¬åœ°æ–‡ä»¶: {e1}")

                        print(f"  è‡ªåŠ¨ç®¡ç†: {e2}")

                        print(f"  ç³»ç»ŸPATH: {e3}")

                        print("\nè§£å†³æ–¹æ¡ˆ:")

                        print("1. ç¡®ä¿å·²å®‰è£…Chromeæµè§ˆå™¨")

                        print("2. ç¡®ä¿chromedriver.exeåœ¨å½“å‰ç›®å½•æˆ–ç³»ç»ŸPATH")

                        print("3. æ£€æŸ¥ChromeDriverç‰ˆæœ¬æ˜¯å¦ä¸Chromeç‰ˆæœ¬åŒ¹é…")

                        print("ChromeDriverä¸‹è½½åœ°å€: https://chromedriver.chromium.org/")

                        return False

        return True

    def wait_for_download_complete(self, timeout=60):
        """ç­‰å¾…ä¸‹è½½å®Œæˆ"""
        print("    â³ ç­‰å¾…ä¸‹è½½å®Œæˆ...")
        
        start_time = time.time()
        last_file_size = 0
        stable_count = 0
        
        while time.time() - start_time < timeout:
            # æ£€æŸ¥ä¸‹è½½ç›®å½•ä¸­æ˜¯å¦æœ‰.crdownloadæ–‡ä»¶ï¼ˆChromeä¸‹è½½ä¸­çš„ä¸´æ—¶æ–‡ä»¶ï¼‰
            temp_files = list(self.download_dir.glob("*.crdownload"))
            if temp_files:
                # è¿˜æœ‰ä¸´æ—¶æ–‡ä»¶ï¼Œç»§ç»­ç­‰å¾…
                time.sleep(1)
                continue
            
            # æ²¡æœ‰ä¸´æ—¶æ–‡ä»¶ï¼Œæ£€æŸ¥æœ€æ–°æ–‡ä»¶æ˜¯å¦ç¨³å®š
            try:
                all_files = [f for f in self.download_dir.iterdir() if f.is_file()]
                if all_files:
                    latest_file = max(all_files, key=lambda f: f.stat().st_mtime)
                    current_size = latest_file.stat().st_size
                    
                    # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦ç¨³å®šï¼ˆè¿ç»­3æ¬¡æ£€æŸ¥å¤§å°ä¸å˜ï¼‰
                    if current_size == last_file_size and current_size > 0:
                        stable_count += 1
                        if stable_count >= 3:
                            print("    âœ… ä¸‹è½½å®Œæˆï¼ˆæ–‡ä»¶å¤§å°ç¨³å®šï¼‰")
                            return True
                    else:
                        stable_count = 0
                        last_file_size = current_size
                else:
                    stable_count = 0
            except Exception as e:
                print(f"    âš ï¸ æ£€æŸ¥æ–‡ä»¶çŠ¶æ€æ—¶å‡ºé”™: {e}")
                stable_count = 0
            
            time.sleep(1)
        
        print("    âš ï¸ ä¸‹è½½è¶…æ—¶")
        return False

    def browser_download_file(self, url: str, expected_filename: str = None) -> bool:
        """
        é€šè¿‡æµè§ˆå™¨ä¸‹è½½æ–‡ä»¶
        
        Args:
            url: ä¸‹è½½URL
            expected_filename: æœŸæœ›çš„æ–‡ä»¶åï¼ˆç”¨äºéªŒè¯ï¼‰
            
        Returns:
            æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        try:
            if not self.driver:
                self.init_selenium_driver()
            
            print(f"    ğŸŒ æµè§ˆå™¨ä¸‹è½½: {url}")
            
            # è®°å½•ä¸‹è½½å‰çš„æ–‡ä»¶åˆ—è¡¨
            files_before = set(f.name for f in self.download_dir.iterdir() if f.is_file())
            
            # å¯¼èˆªåˆ°ä¸‹è½½URL
            self.driver.get(url)
            
            # ç­‰å¾…ä¸‹è½½å®Œæˆ
            if self.wait_for_download_complete():
                # æ£€æŸ¥æ–°ä¸‹è½½çš„æ–‡ä»¶
                files_after = set(f.name for f in self.download_dir.iterdir() if f.is_file())
                new_files = files_after - files_before
                
                if new_files:
                    downloaded_file = list(new_files)[0]
                    print(f"    âœ… ä¸‹è½½æˆåŠŸ: {downloaded_file}")
                    
                    # ğŸ”§ ä¿®å¤ï¼šå†æ¬¡ç¡®è®¤æ–‡ä»¶ä¸æ˜¯.crdownloadæ–‡ä»¶
                    if downloaded_file.endswith('.crdownload'):
                        print(f"    âŒ é”™è¯¯ï¼šæ–‡ä»¶ä»ä¸ºä¸´æ—¶çŠ¶æ€: {downloaded_file}")
                        return False
                    
                    return True
                else:
                    print("    âŒ æœªæ£€æµ‹åˆ°æ–°æ–‡ä»¶")
                    return False
            else:
                return False
                
        except Exception as e:
            print(f"    âŒ æµè§ˆå™¨ä¸‹è½½å¤±è´¥: {e}")
            return False

    

    def identify_stock_type(self, stock_code: str) -> str:
        """
        è¯†åˆ«è‚¡ç¥¨ç±»å‹
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            è‚¡ç¥¨ç±»å‹
        """
        stock_code = stock_code.strip().upper()
        
        # æ¸¯è‚¡ï¼š5ä½æ•°å­—æˆ–å¸¦HKå‰ç¼€
        if re.match(r'^\d{5}$', stock_code) or stock_code.startswith('HK'):
            return StockType.HK
        
        # Aè‚¡ï¼š6ä½æ•°
        if re.match(r'^\d{6}$', stock_code):
            # ç§‘åˆ›æ¿ï¼š688å¼€å¤´
            if stock_code.startswith('688'):
                return StockType.A_STAR
            # åˆ›ä¸šæ¿ï¼š300å¼€å¤´ 
            elif stock_code.startswith('300'):
                return StockType.A_GEM
            # ä¸»æ¿ï¼šå…¶ä»–6ä½æ•°
            else:
                return StockType.A_MAIN
        
        # ç¾è‚¡ï¼šå­—æ¯å¼€å¤´çš„è‚¡ç¥¨ä»£ç ï¼ˆ1-5ä¸ªå­—ç¬¦ï¼‰
        if re.match(r'^[A-Z]{1,5}$', stock_code):
            return StockType.US
        
        return StockType.UNKNOWN

    

    def get_orgid_dict_szse(self) -> Dict[str, str]:

        """

        è·å–æ·±åœ³äº¤æ˜“æ‰€æ‰€æœ‰è‚¡ç¥¨çš„orgIdå­—å…¸

        

        Returns:

            è‚¡ç¥¨ä»£ç åˆ°orgIdçš„æ˜ å°„å­—å…¸

        """

        try:

            print("    ğŸ”„ æ­£åœ¨è·å–æ·±åœ³äº¤æ˜“æ‰€è‚¡ç¥¨orgIdæ˜ å°„è¡¨..")

            response = requests.get("http://www.cninfo.com.cn/new/data/szse_stock.json", timeout=15)

            response.raise_for_status()

            

            org_dict = {}

            stock_list = response.json().get("stockList", [])

            

            for stock_info in stock_list:

                code = stock_info.get("code")

                org_id = stock_info.get("orgId")

                if code and org_id:

                    org_dict[code] = org_id

            

            print(f"    ğŸ”„ è·å–äº†{len(org_dict)} ä¸ªæ·±åœ³äº¤æ˜“æ‰€è‚¡ç¥¨çš„orgId")

            return org_dict

            

        except Exception as e:

            print(f"    âœ— è·å–æ·±åœ³äº¤æ˜“æ‰€orgIdæ˜ å°„è¡¨å¤±è´¥: {e}")

            return {}

    

    def get_orgid_dict_sse(self) -> Dict[str, str]:

        """

        è·å–ä¸Šæµ·äº¤æ˜“æ‰€æ‰€æœ‰è‚¡ç¥¨çš„orgIdå­—å…¸

        

        Returns:

            è‚¡ç¥¨ä»£ç åˆ°orgIdçš„æ˜ å°„å­—å…¸

        """

        try:

            print("    ğŸ”„ æ­£åœ¨è·å–ä¸Šæµ·äº¤æ˜“æ‰€è‚¡ç¥¨orgIdæ˜ å°„è¡¨..")

            response = requests.get("http://www.cninfo.com.cn/new/data/sse_stock.json", timeout=15)

            response.raise_for_status()

            

            org_dict = {}

            stock_list = response.json().get("stockList", [])

            

            for stock_info in stock_list:

                code = stock_info.get("code")

                org_id = stock_info.get("orgId")

                if code and org_id:

                    org_dict[code] = org_id

            

            print(f"    ğŸ”„ è·å–äº†{len(org_dict)} ä¸ªä¸Šæµ·äº¤æ˜“æ‰€è‚¡ç¥¨çš„orgId")

            return org_dict

            

        except Exception as e:

            print(f"    âœ— è·å–ä¸Šæµ·äº¤æ˜“æ‰€orgIdæ˜ å°„è¡¨å¤±è´¥: {e}")

            return {}

    

    def get_all_orgid_dict(self) -> Dict[str, str]:

        """

        è·å–æ‰€æœ‰äº¤æ˜“æ‰€è‚¡ç¥¨çš„orgIdå­—å…¸

        æ³¨æ„ï¼šæ·±åœ³äº¤æ˜“æ‰€çš„æ•°æ®å®é™…åŒ…å«äº†æ‰€æœ‰è‚¡ç¥¨ï¼ˆåŒ…æ‹¬ä¸Šæµ·äº¤æ˜“æ‰€ï¼‰

        

        Returns:

            è‚¡ç¥¨ä»£ç åˆ°orgIdçš„æ˜ å°„å­—å…¸

        """

        # æ·±åœ³äº¤æ˜“æ‰€çš„æ•°æ®åŒ…å«äº†æ‰€æœ‰è‚¡ç¥¨

        all_dict = self.get_orgid_dict_szse()

        

        print(f"    ğŸ“Š æ€»è®¡è·å–äº†{len(all_dict)} ä¸ªè‚¡ç¥¨çš„orgId")

        return all_dict

    

    def get_orgid_for_stock(self, stock_code: str) -> Optional[str]:

        """

        è·å–è‚¡ç¥¨çš„orgId

        

        Args:

            stock_code: è‚¡ç¥¨ä»£ç 

            

        Returns:

            orgIdå­—ç¬¦ä¸²ï¼Œå¦‚æœè·å–å¤±è´¥è¿”å›None

        """

        try:

            # é¦–å…ˆå°è¯•ä»æ˜ å°„è¡¨è·å–orgId

            all_orgid_dict = self.get_all_orgid_dict()

            if stock_code in all_orgid_dict:

                org_id = all_orgid_dict[stock_code]

                print(f"    ğŸ”„ ä»æ˜ å°„è¡¨è·å–äº†{stock_code} çš„orgId: {org_id}")

                return org_id

            

            # å¦‚æœæ˜ å°„è¡¨ä¸­æ²¡æœ‰ï¼Œå°è¯•é€šè¿‡æœç´¢APIè·å–

            print(f"    ğŸ” æ˜ å°„è¡¨ä¸­æœªæ‰¾åˆ°{stock_code}ï¼Œå°è¯•æœç´¢è·å–orgId...")

            

            # ä½¿ç”¨è‚¡ç¥¨ä»£ç æœç´¢ï¼ˆé€šè¿‡searchkeyï¼‰

            api_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"

            headers = {

                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'

            }

            

            params = {

                "stock": "",

                "tabName": "fulltext",

                "pageSize": 50,

                "pageNum": 1,

                "column": "",

                "category": "",

                "plate": "",

                "seDate": "2020-01-01~2025-12-31",

                "searchkey": stock_code,

                "secid": "",

                "sortName": "pubdate",

                "sortType": "desc",

                "isHLtitle": "true"

            }

            

            response = requests.post(api_url, headers=headers, data=params, timeout=15)

            if response.status_code == 200:

                result = response.json()

                announcements = result.get('announcements', [])

                

                if announcements:

                    # æŸ¥æ‰¾åŒ¹é…çš„è‚¡ç¥¨ä»£ç 

                    for ann in announcements:

                        sec_code = ann.get('secCode', '')

                        org_id = ann.get('orgId', '')

                        

                        if sec_code == stock_code and org_id:

                            print(f"    ğŸ”„ é€šè¿‡æœç´¢è·å–äº†{stock_code} çš„orgId: {org_id}")

                            return org_id

            

            print(f"    âœ— æ— æ³•è·å–{stock_code} çš„orgId")

            return None

            

        except Exception as e:

            print(f"    âœ— è·å– {stock_code} orgId æ—¶å‡ºé”™: {e}")

            return None

    

    def download_a_stock_main_reports_with_pagination(self, stock_code: str, years: List[int]) -> List[Dict]:
        """
        ä¸‹è½½Aè‚¡ä¸»æ¿å¹´æŠ¥ï¼ˆä½¿ç”¨API + ç¿»é¡µæ”¯æŒï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            years: å¹´ä»½åˆ—è¡¨
            
        Returns:
            ä¸‹è½½ç»“æœåˆ—è¡¨
        """
        results = []
        
        try:
            print(f"  ğŸ“¥ ä½¿ç”¨å·¨æ½®APIæŸ¥æ‰¾ {stock_code} å¹´æŠ¥ï¼ˆæ”¯æŒç¿»é¡µï¼‰...")
            
            api_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            # ç¡®å®šæ¿å—å’ŒorgId
            if stock_code.startswith('60') or stock_code.startswith('688'):
                plate = 'sse'  # ä¸Šæµ·äº¤æ˜“æ‰€ï¼šä¸»æ¿(60xxxx) + ç§‘åˆ›æ¿(688xxx)
            else:
                plate = 'szse'  # æ·±åœ³äº¤æ˜“æ‰€ï¼šä¸»æ¿(000xxx) + åˆ›ä¸šæ¿(300xxx)
            category = 'category_ndbg_szsh;'
            
            # ä»æ˜ å°„è¡¨è·å–çœŸå®çš„orgId
            real_org_id = self.get_orgid_for_stock(stock_code)
            if not real_org_id:
                print(f"  âœ— æ— æ³•è·å–{stock_code} çš„orgId")
                for year in years:
                    results.append({
                        'stock_code': stock_code,
                        'year': year,
                        'status': 'no_orgid',
                        'error': 'æ— æ³•è·å–orgId'
                    })
                return results
            
            # è®¾ç½®æœç´¢æ—¥æœŸèŒƒå›´ï¼ˆå¹´æŠ¥é€šå¸¸åœ¨æ¬¡å¹´-4æœˆå‘å¸ƒï¼‰
            min_year = min(years)
            max_year = max(years)
            search_start_date = f"{min_year}-01-01"
            search_end_date = f"{max_year + 1}-04-30"
            
            params = {
                "stock": f"{stock_code},{real_org_id}",
                "tabName": "fulltext",
                "pageSize": 50,
                "pageNum": 1,
                "column": plate,
                "category": category,
                "plate": plate,
                "seDate": f"{search_start_date}~{search_end_date}",
                "searchkey": "",
                "secid": "",
                "sortName": "pubdate",
                "sortType": "desc",
                "isHLtitle": "true"
            }
            
            # æ”¯æŒç¿»é¡µæœç´¢ï¼Œæœ€å¤šæœç´¢å‰3é¡µ
            all_announcements = []
            for page_num in range(1, 4):
                params["pageNum"] = page_num
                print(f"    ğŸ” æœç´¢ç¬¬{page_num}é¡µ...")
                
                response = requests.post(api_url, headers=headers, data=params, timeout=20)
                response.raise_for_status()
                data = response.json()
                
                announcements = data.get('announcements', [])
                if announcements:
                    all_announcements.extend(announcements)
                    print(f"    ç¬¬{page_num}é¡µæ‰¾åˆ°{len(announcements)}æ¡å…¬å‘Š")
                else:
                    print(f"    ç¬¬{page_num}é¡µæ— ç»“æœï¼Œåœæ­¢ç¿»é¡µ")
                    break
            
            if not all_announcements:
                print(f"  âœ— æœªæ‰¾åˆ°{stock_code} çš„ç›¸å…³æŠ¥å‘Š")
                for year in years:
                    results.append({
                        'stock_code': stock_code,
                        'year': year,
                        'status': 'not_found',
                        'error': 'æœªæ‰¾åˆ°ç›¸å…³æŠ¥å‘Š'
                    })
                return results
            
            print(f"  ğŸ“Š æ€»å…±æ‰¾åˆ°{len(all_announcements)}æ¡å…¬å‘Š")
            
            # æŒ‰å¹´ä»½æŸ¥æ‰¾å¹´æŠ¥
            for year in years:
                print(f"    ğŸ” æŸ¥æ‰¾ {year} å¹´å¹´æŠ¥..")
                found = False
                
                for ann in all_announcements:
                    title = ann.get('announcementTitle', '')
                    
                    # è·³è¿‡æ‘˜è¦ã€è¡¥å……ã€æ›´æ­£ç­‰éæ­£å¼å¹´æŠ¥
                    if any(keyword in title for keyword in ["æ‘˜è¦", "å–æ¶ˆ", "è¡¥å……", "æ›´æ­£", "ç¬¬ä¸€å­£åº¦", "åŠå¹´", "ç¬¬ä¸‰å­£åº¦"]):
                        continue
                    
                    # ä½¿ç”¨å¢å¼ºçš„å¹´ä»½åŒ¹é…æ£€æŸ¥æ˜¯å¦ä¸ºæŒ‡å®šå¹´ä»½çš„å¹´åº¦æŠ¥å‘Š
                    matched_year = enhanced_year_matching(title, [year])
                    if matched_year and "å¹´åº¦æŠ¥å‘Š" in title:
                        print(f"    ğŸ”„ æ‰¾åˆ°å¹´æŠ¥: {title}")
                        
                        # ä¸‹è½½PDF
                        adj_url = ann.get('adjunctUrl', '')
                        if adj_url:
                            pdf_url = f"http://static.cninfo.com.cn/{adj_url}"
                            stock_name = ann.get('secName', stock_code)
                            filename = f"{stock_code}_{stock_name}_{year}å¹´æŠ¥.pdf"
                            
                            filepath = self.download_dir / filename
                            if self.download_pdf(pdf_url, str(filepath)):
                                print(f"    âœ“ æˆåŠŸä¸‹è½½: {filename}")
                                results.append({
                                    'stock_code': stock_code,
                                    'year': year,
                                    'status': 'success',
                                    'filename': filename,
                                    'title': title
                                })
                                found = True
                                break
                            else:
                                results.append({
                                    'stock_code': stock_code,
                                    'year': year,
                                    'status': 'download_failed',
                                    'error': 'ä¸‹è½½PDFå¤±è´¥'
                                })
                                found = True
                                break
                
                if not found:
                    print(f"    âœ— æœªæ‰¾åˆ°{stock_code} {year}å¹´å¹´æŠ¥")
                    results.append({
                        'stock_code': stock_code,
                        'year': year,
                        'status': 'not_found',
                        'error': 'æœªæ‰¾åˆ°å¹´æŠ¥'
                    })
                
                time.sleep(0.5)  # çŸ­æš‚é—´éš”
                
        except Exception as e:
            print(f"  âœ— Aè‚¡ä¸»æ¿APIå¤„ç†å¤±è´¥: {e}")
            for year in years:
                results.append({
                    'stock_code': stock_code,
                    'year': year,
                    'status': 'error',
                    'error': str(e)
                })
        
        return results

    def download_a_stock_main_reports(self, stock_code: str, years: List[int]) -> List[Dict]:

        """

        ä¸‹è½½Aè‚¡ä¸»æ¿å¹´æŠ¥ï¼ˆä½¿ç”¨APIï¼‰

        

        Args:

            stock_code: è‚¡ç¥¨ä»£ç 

            years: å¹´ä»½åˆ—è¡¨

            

        Returns:

            ä¸‹è½½ç»“æœåˆ—è¡¨

        """

        results = []

        

        try:

            print(f"  ğŸ“¥ ä½¿ç”¨å·¨æ½®APIæŸ¥æ‰¾ {stock_code} å¹´æŠ¥...")

            

            api_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"

            headers = {

                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'

            }

            

            # ç¡®å®šæ¿å—å’ŒorgId

            if stock_code.startswith('60') or stock_code.startswith('688'):

                plate = 'sse'  # ä¸Šæµ·äº¤æ˜“æ‰€ï¼šä¸»æ¿(60xxxx) + ç§‘åˆ›æ¿(688xxx)

            else:

                plate = 'szse'  # æ·±åœ³äº¤æ˜“æ‰€ï¼šä¸»æ¿(000xxx) + åˆ›ä¸šæ¿(300xxx)

            category = 'category_ndbg_szsh;'

            

            # ä»æ˜ å°„è¡¨è·å–çœŸå®çš„orgId

            real_org_id = self.get_orgid_for_stock(stock_code)

            if not real_org_id:

                print(f"  âœ— æ— æ³•è·å–{stock_code} çš„orgId")

                for year in years:

                    results.append({

                        'stock_code': stock_code,

                        'year': year,

                        'status': 'no_orgid',

                        'error': 'æ— æ³•è·å–orgId'

                    })

                return results

            

            # è®¾ç½®æœç´¢æ—¥æœŸèŒƒå›´ï¼ˆå¹´æŠ¥é€šå¸¸åœ¨æ¬¡å¹´-4æœˆå‘å¸ƒï¼‰

            min_year = min(years)

            max_year = max(years)

            search_start_date = f"{min_year}-01-01"

            search_end_date = f"{max_year + 1}-04-30"

            

            params = {

                "stock": f"{stock_code},{real_org_id}",

                "tabName": "fulltext",

                "pageSize": 50,

                "pageNum": 1,

                "column": plate,

                "category": category,

                "plate": plate,

                "seDate": f"{search_start_date}~{search_end_date}",

                "searchkey": "",

                "secid": "",

                "sortName": "pubdate",

                "sortType": "desc",

                "isHLtitle": "true"

            }

            

            response = requests.post(api_url, headers=headers, data=params, timeout=20)

            response.raise_for_status()

            data = response.json()

            

            if not data.get('announcements'):

                print(f"  âœ— æœªæ‰¾åˆ°{stock_code} çš„ç›¸å…³æŠ¥å‘Š")

                for year in years:

                    results.append({

                        'stock_code': stock_code,

                        'year': year,

                        'status': 'not_found',

                        'error': 'æœªæ‰¾åˆ°ç›¸å…³æŠ¥å‘Š'

                    })

                return results

            

            # æŒ‰å¹´ä»½æŸ¥æ‰¾å¹´æŠ¥

            for year in years:

                print(f"    ğŸ” æŸ¥æ‰¾ {year} å¹´å¹´æŠ¥..")

                found = False

                

                for ann in data['announcements']:

                    title = ann.get('announcementTitle', '')

                    

                    # è·³è¿‡æ‘˜è¦ã€è¡¥å……ã€æ›´æ­£ç­‰éæ­£å¼å¹´æŠ¥

                    if any(keyword in title for keyword in ["æ‘˜è¦", "å–æ¶ˆ", "è¡¥å……", "æ›´æ­£", "ç¬¬ä¸€å­£åº¦", "åŠå¹´", "ç¬¬ä¸‰å­£åº¦"]):

                        continue

                    

                    # ä½¿ç”¨å¢å¼ºçš„å¹´ä»½åŒ¹é…æ£€æŸ¥æ˜¯å¦ä¸ºæŒ‡å®šå¹´ä»½çš„å¹´åº¦æŠ¥å‘Š

                    matched_year = enhanced_year_matching(title, [year])

                    if matched_year and "å¹´åº¦æŠ¥å‘Š" in title:

                        print(f"    ğŸ”„ æ‰¾åˆ°å¹´æŠ¥: {title}")

                        

                        # ä¸‹è½½PDF

                        adj_url = ann.get('adjunctUrl', '')

                        if adj_url:

                            pdf_url = f"http://static.cninfo.com.cn/{adj_url}"

                            stock_name = ann.get('secName', stock_code)

                            filename = f"{stock_code}_{stock_name}_{year}å¹´æŠ¥.pdf"

                            

                            filepath = self.download_dir / filename
                            if self.download_pdf(pdf_url, str(filepath)):

                                print(f"    âœ“ æˆåŠŸä¸‹è½½: {filename}")

                                results.append({

                                    'stock_code': stock_code,

                                    'year': year,

                                    'status': 'success',

                                    'filename': filename,

                                    'title': title

                                })

                                found = True

                                break

                            else:

                                results.append({

                                    'stock_code': stock_code,

                                    'year': year,

                                    'status': 'download_failed',

                                    'error': 'ä¸‹è½½PDFå¤±è´¥'

                                })

                                found = True

                                break

                

                if not found:

                    print(f"    âœ— æœªæ‰¾åˆ°{stock_code} {year}å¹´å¹´æŠ¥")

                    results.append({

                        'stock_code': stock_code,

                        'year': year,

                        'status': 'not_found',

                        'error': 'æœªæ‰¾åˆ°å¹´æŠ¥'

                    })

                

                time.sleep(0.5)  # çŸ­æš‚é—´éš”

                

        except Exception as e:

            print(f"  âœ— Aè‚¡ä¸»æ¿APIå¤„ç†å¤±è´¥: {e}")

            for year in years:

                results.append({

                    'stock_code': stock_code,

                    'year': year,

                    'status': 'error',

                    'error': str(e)

                })

        

        return results

    

    def download_a_stock_with_selenium(self, stock_code: str, years: List[int], stock_type: str) -> List[Dict]:

        """

        ä½¿ç”¨Seleniumä¸‹è½½Aè‚¡ç§‘åˆ›æ¿/åˆ›ä¸šæ¿å¹´æŠ¥

        

        Args:

            stock_code: è‚¡ç¥¨ä»£ç 

            years: å¹´ä»½åˆ—è¡¨

            stock_type: è‚¡ç¥¨ç±»å‹

            

        Returns:

            ä¸‹è½½ç»“æœåˆ—è¡¨

        """

        results = []

        

        if not self.init_selenium_driver():

            return [{'stock_code': stock_code, 'year': 'all', 'status': 'selenium_init_failed', 'error': 'Seleniumåˆå§‹åŒ–å¤±è´¥'}]

        

        try:

            # è·å–orgId - ä½¿ç”¨å·¨æ½®ç½‘çš„orgIdæ˜ å°„è¡¨

            print(f"  ğŸ” æ­£åœ¨è·å– {stock_code} çš„orgId...")

            

            # é¦–å…ˆå°è¯•ä»å®Œæ•´æ˜ å°„è¡¨è·å–orgId

            print(f"    ğŸ’¡ å°è¯•ä»å·¨æ½®ç½‘æ˜ å°„è¡¨è·å–orgId")

            all_orgid_dict = self.get_all_orgid_dict()

            org_id = all_orgid_dict.get(stock_code)

            

            if org_id:

                print(f"    ä»æ˜ å°„è¡¨è·å–åˆ°orgId: {org_id}")

            else:

                print(f"    âš ï¸ æ˜ å°„è¡¨ä¸­æœªæ‰¾åˆ°{stock_code}")

                # å¦‚æœæ˜ å°„è¡¨ä¸­æ²¡æœ‰ï¼Œå°è¯•è§„å¾‹ç”Ÿæˆï¼ˆä»…ç”¨äºAè‚¡ä¸»æ¿ï¼‰

                if stock_type == StockType.A_MAIN:

                    if stock_code.startswith('60'):

                        org_id = f"gssh0{stock_code}"

                        print(f"    ğŸ’¡ å°è¯•ä¸Šæµ·ä¸»æ¿è§„å¾‹ç”Ÿæˆ: {org_id}")

                    else:

                        org_id = f"gssz0{stock_code}"

                        print(f"    ğŸ’¡ å°è¯•æ·±åœ³ä¸»æ¿è§„å¾‹ç”Ÿæˆ: {org_id}")

                else:

                    # å…¶ä»–æƒ…å†µå°è¯•é€šç”¨API

                    print(f"    ğŸ”„ ä½¿ç”¨é€šç”¨APIè·å–...")

                    org_id = self.get_orgid_for_stock(stock_code)

            

            if not org_id:

                return [{'stock_code': stock_code, 'year': 'all', 'status': 'orgid_failed', 'error': 'æ— æ³•è·å–orgId'}]

                

            print(f"  ğŸ”„ æœ€ç»ˆä½¿ç”¨orgId: {org_id}")

            

            # è®¿é—®è‚¡ç¥¨é¡µé¢

            url = f"https://www.cninfo.com.cn/new/disclosure/stock?stockCode={stock_code}&orgId={org_id}&sjstsBond=false#periodicReports"

            print(f"  ğŸŒ è®¿é—®é¡µé¢: {url}")

            

            self.driver.get(url)

            time.sleep(3)

            

            # ç­‰å¾…é¡µé¢åŠ è½½ï¼ˆå¢åŠ ç­‰å¾…æ—¶é—´å¹¶å°è¯•å¤šç§å…ƒç´ æ£€æµ‹ï¼‰

            try:

                print("  ğŸ”„ ç­‰å¾…é¡µé¢åŠ è½½...")

                # å°è¯•ç­‰å¾…å¤šç§å¯èƒ½çš„é¡µé¢å…ƒç´ 

                WebDriverWait(self.driver, 20).until(

                    lambda driver: driver.execute_script("return document.readyState") == "complete"

                )

                time.sleep(5)  # é¢å¤–ç­‰å¾…é¡µé¢å†…å®¹åŠ è½½

                print("ğŸ”„ é¡µé¢åŠ è½½å®Œæˆ")

            except TimeoutException:

                print(f"ğŸ”„ é¡µé¢åŠ è½½è¶…æ—¶ï¼Œå°è¯•ç»§ç»­...")

                # å³ä½¿è¶…æ—¶ä¹Ÿå°è¯•ç»§ç»­æ“ä½œ

            

            # è®¾ç½®æœç´¢å‚æ•° - æ¯ä¸ªå¹´ä»½å•ç‹¬æœç´¢ï¼Œæé«˜æ•ˆç‡

            for year in years:

                print(f"  ğŸ“¥ æ­£åœ¨æœç´¢ {stock_code} {year}å¹´å¹´æŠ¥..")

                

                try:

                    # é‡æ–°è®¿é—®é¡µé¢ï¼Œç¡®ä¿çŠ¶æ€å¹²å‡€

                    self.driver.get(url)

                    time.sleep(3)

                    

                    # æ¸¯è‚¡é¡µé¢ï¼šä½¿ç”¨ç²¾ç¡®æœç´¢

                    print(f"    ğŸ” ä½¿ç”¨ç²¾ç¡®æœç´¢: {year}å¹´åº¦æŠ¥å‘Š...")

                    

                    # æŸ¥æ‰¾æœç´¢æ¡† - ä¼˜å…ˆæ‰¾æ ‡é¢˜å…³é”®å­—æœç´¢

                    search_selectors = [

                        "input[placeholder*='æ ‡é¢˜å…³é”®å­—']",

                        "input[placeholder*='æœç´¢']", 

                        "input[type='text'][placeholder*='å…³é”®']",

                        ".search input",

                        "[class*='search'] input"

                    ]

                    

                    search_box = None

                    for selector in search_selectors:

                        try:

                            search_box = self.driver.find_element(By.CSS_SELECTOR, selector)

                            if search_box and search_box.is_displayed():

                                print(f"    æ‰¾åˆ°æœç´¢æ¡†: {selector}")

                                break

                        except:

                            continue

                    

                    # è®¾ç½®æ—¥æœŸç­›é€‰å™¨ - å¹´æŠ¥é€šå¸¸åœ¨æ¬¡å¹´å‘å¸ƒ

                    # æš‚æ—¶ç¦ç”¨æ—¥æœŸç­›é€‰å™¨ï¼Œå› ä¸ºç•Œé¢å…ƒç´ å¯èƒ½å‘ç”Ÿå˜åŒ–

                    print(f"    ğŸ—“ğŸ”„ è·³è¿‡æ—¥æœŸç­›é€‰å™¨è®¾ç½®ï¼Œä¾é æœç´¢å…³é”®è¯ç­›é€‰...")

                    

                    # TODO: ä»¥ä¸‹æ—¥æœŸç­›é€‰å™¨ä»£ç æš‚æ—¶æ³¨é‡Šï¼Œç­‰ç¡®è®¤ç•Œé¢å…ƒç´ åå†å¯ç”¨

                    # try:

                    #     # å¹´æŠ¥åœ¨æ¬¡å¹´å‘å¸ƒï¼Œè®¾ç½®æ¬¡å¹´çš„æ—¥æœŸèŒƒå›´

                    #     start_year = year + 1

                    #     end_year = year + 1

                    #     

                    #     start_date_selectors = [

                    #         "input[placeholder*='å¼€å§‹æ—¥æœŸ']",

                    #         "input[placeholder*='èµ·å§‹']", 

                    #         ".date-picker input:first-child",

                    #         ".start-date input"

                    #     ]

                    #     

                    #     end_date_selectors = [

                    #         "input[placeholder*='ç»“æŸæ—¥æœŸ']",

                    #         "input[placeholder*='ç»ˆæ­¢']",

                    #         ".date-picker input:last-child", 

                    #         ".end-date input"

                    #     ]

                    #     

                    #     # è®¾ç½®èµ·å§‹æ—¥æœŸ

                    #     for start_sel in start_date_selectors:

                    #         try:

                    #             start_input = self.driver.find_element(By.CSS_SELECTOR, start_sel)

                    #             if start_input and start_input.is_displayed():

                    #                 start_input.clear()

                    #                 start_date = f"{start_year}-01-01"

                    #                 start_input.send_keys(start_date)

                    #                 print(f"    è®¾ç½®èµ·å§‹æ—¥æœŸ: {start_date}")

                    #                 break

                    #         except:

                    #             continue

                    #     

                    #     # è®¾ç½®ç»“æŸæ—¥æœŸ  

                    #     for end_sel in end_date_selectors:

                    #         try:

                    #             end_input = self.driver.find_element(By.CSS_SELECTOR, end_sel)

                    #             if end_input and end_input.is_displayed():

                    #                 end_input.clear()

                    #                 end_date = f"{end_year}-12-31"

                    #                 end_input.send_keys(end_date)

                    #                 print(f"    è®¾ç½®ç»“æŸæ—¥æœŸ: {end_date}")

                    #                 break

                    #         except:

                    #             continue

                    #             

                    # except Exception as e:

                    #     print(f"    æ—¥æœŸç­›é€‰å™¨è®¾ç½®å¤±è´¥: {e}")

                    

                    if search_box:

                        # æ¸…ç©ºæœç´¢æ¡†å¹¶è¾“å…¥ç²¾ç¡®çš„æœç´¢å…³é”®è¯

                        search_box.clear()

                        # ä½¿ç”¨å¹´ä»½+å¹´åº¦æŠ¥å‘Šçš„ç²¾ç¡®æœç´¢ï¼Œå¤§å¹…å‡å°‘ç»“æœæ•°é‡

                        search_keywords = f"{year}å¹´åº¦æŠ¥å‘Š"

                        search_box.send_keys(search_keywords)

                        print(f"    è¾“å…¥ç²¾ç¡®æœç´¢å…³é”®è¯: {search_keywords}")

                        

                        # ç‚¹å‡»æœç´¢æŒ‰é’®

                        search_btn_selectors = [

                            "button[class*='æŸ¥è¯¢']",

                            "button[class*='search']", 

                            ".search button",

                            "[class*='search'] button",

                            "button[type='submit']",

                            "input[type='submit']"

                        ]

                        

                        search_clicked = False

                        for btn_selector in search_btn_selectors:

                            try:

                                search_btn = self.driver.find_element(By.CSS_SELECTOR, btn_selector)

                                if search_btn and search_btn.is_displayed():

                                    search_btn.click()

                                    print(f"    ç‚¹å‡»æœç´¢æŒ‰é’®: {btn_selector}")

                                    search_clicked = True

                                    break

                            except:

                                continue

                        

                        if not search_clicked:

                            # å¦‚æœæ‰¾ä¸åˆ°æœç´¢æŒ‰é’®ï¼Œå°è¯•æŒ‰å›è½¦é”®

                            search_box.send_keys(Keys.ENTER)

                            print(f"    æŒ‰å›è½¦é”®æœç´¢")

                        

                        time.sleep(5)  # ç­‰å¾…æœç´¢ç»“æœåŠ è½½

                    else:

                        print(f"    âš ï¸ æœªæ‰¾åˆ°æœç´¢æ¡†ï¼Œè·³è¿‡æ­¤å¹´ä»½")

                        results.append({

                            'stock_code': stock_code,

                            'year': year,

                            'status': 'search_failed',

                            'error': 'æœªæ‰¾åˆ°æœç´¢æ¡†'

                        })

                        continue

                    

                    # æŸ¥æ‰¾æœç´¢ç»“æœè¡¨æ ¼ - ç²¾ç¡®æœç´¢ååº”è¯¥ç»“æœå¾ˆå°‘

                    table_selectors = [

                        "table tbody tr",

                        ".disclosure-table tbody tr", 

                        "[class*='table'] tbody tr",

                        "tr"

                    ]

                    

                    rows = []

                    for selector in table_selectors:

                        try:

                            rows = self.driver.find_elements(By.CSS_SELECTOR, selector)

                            if rows:

                                print(f"    ç²¾ç¡®æœç´¢åæ‰¾åˆ°{len(rows)} è¡Œæ•°")

                                break

                        except:

                            continue

                    

                    # ç²¾ç¡®æœç´¢åï¼Œåªéœ€æ£€æŸ¥å‰10è¡Œç»“æœ

                    found_report = False

                    

                    if rows:

                        print(f"    æ£€æŸ¥å‰50è¡Œç²¾ç¡®æœç´¢ç»“æœ...")

                        

                        for i, row in enumerate(rows[:50]):  # æ£€æŸ¥å‰50è¡Œ

                            try:

                                print(f"    æ­£åœ¨è§£æç¬¬{i+1} è¡Œ...")

                                

                                # å…ˆæŸ¥çœ‹è¡¨æ ¼ç»“æœ

                                tds = row.find_elements(By.CSS_SELECTOR, "td")

                                print(f"      ç¬¬{i+1} è¡Œæœ‰ {len(tds)} åˆ—")

                                

                                # å°è¯•è·å–æ‰€æœ‰åˆ—çš„æ–‡æœ¬å†…å®¹

                                row_texts = []

                                for j, td in enumerate(tds):

                                    text = td.text.strip()

                                    if text:

                                        row_texts.append(f"åˆ—{j+1}: {text[:50]}")

                                

                                if row_texts:

                                    print(f"      è¡Œå†…å®¹: {' | '.join(row_texts)}")

                                

                                # ç®€åŒ–é€‰æ‹©å™¨ï¼Œåªä½¿ç”¨æœ€åŸºæœ¬çš„é€‰æ‹©å™¨

                                title = ""

                                date = ""

                                title_element = None

                                

                                # å°è¯•å¤šç§æ–¹å¼è·å–æ ‡é¢˜

                                try:

                                    # æ–¹æ³•1: æŸ¥æ‰¾é“¾æ¥

                                    title_element = row.find_element(By.CSS_SELECTOR, "td a")

                                    title = title_element.text.strip()

                                    print(f"      æ‰¾åˆ°æ ‡é¢˜é“¾æ¥: {title[:40]}...")

                                except:

                                    try:

                                        # æ–¹æ³•2: æŸ¥æ‰¾ä»»ä½•é“¾æ¥

                                        title_element = row.find_element(By.CSS_SELECTOR, "a")

                                        title = title_element.text.strip()

                                        print(f"      æ‰¾åˆ°é“¾æ¥: {title[:40]}...")

                                    except:

                                        try:

                                            # æ–¹æ³•3: å¦‚æœæ²¡æœ‰é“¾æ¥ï¼Œå–ç¬¬äºŒåˆ—çš„æ–‡æœ¬(é€šå¸¸æ˜¯æ ‡é¢˜åˆ—)

                                            if len(tds) >= 2:

                                                title = tds[1].text.strip()

                                                if title:

                                                    print(f"      æ‰¾åˆ°æ–‡æœ¬æ ‡é¢˜: {title[:40]}...")

                                                    # å¯»æ‰¾è¯¥è¡Œä¸­çš„é“¾æ¥å…ƒç´ 

                                                    try:

                                                        title_element = tds[1].find_element(By.CSS_SELECTOR, "a")

                                                    except:

                                                        title_element = None

                                        except:

                                            print(f"      ç¬¬{i+1} è¡Œæ— æ³•è·å–æ ‡é¢˜")

                                            continue

                                

                                if not title:

                                    print(f"      ç¬¬{i+1} è¡Œæ ‡é¢˜ä¸ºç©ºï¼Œè·³è¿‡")

                                    continue

                                    

                                # æ˜¾ç¤ºæ‰€æœ‰æ¡ç›®ï¼Œä¾¿äºè°ƒè¯•

                                print(f"    [{i+1}] æ ‡é¢˜: {title[:60]}... æ—¥æœŸ: {date}")

                                

                                # ä¸¥æ ¼çš„å¹´æŠ¥åŒ¹é…æ¡ä»¶

                                is_annual_report = (

                                    str(year) in title and 

                                    ('å¹´åº¦æŠ¥å‘Š' in title or 'å¹´æŠ¥' in title or 'Annual Report' in title.title()) and

                                    'æ‘˜è¦' not in title and  # æ’é™¤æ‘˜è¦

                                    'ç›‘ç®¡' not in title and  # æ’é™¤ç›‘ç®¡

                                    'å›å¤' not in title and  # æ’é™¤å›å¤

                                    'é—®è¯¢' not in title and  # æ’é™¤é—®è¯¢

                                    'å„ç§å‡½ä»¶' not in title and    # æ’é™¤å„ç§å‡½ä»¶

                                    'å®¡è®¡æ„è§' not in title and  # æ’é™¤å®¡è®¡æ„è§

                                    'æ›´æ­£' not in title and  # æ’é™¤æ›´æ­£å…¬å‘Š

                                    'è¡¥å……' not in title and  # æ’é™¤è¡¥å……å…¬å‘Š

                                    'å…³äºxxå¹´æŠ¥çš„å…¬å‘Š' not in title and  # æ’é™¤"å…³äºxxå¹´æŠ¥çš„å…¬å‘Š"

                                    'è‡ªæ„¿æ€§æŠ«éœ²å…¬å‘Š' not in title and  # æ’é™¤è‡ªæ„¿æ€§æŠ«éœ²å…¬å‘Š

                                    'è‹±æ–‡' not in title and  # æ’é™¤è‹±æ–‡

                                    'ç®€æŠ¥' not in title     # æ’é™¤ç®€æŠ¥

                                )

                                

                                if is_annual_report:

                                    print(f"    ğŸ”„ æ‰¾åˆ°å¹´æŠ¥: {title}")

                                    

                                    # ç§‘åˆ›æ¿/åˆ›ä¸šæ¿/æ¸¯è‚¡ï¼šè·å–é“¾æ¥hrefå¹¶è®¿é—®è¯¦æƒ…é¡µ

                                    if title_element:

                                        # è·å–é“¾æ¥çš„hrefå±æ€§

                                        try:

                                            detail_href = title_element.get_attribute('href')

                                            print(f"      é“¾æ¥href: {detail_href}")

                                            

                                            if detail_href:

                                                # ç›´æ¥è®¿é—®è¯¦æƒ…é¡µ

                                                self.driver.get(detail_href)

                                                time.sleep(3)

                                                

                                                # è·å–å½“å‰é¡µé¢URL

                                                detail_url = self.driver.current_url

                                                print(f"      è¯¦æƒ…é¡µURL: {detail_url}")

                                            else:

                                                # å¦‚æœæ²¡æœ‰hrefï¼Œå°è¯•ç‚¹å‡»

                                                title_element.click()

                                                time.sleep(3)

                                                detail_url = self.driver.current_url

                                                print(f"      è¯¦æƒ…é¡µURL: {detail_url}")

                                        except:

                                            # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥ç‚¹å‡»

                                            title_element.click()

                                            time.sleep(3)

                                            detail_url = self.driver.current_url

                                            print(f"      è¯¦æƒ…é¡µURL: {detail_url}")

                                        

                                        # ä»URLä¸­æå–announcementIdå’ŒannouncementTime

                                        try:

                                            from urllib.parse import urlparse, parse_qs

                                            parsed_url = urlparse(detail_url)

                                            query_params = parse_qs(parsed_url.query)

                                            

                                            announcement_id = query_params.get('announcementId', [None])[0]

                                            announcement_time = query_params.get('announcementTime', [None])[0]

                                            

                                            if announcement_id and announcement_time:

                                                # ä»announcementTimeä¸­åªæå–æ—¥æœŸéƒ¨åˆ†ï¼ˆå»æ‰æ—¶é—´ï¼‰

                                                announcement_date = announcement_time.split(' ')[0] if ' ' in announcement_time else announcement_time

                                                

                                                # æ„é€ PDFä¸‹è½½URL

                                                pdf_url = f"https://static.cninfo.com.cn/finalpage/{announcement_date}/{announcement_id}.PDF"

                                                print(f"      æ„é€ PDFä¸‹è½½é“¾æ¥: {pdf_url}")

                                                

                                                # å°è¯•è·å–è‚¡ç¥¨åç§°ï¼ˆä»æ ‡é¢˜ä¸­æå–ï¼‰
                                                company_name = stock_code  # é»˜è®¤ä½¿ç”¨è‚¡ç¥¨ä»£ç 
                                                try:
                                                    # ä»æ ‡é¢˜ä¸­æå–å…¬å¸åç§°
                                                    if "ï¼š" in title:
                                                        company_name = title.split("ï¼š")[0].strip()
                                                    elif title.startswith("å…³äº"):
                                                        # å¤„ç†"å…³äºXXXå…¬å¸"æ ¼å¼
                                                        parts = title.split("å¹´åº¦æŠ¥å‘Š")
                                                        if len(parts) > 0:
                                                            name_part = parts[0].replace("å…³äº", "").replace(f"{year}", "").strip()
                                                            if name_part:
                                                                company_name = name_part
                                                except:
                                                    pass
                                                
                                                # æ„é€ æ–‡ä»¶å
                                                filename = f"{stock_code}_{company_name}_{year}å¹´æŠ¥.pdf"

                                                

                                                # ä½¿ç”¨requestsä¸‹è½½PDF

                                                filepath = self.download_dir / filename
                                                download_success = self.download_pdf(pdf_url, str(filepath))

                                                

                                                if download_success:

                                                    print(f"    æˆåŠŸä¸‹è½½: {filename}")

                                                    results.append({

                                                        'stock_code': stock_code,

                                                        'year': year,

                                                        'status': 'success',

                                                        'filename': filename,

                                                        'title': title,

                                                        'pdf_url': pdf_url

                                                    })

                                                else:

                                                    print(f"ğŸ”„ ä¸‹è½½å¤±è´¥: {filename}")

                                                    results.append({

                                                        'stock_code': stock_code,

                                                        'year': year,

                                                        'status': 'download_failed',

                                                        'error': f'PDFä¸‹è½½å¤±è´¥: {pdf_url}',

                                                        'title': title

                                                    })

                                            else:

                                                print(f"      âš ï¸ æ— æ³•ä»URLä¸­æå–å¿…è¦å‚æ•°")

                                                results.append({

                                                    'stock_code': stock_code,

                                                    'year': year,

                                                    'status': 'url_parse_failed',

                                                    'error': 'æ— æ³•è§£æè¯¦æƒ…é¡µURLå‚æ•°',

                                                    'title': title

                                                })

                                        except Exception as url_error:

                                            print(f"      ğŸ”„ URLè§£æå‡ºé”™: {url_error}")

                                            results.append({

                                                'stock_code': stock_code,

                                                'year': year,

                                                'status': 'url_error',

                                                'error': str(url_error),

                                                'title': title

                                            })

                                        

                                        found_report = True

                                        break

                                    

                            except Exception as e:

                                print(f"    è§£æç¬¬{i+1}è¡Œæ—¶å‡ºé”™: {e}")

                                continue

                    

                    # è§£ææœç´¢ç»“æœ
                    if not found_report:
                        # å¦‚æœå‰50è¡Œæ²¡æ‰¾åˆ°ï¼Œå°è¯•ç¿»é¡µæœç´¢
                        print(f"    ğŸ”„ å‰50è¡Œæœªæ‰¾åˆ°å¹´æŠ¥ï¼Œå°è¯•ç¿»é¡µæœç´¢...")
                        
                        # å°è¯•ç¿»é¡µï¼Œæœ€å¤šç¿»3é¡µ
                        for page_num in range(2, 5):  # ç¬¬2é¡µåˆ°ç¬¬4é¡µ
                            try:
                                # æŸ¥æ‰¾ä¸‹ä¸€é¡µæŒ‰é’®
                                next_page_selectors = [
                                    f"a[title='ç¬¬{page_num}é¡µ']",
                                    f"a[data-page='{page_num}']",
                                    f".page-item:nth-child({page_num + 1}) a",
                                    f".pagination a:contains('{page_num}')",
                                    f"a:contains('ç¬¬{page_num}é¡µ')",
                                    f"a:contains('{page_num}')"
                                ]
                                
                                next_button = None
                                for selector in next_page_selectors:
                                    try:
                                        next_button = self.driver.find_element(By.CSS_SELECTOR, selector)
                                        if next_button and next_button.is_displayed() and next_button.is_enabled():
                                            print(f"      æ‰¾åˆ°ç¬¬{page_num}é¡µæŒ‰é’®: {selector}")
                                            break
                                    except:
                                        continue
                                
                                if not next_button:
                                    print(f"      æœªæ‰¾åˆ°ç¬¬{page_num}é¡µæŒ‰é’®ï¼Œåœæ­¢ç¿»é¡µ")
                                    break
                                
                                # ç‚¹å‡»ç¿»é¡µ
                                self.driver.execute_script("arguments[0].click();", next_button)
                                time.sleep(3)
                                
                                print(f"      å·²ç¿»åˆ°ç¬¬{page_num}é¡µï¼Œé‡æ–°æœç´¢...")
                                
                                # é‡æ–°è·å–è¡¨æ ¼è¡Œ
                                rows = self.driver.find_elements(By.CSS_SELECTOR, "tbody tr, .table tr, tr")
                                if not rows:
                                    print(f"      ç¬¬{page_num}é¡µæ— æ•°æ®")
                                    continue
                                
                                # æ£€æŸ¥è¿™ä¸€é¡µçš„å‰20è¡Œ
                                for i, row in enumerate(rows[:20]):
                                    try:
                                        # è·å–æ ‡é¢˜
                                        title = ""
                                        title_element = None
                                        
                                        try:
                                            title_element = row.find_element(By.CSS_SELECTOR, "td a")
                                            title = title_element.text.strip()
                                        except:
                                            try:
                                                title_element = row.find_element(By.CSS_SELECTOR, "a")
                                                title = title_element.text.strip()
                                            except:
                                                tds = row.find_elements(By.CSS_SELECTOR, "td")
                                                if len(tds) >= 2:
                                                    title = tds[1].text.strip()
                                                    try:
                                                        title_element = tds[1].find_element(By.CSS_SELECTOR, "a")
                                                    except:
                                                        title_element = None
                                        
                                        if not title:
                                            continue
                                        
                                        # å¹´æŠ¥åŒ¹é…æ£€æŸ¥
                                        is_annual_report = (
                                            str(year) in title and 
                                            ('å¹´åº¦æŠ¥å‘Š' in title or 'å¹´æŠ¥' in title or 'Annual Report' in title.title()) and
                                            'æ‘˜è¦' not in title and 'ç›‘ç®¡' not in title and 'å›å¤' not in title and 
                                            'é—®è¯¢' not in title and 'å„ç§å‡½ä»¶' not in title and 'å®¡è®¡æ„è§' not in title and 
                                            'æ›´æ­£' not in title and 'è¡¥å……' not in title and 'å…³äºxxå¹´æŠ¥çš„å…¬å‘Š' not in title and 
                                            'è‡ªæ„¿æ€§æŠ«éœ²å…¬å‘Š' not in title and 'è‹±æ–‡' not in title and 'ç®€æŠ¥' not in title
                                        )
                                        
                                        if is_annual_report:
                                            print(f"      ğŸ‰ ç¬¬{page_num}é¡µæ‰¾åˆ°å¹´æŠ¥: {title}")
                                            found_report = True
                                            
                                            # å¤„ç†ä¸‹è½½é€»è¾‘ï¼ˆå¤ç”¨ä¹‹å‰çš„ä»£ç ï¼‰
                                            if title_element:
                                                try:
                                                    detail_href = title_element.get_attribute('href')
                                                    if detail_href:
                                                        self.driver.get(detail_href)
                                                        time.sleep(3)
                                                        detail_url = self.driver.current_url
                                                        
                                                        # è§£æURLå‚æ•°å¹¶ä¸‹è½½ï¼ˆå¤ç”¨ä¹‹å‰çš„é€»è¾‘ï¼‰
                                                        from urllib.parse import urlparse, parse_qs
                                                        parsed_url = urlparse(detail_url)
                                                        query_params = parse_qs(parsed_url.query)
                                                        
                                                        if 'announcementId' in query_params and 'orgId' in query_params:
                                                            announcement_id = query_params['announcementId'][0]
                                                            org_id_param = query_params['orgId'][0]
                                                            
                                                            pdf_url = f"http://static.cninfo.com.cn/finalpage/{announcement_id}.PDF"
                                                            
                                                            # å°è¯•è·å–è‚¡ç¥¨åç§°ï¼ˆä»æ ‡é¢˜ä¸­æå–ï¼‰
                                                            company_name = stock_code  # é»˜è®¤ä½¿ç”¨è‚¡ç¥¨ä»£ç 
                                                            try:
                                                                # ä»æ ‡é¢˜ä¸­æå–å…¬å¸åç§°
                                                                if "ï¼š" in title:
                                                                    company_name = title.split("ï¼š")[0].strip()
                                                                elif title.startswith("å…³äº"):
                                                                    # å¤„ç†"å…³äºXXXå…¬å¸"æ ¼å¼
                                                                    parts = title.split("å¹´åº¦æŠ¥å‘Š")
                                                                    if len(parts) > 0:
                                                                        name_part = parts[0].replace("å…³äº", "").replace(f"{year}", "").strip()
                                                                        if name_part:
                                                                            company_name = name_part
                                                            except:
                                                                pass
                                                            
                                                            filename = f"{stock_code}_{company_name}_{year}å¹´æŠ¥.pdf"
                                                            filepath = self.download_dir / filename
                                                            
                                                            if self.download_pdf(pdf_url, str(filepath)):
                                                                print(f"      âœ“ ç¿»é¡µæˆåŠŸä¸‹è½½: {filename}")
                                                                results.append({
                                                                    'stock_code': stock_code,
                                                                    'year': year,
                                                                    'status': 'success',
                                                                    'filename': filename,
                                                                    'title': title,
                                                                    'pdf_url': pdf_url
                                                                })
                                                            else:
                                                                results.append({
                                                                    'stock_code': stock_code,
                                                                    'year': year,
                                                                    'status': 'download_failed',
                                                                    'error': f'PDFä¸‹è½½å¤±è´¥: {pdf_url}',
                                                                    'title': title
                                                                })
                                                        else:
                                                            results.append({
                                                                'stock_code': stock_code,
                                                                'year': year,
                                                                'status': 'url_parse_failed',
                                                                'error': 'æ— æ³•è§£æè¯¦æƒ…é¡µURLå‚æ•°',
                                                                'title': title
                                                            })
                                                except Exception as e:
                                                    results.append({
                                                        'stock_code': stock_code,
                                                        'year': year,
                                                        'status': 'url_error',
                                                        'error': str(e),
                                                        'title': title
                                                    })
                                            break
                                    except Exception as e:
                                        continue
                                
                                if found_report:
                                    break
                                    
                            except Exception as e:
                                print(f"      ç¿»é¡µåˆ°ç¬¬{page_num}é¡µå¤±è´¥: {e}")
                                break
                        
                        if not found_report:
                            print(f"    âœ— ç¿»é¡µåä»æœªæ‰¾åˆ°{stock_code} {year}å¹´å¹´æŠ¥")
                            results.append({
                                'stock_code': stock_code,
                                'year': year,
                                'status': 'not_found',
                                'error': 'æœªæ‰¾åˆ°å¹´æŠ¥'
                            })
                    # å¦‚æœfound_reportä¸ºTrueï¼Œè¯´æ˜å·²ç»æ‰¾åˆ°å¹¶å¤„ç†äº†ï¼Œä¸éœ€è¦å†æ·»åŠ not_foundè®°å½•
                
                except Exception as e:
                    print(f"ğŸ”„ æœç´¢è¿‡ç¨‹å‡ºé”™: {e}")
                    results.append({
                        'stock_code': stock_code,
                        'year': year,
                        'status': 'search_failed',
                        'error': str(e)
                    })
        
        except Exception as e:
            print(f"ğŸ”„ Seleniumæ“ä½œå‡ºé”™: {e}")
            results.append({
                'stock_code': stock_code,
                'year': 'all',
                'status': 'selenium_error',
                'error': str(e)
            })
        
        return results

    

    def search_hk_company_by_name(self, company_name_part: str) -> Tuple[str, str, str]:
        """
        é€šè¿‡å…¬å¸åç§°ç‰‡æ®µæœç´¢æ¸¯è‚¡ï¼Œè·å–orgId
        
        Args:
            company_name_part: å…¬å¸åç§°ç‰‡æ®µæˆ–è‚¡ç¥¨ä»£ç 
            
        Returns:
            Tuple[è‚¡ç¥¨ä»£ç , å…¬å¸åç§°, orgId]
        """
        api_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'X-Requested-With': 'XMLHttpRequest'
        }
        
        # å¤„ç†HKå‰ç¼€
        search_term = company_name_part
        original_search_code = company_name_part  # ä¿å­˜åŸå§‹è¾“å…¥ç”¨äºç²¾ç¡®åŒ¹é…
        if search_term.startswith('HK'):
            search_term = search_term[2:]  # å»æ‰HKå‰ç¼€
            original_search_code = search_term  # æ›´æ–°åŸå§‹ä»£ç 
        
        params = {
            "stock": "",
            "tabName": "fulltext",
                            "pageSize": 50,
                "pageNum": 1,
            "column": "",
            "category": "",
            "plate": "",
            "seDate": "2020-01-01~2025-12-31",
            "searchkey": search_term,
            "secid": "",
            "sortName": "pubdate",
            "sortType": "desc",
            "isHLtitle": "true"
        }
        
        try:
            print(f"    ğŸ” æœç´¢æ¸¯è‚¡å…¬å¸: {search_term} (ç²¾ç¡®åŒ¹é…: {original_search_code})")
            response = requests.post(api_url, headers=headers, data=params, timeout=10)
            if response.status_code == 200:
                result = response.json()
                announcements = result.get('announcements')
                
                # å¤„ç†Noneå“åº”
                if announcements is None:
                    print(f"    âš ï¸ APIè¿”å›announcementsä¸ºNone")
                    return None, None, None
                
                # ğŸ”§ ä¿®å¤ï¼šæ”¶é›†æ‰€æœ‰åŒ¹é…ç»“æœï¼Œä¼˜å…ˆç²¾ç¡®åŒ¹é…
                exact_matches = []
                partial_matches = []
                
                for ann in announcements:
                    sec_code = ann.get('secCode', '')
                    sec_name = ann.get('secName', '')
                    org_id = ann.get('orgId', '')
                    
                    # æ¸…ç†HTMLæ ‡ç­¾
                    clean_name = sec_name.replace('<em>', '').replace('</em>', '') if sec_name else ''
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ¸¯è‚¡ï¼ˆä»£ç é•¿åº¦5ä½æˆ–ä»¥HKå¼€å¤´ï¼‰
                    if sec_code and org_id and (len(sec_code) == 5 or sec_code.startswith('HK')):
                        # ç²¾ç¡®åŒ¹é…ï¼šè‚¡ç¥¨ä»£ç å®Œå…¨ç›¸åŒ
                        if sec_code == original_search_code or sec_code == original_search_code.zfill(5):
                            exact_matches.append((sec_code, clean_name, org_id))
                            print(f"    âœ… ç²¾ç¡®åŒ¹é…: {clean_name} ({sec_code}) - orgId: {org_id}")
                        else:
                            partial_matches.append((sec_code, clean_name, org_id))
                            print(f"    ğŸ“„ éƒ¨åˆ†åŒ¹é…: {clean_name} ({sec_code}) - orgId: {org_id}")
                
                # ä¼˜å…ˆè¿”å›ç²¾ç¡®åŒ¹é…ç»“æœ
                if exact_matches:
                    sec_code, clean_name, org_id = exact_matches[0]
                    print(f"    ğŸ¯ ä½¿ç”¨ç²¾ç¡®åŒ¹é…ç»“æœ: {clean_name} ({sec_code})")
                    return sec_code, clean_name, org_id
                elif partial_matches:
                    sec_code, clean_name, org_id = partial_matches[0]
                    print(f"    âš ï¸ æ— ç²¾ç¡®åŒ¹é…ï¼Œä½¿ç”¨éƒ¨åˆ†åŒ¹é…: {clean_name} ({sec_code})")
                    print(f"    âš ï¸ è­¦å‘Šï¼šè¾“å…¥ä»£ç  {original_search_code} != æ‰¾åˆ°ä»£ç  {sec_code}")
                    return sec_code, clean_name, org_id
                        
        except Exception as e:
            print(f"    âœ— æœç´¢æ¸¯è‚¡å…¬å¸å¤±è´¥: {e}")
        
        return None, None, None

    def download_hk_reports(self, stock_code: str, years: List[int]) -> List[dict]:
        """
        ä½¿ç”¨APIä¸‹è½½æ¸¯è‚¡å¹´æŠ¥ï¼ˆæ–°ç‰ˆæœ¬ï¼‰
        
        Args:
            stock_code: æ¸¯è‚¡ä»£ç 
            years: å¹´ä»½åˆ—è¡¨
            
        Returns:
            ä¸‹è½½ç»“æœåˆ—è¡¨
        """
        print(f"\nğŸš€ å¼€å§‹ä¸‹è½½æ¸¯è‚¡ {stock_code} çš„å¹´æŠ¥...")
        results = []
        
        # åˆ›å»ºæ¸¯è‚¡ä¸‹è½½ç›®å½•
        hk_dir = self.download_dir / "HK"
        hk_dir.mkdir(exist_ok=True)
        
        try:
            # å…ˆå°è¯•æœç´¢å…¬å¸ä¿¡æ¯
            company_name = None
            org_id = None
            
            # å¤„ç†HKå‰ç¼€çš„è‚¡ç¥¨ä»£ç 
            search_code = stock_code
            if stock_code.startswith('HK'):
                search_code = stock_code[2:]  # å»æ‰HKå‰ç¼€ç”¨äºæœç´¢
            
            # å°è¯•ç”¨è‚¡ç¥¨ä»£ç æœç´¢
            found_code, company_name, org_id = self.search_hk_company_by_name(search_code)
            
            if not org_id:
                # å°è¯•å»æ‰å‰å¯¼0æœç´¢
                search_code_no_zero = search_code.lstrip('0')
                print(f"    ğŸ”„ å°è¯•å»æ‰å‰å¯¼0æœç´¢: {search_code_no_zero}")
                found_code, company_name, org_id = self.search_hk_company_by_name(search_code_no_zero)
            
            if not org_id:
                print(f"  âœ— æ— æ³•æ‰¾åˆ°æ¸¯è‚¡ {stock_code} çš„å…¬å¸ä¿¡æ¯")
                for year in years:
                    results.append({
                        'stock_code': stock_code,
                        'company_name': None,
                        'year': year,
                        'status': 'company_not_found',
                        'error': 'æ— æ³•æ‰¾åˆ°å…¬å¸ä¿¡æ¯'
                    })
                return results
            
            print(f"  âœ“ å…¬å¸ä¿¡æ¯: {company_name} ({found_code}) - orgId: {org_id}")
            
            # æœç´¢å¹´æŠ¥
            api_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
                'Accept': 'application/json, text/javascript, */*; q=0.01',
                'X-Requested-With': 'XMLHttpRequest'
            }
            
            # å¤šç§æœç´¢ç­–ç•¥ï¼ˆåŠ¨æ€ç”ŸæˆåŸºäºç›®æ ‡å¹´ä»½ï¼‰
            search_strategies = [
                (f"{company_name} å¹´åº¦æŠ¥å‘Š", "å…¬å¸å+å¹´åº¦æŠ¥å‘Š"),
                (f"{company_name} å¹´æŠ¥", "å…¬å¸å+å¹´æŠ¥"),
                (f"{found_code} å¹´åº¦æŠ¥å‘Š", "è‚¡ç¥¨ä»£ç +å¹´åº¦æŠ¥å‘Š"),
                (f"{found_code} å¹´æŠ¥", "è‚¡ç¥¨ä»£ç +å¹´æŠ¥"),
            ]
            
            # åŠ¨æ€æ·»åŠ åŸºäºç›®æ ‡å¹´ä»½çš„æœç´¢ç­–ç•¥
            for year in years:
                search_strategies.extend([
                    (f"{company_name} {year}", f"å…¬å¸å+{year}"),
                    (f"{found_code} {year}", f"è‚¡ç¥¨ä»£ç +{year}"),
                ])
            
            found_reports = {}
            
            for search_term, strategy_desc in search_strategies:
                print(f"  ğŸ” ä½¿ç”¨ç­–ç•¥: {strategy_desc} - {search_term}")
                
                params = {
                    "stock": "",
                    "tabName": "fulltext",
                    "pageSize": 50,  # å¢åŠ é¡µé¢å¤§å°
                    "pageNum": 1,
                    "column": "",
                    "category": "",
                    "plate": "",
                    "seDate": "2018-01-01~2025-12-31",
                    "searchkey": search_term,
                    "secid": "",
                    "sortName": "pubdate",
                    "sortType": "desc",
                    "isHLtitle": "true"
                }
                
                try:
                    # æ”¯æŒç¿»é¡µæœç´¢ï¼Œæœ€å¤šæœç´¢å‰3é¡µ
                    all_announcements = []
                    for page_num in range(1, 4):
                        params["pageNum"] = page_num
                        
                        response = requests.post(api_url, headers=headers, data=params, timeout=20)
                        
                        if response.status_code == 200:
                            result = response.json()
                            announcements = result.get('announcements', [])
                            
                            if announcements:
                                all_announcements.extend(announcements)
                                print(f"    ç¬¬{page_num}é¡µæ‰¾åˆ°{len(announcements)}æ¡å…¬å‘Š")
                            else:
                                if page_num == 1:
                                    print(f"    âŒ æ— ç»“æœ")
                                else:
                                    print(f"    ç¬¬{page_num}é¡µæ— ç»“æœï¼Œåœæ­¢ç¿»é¡µ")
                                break
                        else:
                            print(f"    âŒ HTTPé”™è¯¯: {response.status_code}")
                            break
                    
                    if all_announcements:
                        print(f"    âœ“ æ€»å…±æ‰¾åˆ° {len(all_announcements)} æ¡å…¬å‘Š")
                        
                        for ann in all_announcements:
                            title = ann.get('announcementTitle', '')
                            sec_code = ann.get('secCode', '')
                            sec_name = ann.get('secName', '')
                            adj_url = ann.get('adjunctUrl', '')
                            
                            # ç¡®ä¿æ˜¯ç›®æ ‡å…¬å¸ï¼ˆåŒ¹é…æ¸¯è‚¡å’Œå¯¹åº”çš„Aè‚¡ä»£ç ï¼‰
                            target_codes = [found_code]
                            # å¦‚æœæ˜¯æ¸¯è‚¡ï¼Œä¹ŸåŒ¹é…å¯¹åº”çš„Aè‚¡ä»£ç 
                            if found_code == '00939':  # å»ºè®¾é“¶è¡Œæ¸¯è‚¡
                                target_codes.append('601939')  # å»ºè®¾é“¶è¡ŒAè‚¡
                            elif found_code == '00700':  # è…¾è®¯æ¸¯è‚¡
                                # è…¾è®¯æ²¡æœ‰Aè‚¡ï¼Œåªæœ‰æ¸¯è‚¡
                                pass
                            
                            if sec_code not in target_codes:
                                continue
                                
                            # æ¸…ç†HTMLæ ‡ç­¾
                            clean_title = title.replace('<em>', '').replace('</em>', '')
                            
                            # ä½¿ç”¨å¢å¼ºçš„å¹´ä»½åŒ¹é…é€»è¾‘ï¼ˆåŒ…å«æ—¥æœŸè¾…åŠ©ï¼‰
                            matched_year = None
                            if (('å¹´åº¦æŠ¥å‘Š' in clean_title or 'å¹´æŠ¥' in clean_title or 'ä¼ä¸šå¹´åº¦æŠ¥å‘Š' in clean_title) and
                                'åŠå¹´' not in clean_title and  # æ’é™¤åŠå¹´æŠ¥
                                'åŠå¹´åº¦' not in clean_title and  # æ’é™¤åŠå¹´åº¦æŠ¥å‘Š
                                'ä¸­æœŸ' not in clean_title and  # æ’é™¤ä¸­æœŸæŠ¥å‘Š
                                'æ‘˜è¦' not in clean_title and  # æ’é™¤æ‘˜è¦
                                'é€šçŸ¥ä¿¡å‡½' not in clean_title and  # æ’é™¤é€šçŸ¥ä¿¡å‡½
                                'é€šå‘Š' not in clean_title and  # æ’é™¤é€šå‘Š
                                'é€šå‡½' not in clean_title and  # æ’é™¤é€šå‡½
                                'åˆŠå‘é€šçŸ¥' not in clean_title and  # æ’é™¤åˆŠå‘é€šçŸ¥
                                'ä»£è¡¨å§”ä»»è¡¨æ ¼' not in clean_title and  # æ’é™¤ä»£è¡¨å§”ä»»è¡¨æ ¼
                                'è‚¡ä¸œå‘¨å¹´å¤§ä¼š' not in clean_title):  # æ’é™¤è‚¡ä¸œå¤§ä¼šç›¸å…³
                                
                                # è·å–å‘å¸ƒæ—¥æœŸç”¨äºè¾…åŠ©åˆ¤æ–­
                                pub_date = ann.get('announcementTime', '')
                                matched_year = enhanced_year_matching_with_date(clean_title, years, pub_date)
                            
                            if matched_year and matched_year not in found_reports:
                                found_reports[matched_year] = {
                                    'title': title,
                                    'adjunctUrl': adj_url,
                                    'search_term': search_term
                                }
                                print(f"    â˜… æ‰¾åˆ° {matched_year} å¹´æŠ¥: {clean_title}")
                    
                except Exception as e:
                    print(f"    âŒ æœç´¢å¼‚å¸¸: {e}")
                
                # å¦‚æœå·²ç»æ‰¾åˆ°æ‰€æœ‰å¹´ä»½çš„å¹´æŠ¥ï¼Œå¯ä»¥æå‰ç»“æŸ
                if len(found_reports) >= len(years):
                    break
            
            # ä¸‹è½½æ‰¾åˆ°çš„å¹´æŠ¥
            print(f"  ğŸ“¥ å¼€å§‹ä¸‹è½½å¹´æŠ¥...")
            
            for year in years:
                if year in found_reports:
                    report = found_reports[year]
                    adj_url = report['adjunctUrl']
                    
                    if adj_url:
                        # æ„é€ PDFç›´æ¥ä¸‹è½½é“¾æ¥
                        pdf_url = f"http://static.cninfo.com.cn/{adj_url}"
                        # ä½¿ç”¨æ¸…ç†åçš„å…¬å¸åç§°
                        safe_company_name = company_name.replace('/', '_').replace('\\', '_')
                        filename = f"{found_code}_{safe_company_name}_{year}å¹´å¹´åº¦æŠ¥å‘Š.pdf"
                        filepath = hk_dir / filename
                        
                        print(f"    ğŸ“„ ä¸‹è½½ {year} å¹´æŠ¥...")
                        print(f"       æ–‡ä»¶: {report['title']}")
                        
                        if self.download_pdf(pdf_url, str(filepath)):
                            print(f"    âœ“ æˆåŠŸä¸‹è½½: {filename}")
                            results.append({
                                'stock_code': stock_code,
                                'company_name': company_name,
                                'year': year,
                                'status': 'success',
                                'filename': filename,
                                'file_path': str(filepath)
                            })
                        else:
                            print(f"    âœ— ä¸‹è½½å¤±è´¥: {filename}")
                            results.append({
                                'stock_code': stock_code,
                                'company_name': company_name,
                                'year': year,
                                'status': 'download_failed',
                                'error': 'PDFä¸‹è½½å¤±è´¥'
                            })
                    else:
                        print(f"    âœ— {year} å¹´æŠ¥æ— PDFé“¾æ¥")
                        results.append({
                            'stock_code': stock_code,
                            'company_name': company_name,
                            'year': year,
                            'status': 'no_pdf_link',
                            'error': 'æ— PDFé“¾æ¥'
                        })
                else:
                    print(f"    âœ— æœªæ‰¾åˆ° {year} å¹´æŠ¥")
                    results.append({
                        'stock_code': stock_code,
                        'company_name': company_name,
                        'year': year,
                        'status': 'not_found',
                        'error': 'æœªæ‰¾åˆ°å¹´æŠ¥'
                    })
            
            return results
            
        except Exception as e:
            print(f"ğŸ”„ æ¸¯è‚¡ä¸‹è½½è¿‡ç¨‹å‡ºé”™: {e}")
            for year in years:
                results.append({
                    'stock_code': stock_code,
                    'company_name': None,
                    'year': year,
                    'status': 'error',
                    'error': str(e)
                })
            return results

    def download_hk_reports_old(self, stock_code: str, years: List[int]) -> List[dict]:
        """
        æ—§ç‰ˆæ¸¯è‚¡ä¸‹è½½æ–¹æ³•ï¼ˆä½¿ç”¨Seleniumï¼‰
        ç°åœ¨å·²è¢«æ–°ç‰ˆAPIæ–¹æ³•æ›¿ä»£
        """
        return [{'stock_code': stock_code, 'year': 'all', 'status': 'deprecated', 'error': 'å·²ä½¿ç”¨æ–°ç‰ˆAPIæ–¹æ³•'}]

    def download_pdf(self, url: str, filepath: str) -> bool:
        """
        é€šè¿‡æµè§ˆå™¨ä¸‹è½½PDFæ–‡ä»¶
        
        Args:
            url: ä¸‹è½½URL
            filepath: å®Œæ•´æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            target_path = Path(filepath)
            target_path.parent.mkdir(parents=True, exist_ok=True)
            
            # ä½¿ç”¨æµè§ˆå™¨ä¸‹è½½
            filename = target_path.name
            success = self.browser_download_file(url, filename)
            
            if success:
                # ğŸ”§ ä¿®å¤ï¼šåœ¨æµè§ˆå™¨ä¸‹è½½ç›®å½•ä¸­æŸ¥æ‰¾æ–‡ä»¶
                downloaded_files = [f for f in self.download_dir.iterdir() if f.is_file()]
                if downloaded_files:
                    # æ‰¾åˆ°æœ€æ–°ä¸‹è½½çš„æ–‡ä»¶
                    latest_file = max(downloaded_files, key=lambda f: f.stat().st_mtime)
                    
                    # å¢åŠ é¢å¤–å®‰å…¨æ£€æŸ¥
                    if latest_file.name.endswith('.crdownload'):
                        print(f"    âŒ é‡å‘½åå¤±è´¥ï¼šæ–‡ä»¶ä»ä¸ºä¸´æ—¶çŠ¶æ€: {latest_file.name}")
                        return False
                    
                    print(f"    ğŸ“ æµè§ˆå™¨ä¸‹è½½æ–‡ä»¶: {latest_file}")
                    print(f"    ğŸ“ ç›®æ ‡è·¯å¾„: {target_path}")
                    
                    # ğŸ”§ ä¿®å¤ï¼šç§»åŠ¨æ–‡ä»¶åˆ°æ­£ç¡®ç›®å½•å¹¶é‡å‘½å
                    try:
                        # ç¡®ä¿ç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œé¿å…å†²çª
                        if target_path.exists():
                            print(f"    âš ï¸ ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ é™¤æ—§æ–‡ä»¶: {filename}")
                            target_path.unlink()
                        
                        # ç§»åŠ¨å¹¶é‡å‘½åæ–‡ä»¶
                        latest_file.rename(target_path)
                        print(f"    ğŸ“ æ–‡ä»¶ç§»åŠ¨é‡å‘½å: {latest_file.name} -> {target_path}")
                        
                        # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨äºç›®æ ‡ä½ç½®
                        if target_path.exists():
                            print(f"    âœ… æ–‡ä»¶æˆåŠŸä¿å­˜åˆ°: {target_path}")
                            return True
                        else:
                            print(f"    âŒ æ–‡ä»¶ç§»åŠ¨åæœªæ‰¾åˆ°: {target_path}")
                            return False
                            
                    except Exception as rename_error:
                        print(f"    âŒ æ–‡ä»¶ç§»åŠ¨é‡å‘½åå¤±è´¥: {rename_error}")
                        return False
                else:
                    print("    âŒ æœªæ‰¾åˆ°ä¸‹è½½çš„æ–‡ä»¶")
                    return False
            else:
                return False
            
        except Exception as e:
            print(f"    ä¸‹è½½å¤±è´¥: {e}")
            return False

    

    def download_stock_reports(self, stock_code: str, years: List[int]) -> List[Dict]:

        """

        ä¸‹è½½æŒ‡å®šè‚¡ç¥¨çš„å¹´æŠ¥

        

        Args:

            stock_code: è‚¡ç¥¨ä»£ç 

            years: å¹´ä»½åˆ—è¡¨

            

        Returns:

            ä¸‹è½½ç»“æœåˆ—è¡¨

        """

        stock_type = self.identify_stock_type(stock_code)

        print(f"ğŸ“Š å¤„ç†è‚¡ç¥¨: {stock_code} ({stock_type})")

        

        if stock_type == StockType.A_MAIN:

            return self.download_a_stock_main_reports(stock_code, years)

        elif stock_type in [StockType.A_STAR, StockType.A_GEM]:

            return self.download_a_stock_with_selenium(stock_code, years, stock_type)

        elif stock_type == StockType.HK:

            return self.download_hk_reports(stock_code, years)

        elif stock_type == StockType.US:

            return self.download_us_stock_10k_reports(stock_code, years)

        else:

            print(f"    ğŸ”„ ä¸æ”¯æŒçš„è‚¡ç¥¨ç±»å‹: {stock_type}")

            return [{'stock_code': stock_code, 'year': 'all', 'status': 'unsupported', 'error': f'ä¸æ”¯æŒçš„è‚¡ç¥¨ç±»å‹: {stock_type}'}]

    

    def process_stock_list(self, stock_codes: List[str], years: List[int]):

        """

        æ‰¹é‡å¤„ç†è‚¡ç¥¨åˆ—è¡¨

        

        Args:

            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨

            years: å¹´ä»½åˆ—è¡¨

        """

        self.stats["total"] = len(stock_codes) * len(years)

        

        print(f"ğŸš€ å¼€å§‹æ‰¹é‡ä¸‹è½½ï¼Œå…±{len(stock_codes)} åªè‚¡ç¥¨ï¼Œ{len(years)} ä¸ªå¹´ä»½")

        print(f"ğŸ“ ä¸‹è½½ç›®å½•: {self.download_dir.absolute()}")

        print("=" * 60)

        

        for i, stock_code in enumerate(stock_codes, 1):

            print(f"\n[{i}/{len(stock_codes)}] å¤„ç†è‚¡ç¥¨: {stock_code}")

            

            results = self.download_stock_reports(stock_code, years)

            

            # æ›´æ–°ç»Ÿè®¡

            for result in results:

                self.stats["details"].append(result)

                if result["status"] == "success":

                    self.stats["success"] += 1

                else:

                    self.stats["failed"] += 1

            

            # æ˜¾ç¤ºå½“å‰è¿›åº¦

            success_rate = (self.stats["success"] / (self.stats["success"] + self.stats["failed"])) * 100 if (self.stats["success"] + self.stats["failed"]) > 0 else 0

            print(f"  å½“å‰æˆåŠŸç‡ {success_rate:.1f}% ({self.stats['success']}/{self.stats['success'] + self.stats['failed']})")

            

            time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«

    

    def print_summary(self):

        """æ‰“å°ä¸‹è½½æ±‡æ€»æŠ¥å‘Š"""

        print("\n" + "=" * 60)

        print("ğŸ“ˆ ä¸‹è½½æ±‡æ€»æŠ¥å‘Š")

        print("=" * 60)

        

        print(f"æ€»è®¡ä»»åŠ¡: {self.stats['total']}")

        print(f"æˆåŠŸä¸‹è½½: {self.stats['success']}")

        print(f"å¤±è´¥ä»»åŠ¡: {self.stats['failed']}")

        

        if self.stats['total'] > 0:

            success_rate = (self.stats['success'] / self.stats['total']) * 100

            print(f"æˆåŠŸç‡ {success_rate:.1f}%")

        

        # æŒ‰çŠ¶æ€åˆ†ç»„ç»Ÿè®¡

        status_count = {}

        failed_details = []  # å­˜å‚¨å¤±è´¥è¯¦æƒ…

        

        for detail in self.stats["details"]:

            status = detail.get("status", "unknown")

            status_count[status] = status_count.get(status, 0) + 1

            

            # æ”¶é›†å¤±è´¥è¯¦æƒ…

            if status != "success":

                failed_details.append({

                    'stock_code': detail.get('stock_code', ''),

                    'company_name': detail.get('company_name', ''),

                    'year': detail.get('year', ''),

                    'status': status,

                    'error': detail.get('error', ''),

                    'title': detail.get('title', '')

                })

        

        if status_count:

            print(f"\nğŸ“Š è¯¦ç»†ç»Ÿè®¡:")

            for status, count in status_count.items():

                print(f"  {status}: {count}")

        

        # è¯¦ç»†åˆ—å‡ºå¤±è´¥ä»»åŠ¡

        if failed_details:

            print(f"\nå¤±è´¥ä»»åŠ¡è¯¦æƒ… ({len(failed_details)}ä¸ª):")

            

            # æŒ‰å¤±è´¥ç±»å‹åˆ†ç»„

            failure_groups = {}

            for failure in failed_details:

                status = failure['status']

                if status not in failure_groups:

                    failure_groups[status] = []

                failure_groups[status].append(failure)

            

            for status, failures in failure_groups.items():

                print(f"\nğŸ”¸ {status} ({len(failures)}ä¸ª):")

                for failure in failures:

                    stock_code = failure['stock_code']

                    company_name = failure.get('company_name', '')

                    year = failure['year']

                    

                    # æ„å»ºæ˜¾ç¤ºå­—ç¬¦ä¸²ï¼šè‚¡ç¥¨ä»£ç  + å…¬å¸åç§°ï¼ˆå¦‚æœæœ‰ï¼‰+ å¹´ä»½

                    if company_name:

                        stock_info = f"{stock_code} {company_name} {year}å¹´"

                    else:

                        stock_info = f"{stock_code} {year}å¹´"

                    

                    error_msg = failure['error']

                    if failure.get('title'):

                        print(f"  {stock_info}: {error_msg} (æ‰¾åˆ°æ ‡é¢˜: {failure['title'][:50]}...)")

                    else:

                        print(f"  {stock_info}: {error_msg}")

        

        # æˆåŠŸä»»åŠ¡åˆ—è¡¨ï¼ˆå¦‚æœä¸å¤šçš„è¯ï¼‰

        success_details = [d for d in self.stats["details"] if d.get("status") == "success"]

        if success_details and len(success_details) <= 10:  # åªæœ‰ä¸è¶…è¿‡10ä¸ªæˆåŠŸæ—¶æ‰æ˜¾ç¤º

            print(f"\næˆåŠŸä¸‹è½½è¯¦æƒ… ({len(success_details)}ä¸ª):")

            for success in success_details:

                stock_year = f"{success.get('stock_code', '')} {success.get('year', '')}"

                filename = success.get('filename', '')

                print(f"  {stock_year}: {filename}")

        

        print(f"\nğŸ“ ä¸‹è½½æ–‡ä»¶ä¿å­˜ç›®å½• {self.download_dir.absolute()}")

        print("================================================================")
        print('Annual Report Crawler - WebDriver "Otako" Version')
        print("Developed by Terence WANG")
        print("================================================================")
        print()

    def download_us_stock_10k_reports(self, stock_symbol, years):
        """
        ä¸‹è½½ç¾è‚¡10-Kå¹´æŠ¥
        
        Args:
            stock_symbol (str): ç¾è‚¡è‚¡ç¥¨ä»£ç ï¼Œå¦‚ 'AAPL', 'MSFT'
            years (list): å¹´ä»½åˆ—è¡¨ï¼Œå¦‚ [2023, 2022, 2021]
        
        Returns:
            List[Dict]: ä¸‹è½½ç»“æœåˆ—è¡¨ï¼Œä¸å…¶ä»–å‡½æ•°æ ¼å¼ä¸€è‡´
        """
        print(f"\nğŸ‡ºğŸ‡¸ å¼€å§‹ä¸‹è½½ç¾è‚¡ {stock_symbol} çš„10-Kå¹´æŠ¥...")
        
        # åˆ›å»ºUSæ–‡ä»¶å¤¹
        us_folder = os.path.join(self.download_dir, "US")
        if not os.path.exists(us_folder):
            os.makedirs(us_folder)
            print(f"    ğŸ“ åˆ›å»ºUSæ–‡ä»¶å¤¹: {us_folder}")
        
        results = []  # æ”¹ä¸ºåˆ—è¡¨æ ¼å¼ï¼Œä¸å…¶ä»–å‡½æ•°ä¿æŒä¸€è‡´
        successful_downloads = 0
        failed_downloads = 0
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šè·å–å…¬å¸CIK
            cik = self._get_us_stock_cik(stock_symbol)
            if not cik:
                print(f"    âŒ æ— æ³•æ‰¾åˆ°è‚¡ç¥¨ä»£ç  {stock_symbol} å¯¹åº”çš„CIK")
                # ä¸ºæ¯ä¸ªå¹´ä»½åˆ›å»ºå¤±è´¥è®°å½•
                for year in years:
                    results.append({
                        'stock_code': stock_symbol,
                        'year': year,
                        'status': 'failed',
                        'error': f'æ— æ³•æ‰¾åˆ°è‚¡ç¥¨ä»£ç  {stock_symbol} å¯¹åº”çš„CIK',
                        'filename': None
                    })
                return results
            
            print(f"    âœ“ æ‰¾åˆ°CIK: {cik}")
            
            # ç¬¬äºŒæ­¥ï¼šè·å–10-KæŠ¥å‘Šåˆ—è¡¨
            filings = self._get_us_10k_filings(cik, years)
            if not filings:
                print(f"    âŒ æœªæ‰¾åˆ°ä»»ä½•10-KæŠ¥å‘Š")
                for year in years:
                    results.append({
                        'stock_code': stock_symbol,
                        'year': year,
                        'status': 'failed',
                        'error': 'æœªæ‰¾åˆ°ä»»ä½•10-KæŠ¥å‘Š',
                        'filename': None
                    })
                return results
            
            print(f"    âœ“ æ‰¾åˆ° {len(filings)} ä¸ª10-KæŠ¥å‘Š")
            
            # ä¸ºæ¯ä¸ªè¯·æ±‚çš„å¹´ä»½åˆ›å»ºç»“æœè®°å½•
            filing_dict = {filing['year']: filing for filing in filings}
            
            # ç¬¬ä¸‰æ­¥ï¼šä¸‹è½½æ¯ä¸ªå¹´æŠ¥
            for year in years:
                if year in filing_dict:
                    filing = filing_dict[year]
                    try:
                        filing_date = filing['filing_date']
                        document_url = filing['document_url']
                        
                        print(f"    ğŸ“„ ä¸‹è½½ {year} å¹´10-KæŠ¥å‘Š...")
                        
                        # ä¸‹è½½HTMLå†…å®¹
                        html_content = self._download_us_filing_content(document_url)
                        if not html_content:
                            print(f"    âŒ {year} å¹´æŠ¥ä¸‹è½½å¤±è´¥")
                            results.append({
                                'stock_code': stock_symbol,
                                'year': year,
                                'status': 'failed',
                                'error': 'æ–‡æ¡£å†…å®¹ä¸‹è½½å¤±è´¥',
                                'filename': None
                            })
                            failed_downloads += 1
                            continue
                        
                        # ä¿å­˜æ–‡ä»¶ï¼ˆHTMLæ ¼å¼ï¼‰
                        filename = f"{stock_symbol}_{year}_10K_{filing_date}.html"
                        filepath = os.path.join(us_folder, filename)
                        
                        # ç›´æ¥ä¿å­˜ä¸ºHTML
                        success = self._save_us_filing_as_html(html_content, filepath, stock_symbol, year)
                        
                        if success:
                            print(f"    âœ… {year} å¹´æŠ¥ä¸‹è½½æˆåŠŸ: {filename}")
                            results.append({
                                'stock_code': stock_symbol,
                                'year': year,
                                'status': 'success',
                                'error': None,
                                'filename': filename
                            })
                            successful_downloads += 1
                        else:
                            print(f"    âŒ {year} å¹´æŠ¥ä¿å­˜å¤±è´¥")
                            results.append({
                                'stock_code': stock_symbol,
                                'year': year,
                                'status': 'failed',
                                'error': 'æ–‡ä»¶ä¿å­˜å¤±è´¥',
                                'filename': None
                            })
                            failed_downloads += 1
                            
                        # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                        time.sleep(0.5)
                        
                    except Exception as e:
                        print(f"    âŒ {year} å¹´æŠ¥å¤„ç†å¤±è´¥: {str(e)}")
                        results.append({
                            'stock_code': stock_symbol,
                            'year': year,
                            'status': 'failed',
                            'error': str(e),
                            'filename': None
                        })
                        failed_downloads += 1
                else:
                    # æœªæ‰¾åˆ°è¯¥å¹´ä»½çš„æŠ¥å‘Š
                    results.append({
                        'stock_code': stock_symbol,
                        'year': year,
                        'status': 'failed',
                        'error': f'æœªæ‰¾åˆ° {year} å¹´çš„10-KæŠ¥å‘Š',
                        'filename': None
                    })
                    failed_downloads += 1
            
        except Exception as e:
            print(f"    âŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            for year in years:
                results.append({
                    'stock_code': stock_symbol,
                    'year': year,
                    'status': 'failed',
                    'error': str(e),
                    'filename': None
                })
            failed_downloads = len(years)
        
        # è¾“å‡ºç»“æœç»Ÿè®¡
        print(f"\nğŸ“Š ç¾è‚¡ {stock_symbol} 10-Kå¹´æŠ¥ä¸‹è½½å®Œæˆ:")
        print(f"    âœ… æˆåŠŸä¸‹è½½: {successful_downloads} ä¸ª")
        print(f"    âŒ ä¸‹è½½å¤±è´¥: {failed_downloads} ä¸ª")
        
        return results
    
    def _get_us_stock_cik(self, stock_symbol):
        """è·å–ç¾è‚¡å…¬å¸çš„CIK"""
        try:
            # ä½¿ç”¨SECå…¬å¸tickeræ˜ å°„API
            url = "https://www.sec.gov/files/company_tickers.json"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                companies = response.json()
                
                # æŸ¥æ‰¾åŒ¹é…çš„è‚¡ç¥¨ä»£ç 
                for company_data in companies.values():
                    if company_data.get('ticker', '').upper() == stock_symbol.upper():
                        cik = str(company_data.get('cik_str', '')).zfill(10)
                        return cik
                        
        except Exception as e:
            print(f"    âš ï¸ è·å–CIKæ—¶å‡ºé”™: {str(e)}")
        
        return None
    
    def _get_us_10k_filings(self, cik, years):
        """è·å–æŒ‡å®šå¹´ä»½çš„10-KæŠ¥å‘Šåˆ—è¡¨"""
        try:
            # ä½¿ç”¨SEC submissions API
            url = f"https://data.sec.gov/submissions/CIK{cik}.json"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=15)
            if response.status_code != 200:
                return []
            
            data = response.json()
            filings_data = data.get('filings', {}).get('recent', {})
            
            if not filings_data:
                return []
            
            # è§£ææŠ¥å‘Šæ•°æ®
            forms = filings_data.get('form', [])
            filing_dates = filings_data.get('filingDate', [])
            accession_numbers = filings_data.get('accessionNumber', [])
            primary_documents = filings_data.get('primaryDocument', [])
            
            filings = []
            for i, form in enumerate(forms):
                if form == '10-K' and i < len(filing_dates):
                    filing_date = filing_dates[i]
                    year = int(filing_date.split('-')[0])
                    
                    if year in years:
                        accession_no = accession_numbers[i].replace('-', '')
                        primary_doc = primary_documents[i]
                        
                        # æ„å»ºæ–‡æ¡£URL
                        document_url = f"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_no}/{primary_doc}"
                        
                        filings.append({
                            'year': year,
                            'filing_date': filing_date,
                            'accession_number': accession_numbers[i],
                            'document_url': document_url,
                            'primary_document': primary_doc
                        })
            
            # æŒ‰å¹´ä»½æ’åº
            filings.sort(key=lambda x: x['year'], reverse=True)
            return filings
            
        except Exception as e:
            print(f"    âš ï¸ è·å–10-KæŠ¥å‘Šåˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
            return []
    
    def _download_us_filing_content(self, document_url):
        """é€šè¿‡æµè§ˆå™¨è·å–SECæ–‡æ¡£å†…å®¹"""
        try:
            if not self.driver:
                self.init_selenium_driver()
            
            print(f"    ğŸŒ è®¿é—®SECæ–‡æ¡£: {document_url}")
            self.driver.get(document_url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            time.sleep(3)
            
            # è·å–é¡µé¢HTMLå†…å®¹
            html_content = self.driver.page_source
            
            if html_content and len(html_content) > 1000:  # ç¡®ä¿è·å–åˆ°äº†æœ‰æ•ˆå†…å®¹
                return html_content
            else:
                print(f"    âš ï¸ è·å–åˆ°çš„å†…å®¹è¿‡çŸ­æˆ–ä¸ºç©º")
                return None
                
        except Exception as e:
            print(f"    âš ï¸ è·å–æ–‡æ¡£å†…å®¹æ—¶å‡ºé”™: {str(e)}")
            return None
    
    def _save_us_filing_as_html(self, html_content, filepath, stock_symbol, year):
        """å°†HTMLå†…å®¹ä¿å­˜ä¸ºHTMLæ–‡ä»¶"""
        try:
            # æ¸…ç†HTMLå†…å®¹
            cleaned_html = self._clean_html_for_pdf(html_content)
            
            # æ·»åŠ åŸºæœ¬æ ·å¼
            styled_html = f"""
            <!DOCTYPE html>
            <html>
            <head>
                <meta charset="utf-8">
                <title>{stock_symbol} {year} 10-K Annual Report</title>
                <style>
                    body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.4; }}
                    .header {{ text-align: center; margin-bottom: 30px; border-bottom: 2px solid #333; padding-bottom: 10px; }}
                    .content {{ max-width: 100%; }}
                    table {{ border-collapse: collapse; width: 100%; margin: 10px 0; }}
                    th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                    th {{ background-color: #f2f2f2; }}
                    .page-break {{ page-break-before: always; }}
                </style>
            </head>
            <body>
                <div class="header">
                    <h1>{stock_symbol} - 10-K Annual Report ({year})</h1>
                    <p>Downloaded from SEC EDGAR Database</p>
                </div>
                <div class="content">
                    {cleaned_html}
                </div>
            </body>
            </html>
            """
            
            # ç›´æ¥ä¿å­˜ä¸ºHTMLæ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(styled_html)
            return True
                    
        except Exception as e:
            print(f"    âš ï¸ ä¿å­˜HTMLæ—¶å‡ºé”™: {str(e)}")
            return False

    def _save_us_filing_as_pdf(self, html_content, filepath, stock_symbol, year):
        """å°†HTMLå†…å®¹ä¿å­˜ä¸ºPDF"""
        try:
            # æ¸…ç†HTMLå†…å®¹
            cleaned_html = self._clean_html_for_pdf(html_content)
            
            # æ·»åŠ åŸºæœ¬æ ·å¼
            styled_html = f"""
            <!DOCTYPE html>
            <html>
            <head>
                <meta charset="utf-8">
                <title>{stock_symbol} {year} 10-K Annual Report</title>
                <style>
                    body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.4; }}
                    .header {{ text-align: center; margin-bottom: 30px; border-bottom: 2px solid #333; padding-bottom: 10px; }}
                    .content {{ max-width: 100%; }}
                    table {{ border-collapse: collapse; width: 100%; margin: 10px 0; }}
                    th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                    th {{ background-color: #f2f2f2; }}
                    .page-break {{ page-break-before: always; }}
                </style>
            </head>
            <body>
                <div class="header">
                    <h1>{stock_symbol} - 10-K Annual Report ({year})</h1>
                    <p>Downloaded from SEC EDGAR Database</p>
                </div>
                <div class="content">
                    {cleaned_html}
                </div>
            </body>
            </html>
            """
            
            # ä½¿ç”¨pdfkitè½¬æ¢ä¸ºPDF
            try:
                import pdfkit
                
                # é…ç½®wkhtmltopdfè·¯å¾„ï¼ˆWindowsï¼‰
                config = pdfkit.configuration(wkhtmltopdf=r'C:\Program Files\wkhtmltopdf\bin\wkhtmltopdf.exe')
                
                options = {
                    'page-size': 'A4',
                    'margin-top': '0.75in',
                    'margin-right': '0.75in',
                    'margin-bottom': '0.75in',
                    'margin-left': '0.75in',
                    'encoding': "UTF-8",
                    'no-outline': None,
                    'enable-local-file-access': None
                }
                
                pdfkit.from_string(styled_html, filepath, options=options, configuration=config)
                return True
                
            except ImportError:
                print("    âš ï¸ pdfkitæœªå®‰è£…ï¼Œå°è¯•ä½¿ç”¨weasyprint...")
                try:
                    from weasyprint import HTML, CSS
                    HTML(string=styled_html).write_pdf(filepath)
                    return True
                except ImportError:
                    print("    âš ï¸ weasyprintä¹Ÿæœªå®‰è£…ï¼Œä¿å­˜ä¸ºHTMLæ–‡ä»¶...")
                    # å¦‚æœéƒ½æ²¡æœ‰å®‰è£…ï¼Œä¿å­˜ä¸ºHTML
                    html_filepath = filepath.replace('.pdf', '.html')
                    with open(html_filepath, 'w', encoding='utf-8') as f:
                        f.write(styled_html)
                    print(f"    ğŸ’¡ å·²ä¿å­˜ä¸ºHTMLæ–‡ä»¶: {html_filepath}")
                    return True
                    
        except Exception as e:
            print(f"    âš ï¸ ä¿å­˜PDFæ—¶å‡ºé”™: {str(e)}")
            return False
    
    def _clean_html_for_pdf(self, html_content):
        """æ¸…ç†HTMLå†…å®¹ä»¥ä¾¿è½¬æ¢ä¸ºPDF"""
        try:
            from bs4 import BeautifulSoup
            
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # ç§»é™¤è„šæœ¬å’Œæ ·å¼æ ‡ç­¾
            for script in soup(["script", "style"]):
                script.decompose()
            
            # ç§»é™¤ä¸€äº›å¯èƒ½å¯¼è‡´é—®é¢˜çš„å±æ€§
            for tag in soup.find_all():
                if tag.name:
                    # ä¿ç•™åŸºæœ¬å±æ€§ï¼Œç§»é™¤å¯èƒ½æœ‰é—®é¢˜çš„å±æ€§
                    attrs_to_keep = ['href', 'src', 'alt', 'title', 'colspan', 'rowspan']
                    new_attrs = {}
                    for attr in attrs_to_keep:
                        if attr in tag.attrs:
                            new_attrs[attr] = tag.attrs[attr]
                    tag.attrs = new_attrs
            
            # è·å–bodyå†…å®¹ï¼Œå¦‚æœæ²¡æœ‰bodyå°±è¿”å›å…¨éƒ¨
            body = soup.find('body')
            if body:
                return str(body)
            else:
                return str(soup)
                
        except Exception as e:
            print(f"    âš ï¸ æ¸…ç†HTMLæ—¶å‡ºé”™: {str(e)}")
            # å¦‚æœæ¸…ç†å¤±è´¥ï¼Œè¿”å›åŸå§‹å†…å®¹
            return html_content
    
    def enhanced_year_matching(self, title, target_year):
        """
        å¢å¼ºçš„å¹´ä»½åŒ¹é…å‡½æ•°ï¼Œæ”¯æŒæ•°å­—å’Œä¸­æ–‡å¹´ä»½æ ¼å¼
        
        Args:
            title (str): å…¬å‘Šæ ‡é¢˜
            target_year (int): ç›®æ ‡å¹´ä»½
            
        Returns:
            bool: æ˜¯å¦åŒ¹é…
        """
        if not title or not target_year:
            return False
        
        title_lower = title.lower()
        year_str = str(target_year)
        
        # 1. ç›´æ¥æ•°å­—åŒ¹é…
        if year_str in title:
            return True
        
        # 2. ä¸­æ–‡æ•°å­—æ˜ å°„
        chinese_digits = {
            '0': ['ã€‡', 'é›¶', 'O', 'o'],
            '1': ['ä¸€', 'å£¹'],
            '2': ['äºŒ', 'è´°', 'è²³'],
            '3': ['ä¸‰', 'å', 'åƒ'],
            '4': ['å››', 'è‚†'],
            '5': ['äº”', 'ä¼'],
            '6': ['å…­', 'é™†', 'é™¸'],
            '7': ['ä¸ƒ', 'æŸ’'],
            '8': ['å…«', 'æŒ'],
            '9': ['ä¹', 'ç–']
        }
        
        def generate_chinese_patterns(year_str):
            """é€’å½’ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ä¸­æ–‡æ•°å­—ç»„åˆ"""
            if not year_str:
                return ['']
            
            first_digit = year_str[0]
            rest_patterns = generate_chinese_patterns(year_str[1:])
            
            patterns = []
            for chinese_char in chinese_digits.get(first_digit, [first_digit]):
                for rest_pattern in rest_patterns:
                    patterns.append(chinese_char + rest_pattern)
            
            return patterns
        
        # 3. ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ä¸­æ–‡å¹´ä»½æ ¼å¼
        chinese_patterns = generate_chinese_patterns(year_str)
        
        for pattern in chinese_patterns:
            if pattern in title:
                return True
        
        # 4. æ¸¯è‚¡ç‰¹æ®Šæ ¼å¼åŒ¹é…
        hk_patterns = [
            f"{year_str}å¹´åº¦æŠ¥å‘Š",
            f"{year_str}å¹´å¹´åº¦æŠ¥å‘Š", 
            f"{year_str}å¹´æŠ¥",
            f"{year_str} annual report",
            f"annual report {year_str}",
            f"å¹´åº¦æŠ¥å‘Š{year_str}",
            f"ä¼ä¸šå¹´åº¦æŠ¥å‘Š{year_str}",
            f"hè‚¡å…¬å‘Šå¹´åº¦æŠ¥å‘Š{year_str}"
        ]
        
        for pattern in hk_patterns:
            if pattern in title_lower:
                return True
        
        # 5. ä¸­æ–‡å¹´ä»½ + å¹´åº¦æŠ¥å‘Šæ ¼å¼
        for pattern in chinese_patterns:
            chinese_year_patterns = [
                f"{pattern}å¹´åº¦æŠ¥å‘Š",
                f"{pattern}å¹´å¹´åº¦æŠ¥å‘Š",
                f"{pattern}å¹´æŠ¥",
                f"å¹´åº¦æŠ¥å‘Š{pattern}",
                f"ä¼ä¸šå¹´åº¦æŠ¥å‘Š{pattern}"
            ]
            
            for chinese_pattern in chinese_year_patterns:
                if chinese_pattern in title:
                    return True
        
        return False





def parse_year_range(year_str: str) -> List[int]:

    """

    è§£æå¹´ä»½èŒƒå›´å­—ç¬¦ä¸²

    

    Args:

        year_str: å¹´ä»½å­—ç¬¦ä¸²ï¼Œæ”¯æŒæ ¼å¼: "2020", "2020-2022", "2020,2021,2022"

        

    Returns:

        å¹´ä»½åˆ—è¡¨

    """

    years = []

    

    if '-' in year_str:

        # èŒƒå›´æ ¼å¼: 2020-2022

        start, end = year_str.split('-')

        years = list(range(int(start), int(end) + 1))

    elif ',' in year_str:

        # åˆ—è¡¨æ ¼å¼: 2020,2021,2022

        years = [int(y.strip()) for y in year_str.split(',')]

    else:

        # å•ä¸ªå¹´ä»½: 2020

        years = [int(year_str)]

    

    return years





def load_stock_codes_from_file(filepath: str) -> List[str]:
    """
    ä»æ–‡ä»¶åŠ è½½è‚¡ç¥¨ä»£ç åˆ—è¡¨
    
    Args:
        filepath: æ–‡ä»¶è·¯å¾„
        
    Returns:
        è‚¡ç¥¨ä»£ç åˆ—è¡¨
    """
    stock_codes = []
    
    try:
        # å°è¯•å¤šç§ç¼–ç æ–¹å¼
        encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312']
        content = None
        used_encoding = None
        
        for encoding in encodings:
            try:
                with open(filepath, 'r', encoding=encoding) as f:
                    content = f.read()
                used_encoding = encoding
                break
            except UnicodeDecodeError:
                continue
        
        if content is None:
            raise Exception("æ— æ³•è§£ç æ–‡ä»¶ï¼Œå°è¯•äº†å¤šç§ç¼–ç æ–¹å¼")
        
        for line in content.splitlines():
            code = line.strip()
            if code and not code.startswith('#'):  # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
                stock_codes.append(code)
        
        print(f"ğŸ”„ ä»æ–‡ä»¶{filepath} åŠ è½½äº†{len(stock_codes)} ä¸ªè‚¡ç¥¨ä»£ç  (ç¼–ç : {used_encoding})")
        
    except Exception as e:
        print(f"ğŸ”„ è¯»å–æ–‡ä»¶ {filepath} å¤±è´¥: {e}")
        sys.exit(1)
    
    return stock_codes





def main():
    # æ‰“å°æ¬¢è¿ä¿¡æ¯
    print("================================================================")
    print('Annual Report Crawler - WebDriver "Otako" Version')
    print("Developed by Terence WANG")
    print("================================================================")
    
    parser = argparse.ArgumentParser(description="å¹´æŠ¥ä¸‹è½½å™¨ï¼Œæ”¯æŒAè‚¡ã€æ¸¯è‚¡å’Œç¾è‚¡ã€‚")
    
    # æ·»åŠ å‚æ•°
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('-s', '--stock', type=str, help='è‚¡ç¥¨ä»£ç ï¼ˆAè‚¡6ä½ä»£ç æˆ–5ä½æ¸¯è‚¡ä»£ç ï¼‰')
    group.add_argument('-f', '--file', type=str, help='åŒ…å«è‚¡ç¥¨ä»£ç çš„æ–‡æœ¬æ–‡ä»¶è·¯å¾„')
    
    parser.add_argument('-y', '--years', type=str, required=True,
                       help='å¹´ä»½èŒƒå›´ï¼Œæ”¯æŒæ ¼å¼ 2020 | 2020-2022 | 2020,2021,2022')
    parser.add_argument('-d', '--dir', type=str, default='annual_reports',
                       help='ä¸‹è½½ç›®å½• (é»˜è®¤: annual_reports)')
    
    args = parser.parse_args()
    
    # è§£æå¹´ä»½
    try:
        years = parse_year_range(args.years)
        print(f"ğŸ“… ç›®æ ‡å¹´ä»½: {years}")
    except Exception as e:
        print(f"ğŸ”„ å¹´ä»½æ ¼å¼é”™è¯¯: {e}")
        sys.exit(1)
    
    # è·å–è‚¡ç¥¨ä»£ç åˆ—è¡¨
    if args.stock:
        stock_codes = [args.stock]
    else:
        stock_codes = load_stock_codes_from_file(args.file)
    
    if not stock_codes:
        print("ğŸ”„ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è‚¡ç¥¨ä»£ç ")
        sys.exit(1)
    
    # å¼€å§‹ä¸‹è½½
    with AnnualReportDownloader(args.dir) as downloader:
        downloader.process_stock_list(stock_codes, years)
        downloader.print_summary()





if __name__ == "__main__":

    main()

 