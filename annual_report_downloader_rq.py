#!/usr/bin/env python3

# -*- coding: utf-8 -*-

"""

Â∑®ÊΩÆÁΩëÂπ¥Êä•‰∏ãËΩΩÂô®

ÊîØÊåÅAËÇ°‰∏ªÊùø„ÄÅÁßëÂàõÊùø„ÄÅÂàõ‰∏öÊùøÂíåÊ∏ØËÇ°Âπ¥Êä•‰∏ãËΩΩ

"""



import os

import sys

import re

import json

import time

import requests

import argparse

from pathlib import Path

from typing import List, Dict, Tuple, Optional

from selenium import webdriver

from selenium.webdriver.common.by import By

from selenium.webdriver.support.ui import WebDriverWait

from selenium.webdriver.support import expected_conditions as EC

from selenium.webdriver.chrome.options import Options

from selenium.webdriver.chrome.service import Service

from selenium.common.exceptions import TimeoutException, NoSuchElementException

from webdriver_manager.chrome import ChromeDriverManager

import urllib.parse

from selenium.webdriver.common.keys import Keys





class StockType:

    """ËÇ°Á•®Á±ªÂûãÊûö‰∏æ"""

    A_MAIN = "AËÇ°‰∏ªÊùø"

    A_STAR = "AËÇ°ÁßëÂàõÊùø" 

    A_GEM = "AËÇ°Âàõ‰∏öÊùø"

    HK = "Ê∏ØËÇ°"

    US = "ÁæéËÇ°"

    UNKNOWN = "Êú™Áü•"





def enhanced_year_matching(title: str, target_years: List[int]) -> Optional[int]:
    """
    Â¢ûÂº∫ÁöÑÂπ¥‰ªΩÂåπÈÖçÂáΩÊï∞ÔºåÊîØÊåÅÊï∞Â≠óÂíå‰∏≠ÊñáÂπ¥‰ªΩÊ†ºÂºè
    
    Args:
        title: Ê†áÈ¢òÊñáÊú¨
        target_years: ÁõÆÊ†áÂπ¥‰ªΩÂàóË°®
        
    Returns:
        ÂåπÈÖçÂà∞ÁöÑÂπ¥‰ªΩÔºåÂ¶ÇÊûúÊú™ÂåπÈÖçËøîÂõûNone
    """
    # ‰∏≠ÊñáÊï∞Â≠óÊò†Â∞Ñ
    chinese_digits = {
        '0': ['„Äá', 'Èõ∂'],
        '1': ['‰∏Ä'],
        '2': ['‰∫å'], 
        '3': ['‰∏â'],
        '4': ['Âõõ'],
        '5': ['‰∫î'],
        '6': ['ÂÖ≠'],
        '7': ['‰∏É'],
        '8': ['ÂÖ´'],
        '9': ['‰πù']
    }
    
    for year in target_years:
        year_str = str(year)
        
        # Ê£ÄÊü•Êï∞Â≠óÊ†ºÂºè
        if year_str in title:
            return year
        
        # Ê£ÄÊü•‰∏≠ÊñáÊ†ºÂºè - ÁîüÊàêÊâÄÊúâÂèØËÉΩÁöÑ‰∏≠ÊñáÂπ¥‰ªΩÁªÑÂêà
        def generate_chinese_patterns(digits, pos=0, current=""):
            if pos == len(digits):
                if current in title:
                    return True
                return False
            
            digit = digits[pos]
            for chinese_char in chinese_digits[digit]:
                if generate_chinese_patterns(digits, pos + 1, current + chinese_char):
                    return True
            return False
        
        if generate_chinese_patterns(year_str):
            return year
    
    return None


class AnnualReportDownloader:

    """Âπ¥Êä•‰∏ãËΩΩÂô®‰∏ªÁ±ª"""

    

    def __init__(self, download_dir: str = "annual_reports"):

        """

        ÂàùÂßãÂåñ‰∏ãËΩΩÂô®

        

        Args:

            download_dir: ‰∏ãËΩΩÁõÆÂΩï

        """

        self.download_dir = Path(download_dir)

        self.download_dir.mkdir(exist_ok=True)

        

        # ÁªüËÆ°‰ø°ÊÅØ

        self.stats = {

            "total": 0,

            "success": 0,

            "failed": 0,

            "details": []

        }

        

        # ÂàùÂßãÂåñselenium driverÔºàÂª∂ËøüÂàùÂßãÂåñÔºâ

        self.driver = None

        

    def __enter__(self):

        return self

    

    def __del__(self):

        if self.driver:

            try:

                self.driver.quit()

            except:

                pass

    

    def __exit__(self, exc_type, exc_val, exc_tb):

        if self.driver:

            try:

                self.driver.quit()

            except:

                pass

    

    def init_selenium_driver(self):

        """ÂàùÂßãÂåñSelenium WebDriver"""

        if self.driver is None:

            # ChromeÈÄâÈ°πÈÖçÁΩÆ

            chrome_options = Options()

            chrome_options.add_argument('--headless')  # Êó†Â§¥Ê®°Âºè

            chrome_options.add_argument('--no-sandbox')

            chrome_options.add_argument('--disable-dev-shm-usage')

            chrome_options.add_argument('--disable-gpu')  # Á¶ÅÁî®GPUÂä†ÈÄü

            chrome_options.add_argument('--disable-web-security')  # Á¶ÅÁî®webÂÆâÂÖ®

            chrome_options.add_argument('--disable-features=VizDisplayCompositor')  # Á¶ÅÁî®ÊòæÁ§∫ÂêàÊàê

            chrome_options.add_argument('--disable-extensions')  # Á¶ÅÁî®Êâ©Â±ï

            chrome_options.add_argument('--disable-plugins')  # Á¶ÅÁî®Êèí‰ª∂

            chrome_options.add_argument('--disable-images')  # Á¶ÅÁî®ÂõæÁâáÂä†ËΩΩ
            # Ëß£ÂÜ≥WebGLË≠¶Âëä
            chrome_options.add_argument('--disable-webgl')
            chrome_options.add_argument('--disable-webgl2')
            chrome_options.add_argument('--disable-3d-apis')
            chrome_options.add_argument('--disable-accelerated-2d-canvas')
            chrome_options.add_argument('--disable-accelerated-jpeg-decoding')
            chrome_options.add_argument('--disable-accelerated-mjpeg-decode')
            chrome_options.add_argument('--disable-accelerated-video-decode')
            chrome_options.add_argument('--disable-gpu-sandbox')
            chrome_options.add_argument('--disable-software-rasterizer')
            chrome_options.add_argument('--disable-background-timer-throttling')
            chrome_options.add_argument('--disable-renderer-backgrounding')
            chrome_options.add_argument('--disable-features=TranslateUI')
            chrome_options.add_argument('--disable-ipc-flooding-protection')

            chrome_options.add_argument('--log-level=3')  # Âè™ÊòæÁ§∫Ëá¥ÂëΩÈîôËØØ

            chrome_options.add_argument('--silent')  # ÈùôÈªòÊ®°Âºè

            chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])  # ÊéíÈô§Êó•ÂøóÂºÄÂÖ≥

            chrome_options.add_experimental_option('useAutomationExtension', False)  # Á¶ÅÁî®Ëá™Âä®ÂåñÊâ©Â±ï

            chrome_options.add_argument('--disable-blink-features=AutomationControlled')  # Á¶ÅÁî®Ëá™Âä®ÂåñÊéßÂà∂ÁâπÂæÅ

            

            # ËÆæÁΩÆ‰∏ãËΩΩË∑ØÂæÑ

            prefs = {

                "download.default_directory": str(self.download_dir.absolute()),

                "download.prompt_for_download": False,

                "download.directory_upgrade": True,

                "safebrowsing.enabled": True

            }

            chrome_options.add_experimental_option("prefs", prefs)

            

            # Â∞ùËØïÂ§öÁßçÊñπÂºèÂàùÂßãÂåñChromeDriver

            try:

                # ÊñπÊ≥ï1: ‰ΩøÁî®ÂΩìÂâçÁõÆÂΩï‰∏ãÁöÑChromeDriver

                local_chromedriver = Path("./chromedriver.exe")

                if local_chromedriver.exists():

                    print("  üîß ‰ΩøÁî®ÂΩìÂâçÁõÆÂΩï‰∏ãÁöÑChromeDriver...")

                    service = Service(str(local_chromedriver.absolute()))

                    self.driver = webdriver.Chrome(service=service, options=chrome_options)

                    print("üîß Selenium WebDriver ÂàùÂßãÂåñÊàêÂäü(Êú¨Âú∞Êñá‰ª∂)")

                else:

                    raise Exception("Êú¨Âú∞ChromeDriver‰∏çÂ≠òÂú®")

                

            except Exception as e1:

                print(f"  Êú¨Âú∞ChromeDriverÂ§±Ë¥•: {e1}")

                try:

                    # ÊñπÊ≥ï2: ‰ΩøÁî®webdriver-managerËá™Âä®ÁÆ°ÁêÜChromeDriver

                    print("  üîß Â∞ùËØïËá™Âä®‰∏ãËΩΩ/Êõ¥Êñ∞ChromeDriver...")

                    service = Service(ChromeDriverManager().install())

                    self.driver = webdriver.Chrome(service=service, options=chrome_options)

                    print("üîß Selenium WebDriver ÂàùÂßãÂåñÊàêÂäü(Ëá™Âä®ÁÆ°ÁêÜ)")

                    

                except Exception as e2:

                    print(f"  Ëá™Âä®ÁÆ°ÁêÜChromeDriverÂ§±Ë¥•: {e2}")

                    try:

                        # ÊñπÊ≥ï3: ‰ΩøÁî®Á≥ªÁªüPATH‰∏≠ÁöÑChromeDriver

                        print("  üîß Â∞ùËØï‰ΩøÁî®Á≥ªÁªüPATH‰∏≠ÁöÑChromeDriver...")

                        self.driver = webdriver.Chrome(options=chrome_options)

                        print("üîß Selenium WebDriver ÂàùÂßãÂåñÊàêÂäü(Á≥ªÁªüPATH)")

                        

                    except Exception as e3:

                        print(f"ÊâÄÊúâChromeDriverÂàùÂßãÂåñÊñπÂºèÈÉΩÂ§±Ë¥•:")

                        print(f"  Êú¨Âú∞Êñá‰ª∂: {e1}")

                        print(f"  Ëá™Âä®ÁÆ°ÁêÜ: {e2}")

                        print(f"  Á≥ªÁªüPATH: {e3}")

                        print("\nËß£ÂÜ≥ÊñπÊ°à:")

                        print("1. Á°Æ‰øùÂ∑≤ÂÆâË£ÖChromeÊµèËßàÂô®")

                        print("2. Á°Æ‰øùchromedriver.exeÂú®ÂΩìÂâçÁõÆÂΩïÊàñÁ≥ªÁªüPATH")

                        print("3. Ê£ÄÊü•ChromeDriverÁâàÊú¨ÊòØÂê¶‰∏éChromeÁâàÊú¨ÂåπÈÖç")

                        print("ChromeDriver‰∏ãËΩΩÂú∞ÂùÄ: https://chromedriver.chromium.org/")

                        return False

        return True

    

    def identify_stock_type(self, stock_code: str) -> str:
        """
        ËØÜÂà´ËÇ°Á•®Á±ªÂûã
        
        Args:
            stock_code: ËÇ°Á•®‰ª£Á†Å
            
        Returns:
            ËÇ°Á•®Á±ªÂûã
        """
        stock_code = stock_code.strip().upper()
        
        # Ê∏ØËÇ°Ôºö5‰ΩçÊï∞Â≠óÊàñÂ∏¶HKÂâçÁºÄ
        if re.match(r'^\d{5}$', stock_code) or stock_code.startswith('HK'):
            return StockType.HK
        
        # AËÇ°Ôºö6‰ΩçÊï∞
        if re.match(r'^\d{6}$', stock_code):
            # ÁßëÂàõÊùøÔºö688ÂºÄÂ§¥
            if stock_code.startswith('688'):
                return StockType.A_STAR
            # Âàõ‰∏öÊùøÔºö300ÂºÄÂ§¥ 
            elif stock_code.startswith('300'):
                return StockType.A_GEM
            # ‰∏ªÊùøÔºöÂÖ∂‰ªñ6‰ΩçÊï∞
            else:
                return StockType.A_MAIN
        
        # ÁæéËÇ°ÔºöÂ≠óÊØçÂºÄÂ§¥ÁöÑËÇ°Á•®‰ª£Á†ÅÔºà1-5‰∏™Â≠óÁ¨¶Ôºâ
        if re.match(r'^[A-Z]{1,5}$', stock_code):
            return StockType.US
        
        return StockType.UNKNOWN

    

    def get_orgid_dict_szse(self) -> Dict[str, str]:

        """

        Ëé∑ÂèñÊ∑±Âú≥‰∫§ÊòìÊâÄÊâÄÊúâËÇ°Á•®ÁöÑorgIdÂ≠óÂÖ∏

        

        Returns:

            ËÇ°Á•®‰ª£Á†ÅÂà∞orgIdÁöÑÊò†Â∞ÑÂ≠óÂÖ∏

        """

        try:

            print("    üîÑ Ê≠£Âú®Ëé∑ÂèñÊ∑±Âú≥‰∫§ÊòìÊâÄËÇ°Á•®orgIdÊò†Â∞ÑË°®..")

            response = requests.get("http://www.cninfo.com.cn/new/data/szse_stock.json", timeout=15)

            response.raise_for_status()

            

            org_dict = {}

            stock_list = response.json().get("stockList", [])

            

            for stock_info in stock_list:

                code = stock_info.get("code")

                org_id = stock_info.get("orgId")

                if code and org_id:

                    org_dict[code] = org_id

            

            print(f"    üîÑ Ëé∑Âèñ‰∫Ü{len(org_dict)} ‰∏™Ê∑±Âú≥‰∫§ÊòìÊâÄËÇ°Á•®ÁöÑorgId")

            return org_dict

            

        except Exception as e:

            print(f"    ‚úó Ëé∑ÂèñÊ∑±Âú≥‰∫§ÊòìÊâÄorgIdÊò†Â∞ÑË°®Â§±Ë¥•: {e}")

            return {}

    

    def get_orgid_dict_sse(self) -> Dict[str, str]:

        """

        Ëé∑Âèñ‰∏äÊµ∑‰∫§ÊòìÊâÄÊâÄÊúâËÇ°Á•®ÁöÑorgIdÂ≠óÂÖ∏

        

        Returns:

            ËÇ°Á•®‰ª£Á†ÅÂà∞orgIdÁöÑÊò†Â∞ÑÂ≠óÂÖ∏

        """

        try:

            print("    üîÑ Ê≠£Âú®Ëé∑Âèñ‰∏äÊµ∑‰∫§ÊòìÊâÄËÇ°Á•®orgIdÊò†Â∞ÑË°®..")

            response = requests.get("http://www.cninfo.com.cn/new/data/sse_stock.json", timeout=15)

            response.raise_for_status()

            

            org_dict = {}

            stock_list = response.json().get("stockList", [])

            

            for stock_info in stock_list:

                code = stock_info.get("code")

                org_id = stock_info.get("orgId")

                if code and org_id:

                    org_dict[code] = org_id

            

            print(f"    üîÑ Ëé∑Âèñ‰∫Ü{len(org_dict)} ‰∏™‰∏äÊµ∑‰∫§ÊòìÊâÄËÇ°Á•®ÁöÑorgId")

            return org_dict

            

        except Exception as e:

            print(f"    ‚úó Ëé∑Âèñ‰∏äÊµ∑‰∫§ÊòìÊâÄorgIdÊò†Â∞ÑË°®Â§±Ë¥•: {e}")

            return {}

    

    def get_all_orgid_dict(self) -> Dict[str, str]:

        """

        Ëé∑ÂèñÊâÄÊúâ‰∫§ÊòìÊâÄËÇ°Á•®ÁöÑorgIdÂ≠óÂÖ∏

        Ê≥®ÊÑèÔºöÊ∑±Âú≥‰∫§ÊòìÊâÄÁöÑÊï∞ÊçÆÂÆûÈôÖÂåÖÂê´‰∫ÜÊâÄÊúâËÇ°Á•®ÔºàÂåÖÊã¨‰∏äÊµ∑‰∫§ÊòìÊâÄÔºâ

        

        Returns:

            ËÇ°Á•®‰ª£Á†ÅÂà∞orgIdÁöÑÊò†Â∞ÑÂ≠óÂÖ∏

        """

        # Ê∑±Âú≥‰∫§ÊòìÊâÄÁöÑÊï∞ÊçÆÂåÖÂê´‰∫ÜÊâÄÊúâËÇ°Á•®

        all_dict = self.get_orgid_dict_szse()

        

        print(f"    üìä ÊÄªËÆ°Ëé∑Âèñ‰∫Ü{len(all_dict)} ‰∏™ËÇ°Á•®ÁöÑorgId")

        return all_dict

    

    def get_orgid_for_stock(self, stock_code: str) -> Optional[str]:

        """

        Ëé∑ÂèñËÇ°Á•®ÁöÑorgId

        

        Args:

            stock_code: ËÇ°Á•®‰ª£Á†Å

            

        Returns:

            orgIdÂ≠óÁ¨¶‰∏≤ÔºåÂ¶ÇÊûúËé∑ÂèñÂ§±Ë¥•ËøîÂõûNone

        """

        try:

            # È¶ñÂÖàÂ∞ùËØï‰ªéÊò†Â∞ÑË°®Ëé∑ÂèñorgId

            all_orgid_dict = self.get_all_orgid_dict()

            if stock_code in all_orgid_dict:

                org_id = all_orgid_dict[stock_code]

                print(f"    üîÑ ‰ªéÊò†Â∞ÑË°®Ëé∑Âèñ‰∫Ü{stock_code} ÁöÑorgId: {org_id}")

                return org_id

            

            # Â¶ÇÊûúÊò†Â∞ÑË°®‰∏≠Ê≤°ÊúâÔºåÂ∞ùËØïÈÄöËøáÊêúÁ¥¢APIËé∑Âèñ

            print(f"    üîç Êò†Â∞ÑË°®‰∏≠Êú™ÊâæÂà∞{stock_code}ÔºåÂ∞ùËØïÊêúÁ¥¢Ëé∑ÂèñorgId...")

            

            # ‰ΩøÁî®ËÇ°Á•®‰ª£Á†ÅÊêúÁ¥¢ÔºàÈÄöËøásearchkeyÔºâ

            api_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"

            headers = {

                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'

            }

            

            params = {

                "stock": "",

                "tabName": "fulltext",

                "pageSize": 50,

                "pageNum": 1,

                "column": "",

                "category": "",

                "plate": "",

                "seDate": "2020-01-01~2025-12-31",

                "searchkey": stock_code,

                "secid": "",

                "sortName": "pubdate",

                "sortType": "desc",

                "isHLtitle": "true"

            }

            

            response = requests.post(api_url, headers=headers, data=params, timeout=15)

            if response.status_code == 200:

                result = response.json()

                announcements = result.get('announcements', [])

                

                if announcements:

                    # Êü•ÊâæÂåπÈÖçÁöÑËÇ°Á•®‰ª£Á†Å

                    for ann in announcements:

                        sec_code = ann.get('secCode', '')

                        org_id = ann.get('orgId', '')

                        

                        if sec_code == stock_code and org_id:

                            print(f"    üîÑ ÈÄöËøáÊêúÁ¥¢Ëé∑Âèñ‰∫Ü{stock_code} ÁöÑorgId: {org_id}")

                            return org_id

            

            print(f"    ‚úó Êó†Ê≥ïËé∑Âèñ{stock_code} ÁöÑorgId")

            return None

            

        except Exception as e:

            print(f"    ‚úó Ëé∑Âèñ {stock_code} orgId Êó∂Âá∫Èîô: {e}")

            return None

    

    def download_a_stock_main_reports_with_pagination(self, stock_code: str, years: List[int]) -> List[Dict]:
        """
        ‰∏ãËΩΩAËÇ°‰∏ªÊùøÂπ¥Êä•Ôºà‰ΩøÁî®API + ÁøªÈ°µÊîØÊåÅÔºâ
        
        Args:
            stock_code: ËÇ°Á•®‰ª£Á†Å
            years: Âπ¥‰ªΩÂàóË°®
            
        Returns:
            ‰∏ãËΩΩÁªìÊûúÂàóË°®
        """
        results = []
        
        try:
            print(f"  üì• ‰ΩøÁî®Â∑®ÊΩÆAPIÊü•Êâæ {stock_code} Âπ¥Êä•ÔºàÊîØÊåÅÁøªÈ°µÔºâ...")
            
            api_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            # Á°ÆÂÆöÊùøÂùóÂíåorgId
            if stock_code.startswith('60') or stock_code.startswith('688'):
                plate = 'sse'  # ‰∏äÊµ∑‰∫§ÊòìÊâÄÔºö‰∏ªÊùø(60xxxx) + ÁßëÂàõÊùø(688xxx)
            else:
                plate = 'szse'  # Ê∑±Âú≥‰∫§ÊòìÊâÄÔºö‰∏ªÊùø(000xxx) + Âàõ‰∏öÊùø(300xxx)
            category = 'category_ndbg_szsh;'
            
            # ‰ªéÊò†Â∞ÑË°®Ëé∑ÂèñÁúüÂÆûÁöÑorgId
            real_org_id = self.get_orgid_for_stock(stock_code)
            if not real_org_id:
                print(f"  ‚úó Êó†Ê≥ïËé∑Âèñ{stock_code} ÁöÑorgId")
                for year in years:
                    results.append({
                        'stock_code': stock_code,
                        'year': year,
                        'status': 'no_orgid',
                        'error': 'Êó†Ê≥ïËé∑ÂèñorgId'
                    })
                return results
            
            # ËÆæÁΩÆÊêúÁ¥¢Êó•ÊúüËåÉÂõ¥ÔºàÂπ¥Êä•ÈÄöÂ∏∏Âú®Ê¨°Âπ¥-4ÊúàÂèëÂ∏ÉÔºâ
            min_year = min(years)
            max_year = max(years)
            search_start_date = f"{min_year}-01-01"
            search_end_date = f"{max_year + 1}-04-30"
            
            params = {
                "stock": f"{stock_code},{real_org_id}",
                "tabName": "fulltext",
                "pageSize": 50,
                "pageNum": 1,
                "column": plate,
                "category": category,
                "plate": plate,
                "seDate": f"{search_start_date}~{search_end_date}",
                "searchkey": "",
                "secid": "",
                "sortName": "pubdate",
                "sortType": "desc",
                "isHLtitle": "true"
            }
            
            # ÊîØÊåÅÁøªÈ°µÊêúÁ¥¢ÔºåÊúÄÂ§öÊêúÁ¥¢Ââç3È°µ
            all_announcements = []
            for page_num in range(1, 4):
                params["pageNum"] = page_num
                print(f"    üîç ÊêúÁ¥¢Á¨¨{page_num}È°µ...")
                
                response = requests.post(api_url, headers=headers, data=params, timeout=20)
                response.raise_for_status()
                data = response.json()
                
                announcements = data.get('announcements', [])
                if announcements:
                    all_announcements.extend(announcements)
                    print(f"    Á¨¨{page_num}È°µÊâæÂà∞{len(announcements)}Êù°ÂÖ¨Âëä")
                else:
                    print(f"    Á¨¨{page_num}È°µÊó†ÁªìÊûúÔºåÂÅúÊ≠¢ÁøªÈ°µ")
                    break
            
            if not all_announcements:
                print(f"  ‚úó Êú™ÊâæÂà∞{stock_code} ÁöÑÁõ∏ÂÖ≥Êä•Âëä")
                for year in years:
                    results.append({
                        'stock_code': stock_code,
                        'year': year,
                        'status': 'not_found',
                        'error': 'Êú™ÊâæÂà∞Áõ∏ÂÖ≥Êä•Âëä'
                    })
                return results
            
            print(f"  üìä ÊÄªÂÖ±ÊâæÂà∞{len(all_announcements)}Êù°ÂÖ¨Âëä")
            
            # ÊåâÂπ¥‰ªΩÊü•ÊâæÂπ¥Êä•
            for year in years:
                print(f"    üîç Êü•Êâæ {year} Âπ¥Âπ¥Êä•..")
                found = False
                
                for ann in all_announcements:
                    title = ann.get('announcementTitle', '')
                    
                    # Ë∑≥ËøáÊëòË¶Å„ÄÅË°•ÂÖÖ„ÄÅÊõ¥Ê≠£Á≠âÈùûÊ≠£ÂºèÂπ¥Êä•
                    if any(keyword in title for keyword in ["ÊëòË¶Å", "ÂèñÊ∂à", "Ë°•ÂÖÖ", "Êõ¥Ê≠£", "Á¨¨‰∏ÄÂ≠£Â∫¶", "ÂçäÂπ¥", "Á¨¨‰∏âÂ≠£Â∫¶"]):
                        continue
                    
                    # ‰ΩøÁî®Â¢ûÂº∫ÁöÑÂπ¥‰ªΩÂåπÈÖçÊ£ÄÊü•ÊòØÂê¶‰∏∫ÊåáÂÆöÂπ¥‰ªΩÁöÑÂπ¥Â∫¶Êä•Âëä
                    matched_year = enhanced_year_matching(title, [year])
                    if matched_year and "Âπ¥Â∫¶Êä•Âëä" in title:
                        print(f"    üîÑ ÊâæÂà∞Âπ¥Êä•: {title}")
                        
                        # ‰∏ãËΩΩPDF
                        adj_url = ann.get('adjunctUrl', '')
                        if adj_url:
                            pdf_url = f"http://static.cninfo.com.cn/{adj_url}"
                            stock_name = ann.get('secName', stock_code)
                            filename = f"{stock_code}_{stock_name}_{year}Âπ¥Êä•.pdf"
                            
                            filepath = self.download_dir / filename
                            if self.download_pdf(pdf_url, str(filepath)):
                                print(f"    ‚úì ÊàêÂäü‰∏ãËΩΩ: {filename}")
                                results.append({
                                    'stock_code': stock_code,
                                    'year': year,
                                    'status': 'success',
                                    'filename': filename,
                                    'title': title
                                })
                                found = True
                                break
                            else:
                                results.append({
                                    'stock_code': stock_code,
                                    'year': year,
                                    'status': 'download_failed',
                                    'error': '‰∏ãËΩΩPDFÂ§±Ë¥•'
                                })
                                found = True
                                break
                
                if not found:
                    print(f"    ‚úó Êú™ÊâæÂà∞{stock_code} {year}Âπ¥Âπ¥Êä•")
                    results.append({
                        'stock_code': stock_code,
                        'year': year,
                        'status': 'not_found',
                        'error': 'Êú™ÊâæÂà∞Âπ¥Êä•'
                    })
                
                time.sleep(0.5)  # Áü≠ÊöÇÈó¥Èöî
                
        except Exception as e:
            print(f"  ‚úó AËÇ°‰∏ªÊùøAPIÂ§ÑÁêÜÂ§±Ë¥•: {e}")
            for year in years:
                results.append({
                    'stock_code': stock_code,
                    'year': year,
                    'status': 'error',
                    'error': str(e)
                })
        
        return results

    def download_a_stock_main_reports(self, stock_code: str, years: List[int]) -> List[Dict]:

        """

        ‰∏ãËΩΩAËÇ°‰∏ªÊùøÂπ¥Êä•Ôºà‰ΩøÁî®APIÔºâ

        

        Args:

            stock_code: ËÇ°Á•®‰ª£Á†Å

            years: Âπ¥‰ªΩÂàóË°®

            

        Returns:

            ‰∏ãËΩΩÁªìÊûúÂàóË°®

        """

        results = []

        

        try:

            print(f"  üì• ‰ΩøÁî®Â∑®ÊΩÆAPIÊü•Êâæ {stock_code} Âπ¥Êä•...")

            

            api_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"

            headers = {

                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'

            }

            

            # Á°ÆÂÆöÊùøÂùóÂíåorgId

            if stock_code.startswith('60') or stock_code.startswith('688'):

                plate = 'sse'  # ‰∏äÊµ∑‰∫§ÊòìÊâÄÔºö‰∏ªÊùø(60xxxx) + ÁßëÂàõÊùø(688xxx)

            else:

                plate = 'szse'  # Ê∑±Âú≥‰∫§ÊòìÊâÄÔºö‰∏ªÊùø(000xxx) + Âàõ‰∏öÊùø(300xxx)

            category = 'category_ndbg_szsh;'

            

            # ‰ªéÊò†Â∞ÑË°®Ëé∑ÂèñÁúüÂÆûÁöÑorgId

            real_org_id = self.get_orgid_for_stock(stock_code)

            if not real_org_id:

                print(f"  ‚úó Êó†Ê≥ïËé∑Âèñ{stock_code} ÁöÑorgId")

                for year in years:

                    results.append({

                        'stock_code': stock_code,

                        'year': year,

                        'status': 'no_orgid',

                        'error': 'Êó†Ê≥ïËé∑ÂèñorgId'

                    })

                return results

            

            # ËÆæÁΩÆÊêúÁ¥¢Êó•ÊúüËåÉÂõ¥ÔºàÂπ¥Êä•ÈÄöÂ∏∏Âú®Ê¨°Âπ¥-4ÊúàÂèëÂ∏ÉÔºâ

            min_year = min(years)

            max_year = max(years)

            search_start_date = f"{min_year}-01-01"

            search_end_date = f"{max_year + 1}-04-30"

            

            params = {

                "stock": f"{stock_code},{real_org_id}",

                "tabName": "fulltext",

                "pageSize": 50,

                "pageNum": 1,

                "column": plate,

                "category": category,

                "plate": plate,

                "seDate": f"{search_start_date}~{search_end_date}",

                "searchkey": "",

                "secid": "",

                "sortName": "pubdate",

                "sortType": "desc",

                "isHLtitle": "true"

            }

            

            response = requests.post(api_url, headers=headers, data=params, timeout=20)

            response.raise_for_status()

            data = response.json()

            

            if not data.get('announcements'):

                print(f"  ‚úó Êú™ÊâæÂà∞{stock_code} ÁöÑÁõ∏ÂÖ≥Êä•Âëä")

                for year in years:

                    results.append({

                        'stock_code': stock_code,

                        'year': year,

                        'status': 'not_found',

                        'error': 'Êú™ÊâæÂà∞Áõ∏ÂÖ≥Êä•Âëä'

                    })

                return results

            

            # ÊåâÂπ¥‰ªΩÊü•ÊâæÂπ¥Êä•

            for year in years:

                print(f"    üîç Êü•Êâæ {year} Âπ¥Âπ¥Êä•..")

                found = False

                

                for ann in data['announcements']:

                    title = ann.get('announcementTitle', '')

                    

                    # Ë∑≥ËøáÊëòË¶Å„ÄÅË°•ÂÖÖ„ÄÅÊõ¥Ê≠£Á≠âÈùûÊ≠£ÂºèÂπ¥Êä•

                    if any(keyword in title for keyword in ["ÊëòË¶Å", "ÂèñÊ∂à", "Ë°•ÂÖÖ", "Êõ¥Ê≠£", "Á¨¨‰∏ÄÂ≠£Â∫¶", "ÂçäÂπ¥", "Á¨¨‰∏âÂ≠£Â∫¶"]):

                        continue

                    

                    # ‰ΩøÁî®Â¢ûÂº∫ÁöÑÂπ¥‰ªΩÂåπÈÖçÊ£ÄÊü•ÊòØÂê¶‰∏∫ÊåáÂÆöÂπ¥‰ªΩÁöÑÂπ¥Â∫¶Êä•Âëä

                    matched_year = enhanced_year_matching(title, [year])

                    if matched_year and "Âπ¥Â∫¶Êä•Âëä" in title:

                        print(f"    üîÑ ÊâæÂà∞Âπ¥Êä•: {title}")

                        

                        # ‰∏ãËΩΩPDF

                        adj_url = ann.get('adjunctUrl', '')

                        if adj_url:

                            pdf_url = f"http://static.cninfo.com.cn/{adj_url}"

                            stock_name = ann.get('secName', stock_code)

                            filename = f"{stock_code}_{stock_name}_{year}Âπ¥Êä•.pdf"

                            

                            filepath = self.download_dir / filename
                            if self.download_pdf(pdf_url, str(filepath)):

                                print(f"    ‚úì ÊàêÂäü‰∏ãËΩΩ: {filename}")

                                results.append({

                                    'stock_code': stock_code,

                                    'year': year,

                                    'status': 'success',

                                    'filename': filename,

                                    'title': title

                                })

                                found = True

                                break

                            else:

                                results.append({

                                    'stock_code': stock_code,

                                    'year': year,

                                    'status': 'download_failed',

                                    'error': '‰∏ãËΩΩPDFÂ§±Ë¥•'

                                })

                                found = True

                                break

                

                if not found:

                    print(f"    ‚úó Êú™ÊâæÂà∞{stock_code} {year}Âπ¥Âπ¥Êä•")

                    results.append({

                        'stock_code': stock_code,

                        'year': year,

                        'status': 'not_found',

                        'error': 'Êú™ÊâæÂà∞Âπ¥Êä•'

                    })

                

                time.sleep(0.5)  # Áü≠ÊöÇÈó¥Èöî

                

        except Exception as e:

            print(f"  ‚úó AËÇ°‰∏ªÊùøAPIÂ§ÑÁêÜÂ§±Ë¥•: {e}")

            for year in years:

                results.append({

                    'stock_code': stock_code,

                    'year': year,

                    'status': 'error',

                    'error': str(e)

                })

        

        return results

    

    def download_a_stock_with_selenium(self, stock_code: str, years: List[int], stock_type: str) -> List[Dict]:

        """

        ‰ΩøÁî®Selenium‰∏ãËΩΩAËÇ°ÁßëÂàõÊùø/Âàõ‰∏öÊùøÂπ¥Êä•

        

        Args:

            stock_code: ËÇ°Á•®‰ª£Á†Å

            years: Âπ¥‰ªΩÂàóË°®

            stock_type: ËÇ°Á•®Á±ªÂûã

            

        Returns:

            ‰∏ãËΩΩÁªìÊûúÂàóË°®

        """

        results = []

        

        if not self.init_selenium_driver():

            return [{'stock_code': stock_code, 'year': 'all', 'status': 'selenium_init_failed', 'error': 'SeleniumÂàùÂßãÂåñÂ§±Ë¥•'}]

        

        try:

            # Ëé∑ÂèñorgId - ‰ΩøÁî®Â∑®ÊΩÆÁΩëÁöÑorgIdÊò†Â∞ÑË°®

            print(f"  üîç Ê≠£Âú®Ëé∑Âèñ {stock_code} ÁöÑorgId...")

            

            # È¶ñÂÖàÂ∞ùËØï‰ªéÂÆåÊï¥Êò†Â∞ÑË°®Ëé∑ÂèñorgId

            print(f"    üí° Â∞ùËØï‰ªéÂ∑®ÊΩÆÁΩëÊò†Â∞ÑË°®Ëé∑ÂèñorgId")

            all_orgid_dict = self.get_all_orgid_dict()

            org_id = all_orgid_dict.get(stock_code)

            

            if org_id:

                print(f"    ‰ªéÊò†Â∞ÑË°®Ëé∑ÂèñÂà∞orgId: {org_id}")

            else:

                print(f"    ‚ö†Ô∏è Êò†Â∞ÑË°®‰∏≠Êú™ÊâæÂà∞{stock_code}")

                # Â¶ÇÊûúÊò†Â∞ÑË°®‰∏≠Ê≤°ÊúâÔºåÂ∞ùËØïËßÑÂæãÁîüÊàêÔºà‰ªÖÁî®‰∫éAËÇ°‰∏ªÊùøÔºâ

                if stock_type == StockType.A_MAIN:

                    if stock_code.startswith('60'):

                        org_id = f"gssh0{stock_code}"

                        print(f"    üí° Â∞ùËØï‰∏äÊµ∑‰∏ªÊùøËßÑÂæãÁîüÊàê: {org_id}")

                    else:

                        org_id = f"gssz0{stock_code}"

                        print(f"    üí° Â∞ùËØïÊ∑±Âú≥‰∏ªÊùøËßÑÂæãÁîüÊàê: {org_id}")

                else:

                    # ÂÖ∂‰ªñÊÉÖÂÜµÂ∞ùËØïÈÄöÁî®API

                    print(f"    üîÑ ‰ΩøÁî®ÈÄöÁî®APIËé∑Âèñ...")

                    org_id = self.get_orgid_for_stock(stock_code)

            

            if not org_id:

                return [{'stock_code': stock_code, 'year': 'all', 'status': 'orgid_failed', 'error': 'Êó†Ê≥ïËé∑ÂèñorgId'}]

                

            print(f"  üîÑ ÊúÄÁªà‰ΩøÁî®orgId: {org_id}")

            

            # ËÆøÈóÆËÇ°Á•®È°µÈù¢

            url = f"https://www.cninfo.com.cn/new/disclosure/stock?stockCode={stock_code}&orgId={org_id}&sjstsBond=false#periodicReports"

            print(f"  üåê ËÆøÈóÆÈ°µÈù¢: {url}")

            

            self.driver.get(url)

            time.sleep(3)

            

            # Á≠âÂæÖÈ°µÈù¢Âä†ËΩΩÔºàÂ¢ûÂä†Á≠âÂæÖÊó∂Èó¥Âπ∂Â∞ùËØïÂ§öÁßçÂÖÉÁ¥†Ê£ÄÊµãÔºâ

            try:

                print("  üîÑ Á≠âÂæÖÈ°µÈù¢Âä†ËΩΩ...")

                # Â∞ùËØïÁ≠âÂæÖÂ§öÁßçÂèØËÉΩÁöÑÈ°µÈù¢ÂÖÉÁ¥†

                WebDriverWait(self.driver, 20).until(

                    lambda driver: driver.execute_script("return document.readyState") == "complete"

                )

                time.sleep(5)  # È¢ùÂ§ñÁ≠âÂæÖÈ°µÈù¢ÂÜÖÂÆπÂä†ËΩΩ

                print("üîÑ È°µÈù¢Âä†ËΩΩÂÆåÊàê")

            except TimeoutException:

                print(f"üîÑ È°µÈù¢Âä†ËΩΩË∂ÖÊó∂ÔºåÂ∞ùËØïÁªßÁª≠...")

                # Âç≥‰ΩøË∂ÖÊó∂‰πüÂ∞ùËØïÁªßÁª≠Êìç‰Ωú

            

            # ËÆæÁΩÆÊêúÁ¥¢ÂèÇÊï∞ - ÊØè‰∏™Âπ¥‰ªΩÂçïÁã¨ÊêúÁ¥¢ÔºåÊèêÈ´òÊïàÁéá

            for year in years:

                print(f"  üì• Ê≠£Âú®ÊêúÁ¥¢ {stock_code} {year}Âπ¥Âπ¥Êä•..")

                

                try:

                    # ÈáçÊñ∞ËÆøÈóÆÈ°µÈù¢ÔºåÁ°Æ‰øùÁä∂ÊÄÅÂπ≤ÂáÄ

                    self.driver.get(url)

                    time.sleep(3)

                    

                    # Ê∏ØËÇ°È°µÈù¢Ôºö‰ΩøÁî®Á≤æÁ°ÆÊêúÁ¥¢

                    print(f"    üîç ‰ΩøÁî®Á≤æÁ°ÆÊêúÁ¥¢: {year}Âπ¥Â∫¶Êä•Âëä...")

                    

                    # Êü•ÊâæÊêúÁ¥¢Ê°Ü - ‰ºòÂÖàÊâæÊ†áÈ¢òÂÖ≥ÈîÆÂ≠óÊêúÁ¥¢

                    search_selectors = [

                        "input[placeholder*='Ê†áÈ¢òÂÖ≥ÈîÆÂ≠ó']",

                        "input[placeholder*='ÊêúÁ¥¢']", 

                        "input[type='text'][placeholder*='ÂÖ≥ÈîÆ']",

                        ".search input",

                        "[class*='search'] input"

                    ]

                    

                    search_box = None

                    for selector in search_selectors:

                        try:

                            search_box = self.driver.find_element(By.CSS_SELECTOR, selector)

                            if search_box and search_box.is_displayed():

                                print(f"    ÊâæÂà∞ÊêúÁ¥¢Ê°Ü: {selector}")

                                break

                        except:

                            continue

                    

                    # ËÆæÁΩÆÊó•ÊúüÁ≠õÈÄâÂô® - Âπ¥Êä•ÈÄöÂ∏∏Âú®Ê¨°Âπ¥ÂèëÂ∏É

                    # ÊöÇÊó∂Á¶ÅÁî®Êó•ÊúüÁ≠õÈÄâÂô®ÔºåÂõ†‰∏∫ÁïåÈù¢ÂÖÉÁ¥†ÂèØËÉΩÂèëÁîüÂèòÂåñ

                    print(f"    üóìüîÑ Ë∑≥ËøáÊó•ÊúüÁ≠õÈÄâÂô®ËÆæÁΩÆÔºå‰æùÈù†ÊêúÁ¥¢ÂÖ≥ÈîÆËØçÁ≠õÈÄâ...")

                    

                    # TODO: ‰ª•‰∏ãÊó•ÊúüÁ≠õÈÄâÂô®‰ª£Á†ÅÊöÇÊó∂Ê≥®ÈáäÔºåÁ≠âÁ°ÆËÆ§ÁïåÈù¢ÂÖÉÁ¥†ÂêéÂÜçÂêØÁî®

                    # try:

                    #     # Âπ¥Êä•Âú®Ê¨°Âπ¥ÂèëÂ∏ÉÔºåËÆæÁΩÆÊ¨°Âπ¥ÁöÑÊó•ÊúüËåÉÂõ¥

                    #     start_year = year + 1

                    #     end_year = year + 1

                    #     

                    #     start_date_selectors = [

                    #         "input[placeholder*='ÂºÄÂßãÊó•Êúü']",

                    #         "input[placeholder*='Ëµ∑Âßã']", 

                    #         ".date-picker input:first-child",

                    #         ".start-date input"

                    #     ]

                    #     

                    #     end_date_selectors = [

                    #         "input[placeholder*='ÁªìÊùüÊó•Êúü']",

                    #         "input[placeholder*='ÁªàÊ≠¢']",

                    #         ".date-picker input:last-child", 

                    #         ".end-date input"

                    #     ]

                    #     

                    #     # ËÆæÁΩÆËµ∑ÂßãÊó•Êúü

                    #     for start_sel in start_date_selectors:

                    #         try:

                    #             start_input = self.driver.find_element(By.CSS_SELECTOR, start_sel)

                    #             if start_input and start_input.is_displayed():

                    #                 start_input.clear()

                    #                 start_date = f"{start_year}-01-01"

                    #                 start_input.send_keys(start_date)

                    #                 print(f"    ËÆæÁΩÆËµ∑ÂßãÊó•Êúü: {start_date}")

                    #                 break

                    #         except:

                    #             continue

                    #     

                    #     # ËÆæÁΩÆÁªìÊùüÊó•Êúü  

                    #     for end_sel in end_date_selectors:

                    #         try:

                    #             end_input = self.driver.find_element(By.CSS_SELECTOR, end_sel)

                    #             if end_input and end_input.is_displayed():

                    #                 end_input.clear()

                    #                 end_date = f"{end_year}-12-31"

                    #                 end_input.send_keys(end_date)

                    #                 print(f"    ËÆæÁΩÆÁªìÊùüÊó•Êúü: {end_date}")

                    #                 break

                    #         except:

                    #             continue

                    #             

                    # except Exception as e:

                    #     print(f"    Êó•ÊúüÁ≠õÈÄâÂô®ËÆæÁΩÆÂ§±Ë¥•: {e}")

                    

                    if search_box:

                        # Ê∏ÖÁ©∫ÊêúÁ¥¢Ê°ÜÂπ∂ËæìÂÖ•Á≤æÁ°ÆÁöÑÊêúÁ¥¢ÂÖ≥ÈîÆËØç

                        search_box.clear()

                        # ‰ΩøÁî®Âπ¥‰ªΩ+Âπ¥Â∫¶Êä•ÂëäÁöÑÁ≤æÁ°ÆÊêúÁ¥¢ÔºåÂ§ßÂπÖÂáèÂ∞ëÁªìÊûúÊï∞Èáè

                        search_keywords = f"{year}Âπ¥Â∫¶Êä•Âëä"

                        search_box.send_keys(search_keywords)

                        print(f"    ËæìÂÖ•Á≤æÁ°ÆÊêúÁ¥¢ÂÖ≥ÈîÆËØç: {search_keywords}")

                        

                        # ÁÇπÂáªÊêúÁ¥¢ÊåâÈíÆ

                        search_btn_selectors = [

                            "button[class*='Êü•ËØ¢']",

                            "button[class*='search']", 

                            ".search button",

                            "[class*='search'] button",

                            "button[type='submit']",

                            "input[type='submit']"

                        ]

                        

                        search_clicked = False

                        for btn_selector in search_btn_selectors:

                            try:

                                search_btn = self.driver.find_element(By.CSS_SELECTOR, btn_selector)

                                if search_btn and search_btn.is_displayed():

                                    search_btn.click()

                                    print(f"    ÁÇπÂáªÊêúÁ¥¢ÊåâÈíÆ: {btn_selector}")

                                    search_clicked = True

                                    break

                            except:

                                continue

                        

                        if not search_clicked:

                            # Â¶ÇÊûúÊâæ‰∏çÂà∞ÊêúÁ¥¢ÊåâÈíÆÔºåÂ∞ùËØïÊåâÂõûËΩ¶ÈîÆ

                            search_box.send_keys(Keys.ENTER)

                            print(f"    ÊåâÂõûËΩ¶ÈîÆÊêúÁ¥¢")

                        

                        time.sleep(5)  # Á≠âÂæÖÊêúÁ¥¢ÁªìÊûúÂä†ËΩΩ

                    else:

                        print(f"    ‚ö†Ô∏è Êú™ÊâæÂà∞ÊêúÁ¥¢Ê°ÜÔºåË∑≥ËøáÊ≠§Âπ¥‰ªΩ")

                        results.append({

                            'stock_code': stock_code,

                            'year': year,

                            'status': 'search_failed',

                            'error': 'Êú™ÊâæÂà∞ÊêúÁ¥¢Ê°Ü'

                        })

                        continue

                    

                    # Êü•ÊâæÊêúÁ¥¢ÁªìÊûúË°®Ê†º - Á≤æÁ°ÆÊêúÁ¥¢ÂêéÂ∫îËØ•ÁªìÊûúÂæàÂ∞ë

                    table_selectors = [

                        "table tbody tr",

                        ".disclosure-table tbody tr", 

                        "[class*='table'] tbody tr",

                        "tr"

                    ]

                    

                    rows = []

                    for selector in table_selectors:

                        try:

                            rows = self.driver.find_elements(By.CSS_SELECTOR, selector)

                            if rows:

                                print(f"    Á≤æÁ°ÆÊêúÁ¥¢ÂêéÊâæÂà∞{len(rows)} Ë°åÊï∞")

                                break

                        except:

                            continue

                    

                    # Á≤æÁ°ÆÊêúÁ¥¢ÂêéÔºåÂè™ÈúÄÊ£ÄÊü•Ââç10Ë°åÁªìÊûú

                    found_report = False

                    

                    if rows:

                        print(f"    Ê£ÄÊü•Ââç50Ë°åÁ≤æÁ°ÆÊêúÁ¥¢ÁªìÊûú...")

                        

                        for i, row in enumerate(rows[:50]):  # Ê£ÄÊü•Ââç50Ë°å

                            try:

                                print(f"    Ê≠£Âú®Ëß£ÊûêÁ¨¨{i+1} Ë°å...")

                                

                                # ÂÖàÊü•ÁúãË°®Ê†ºÁªìÊûú

                                tds = row.find_elements(By.CSS_SELECTOR, "td")

                                print(f"      Á¨¨{i+1} Ë°åÊúâ {len(tds)} Âàó")

                                

                                # Â∞ùËØïËé∑ÂèñÊâÄÊúâÂàóÁöÑÊñáÊú¨ÂÜÖÂÆπ

                                row_texts = []

                                for j, td in enumerate(tds):

                                    text = td.text.strip()

                                    if text:

                                        row_texts.append(f"Âàó{j+1}: {text[:50]}")

                                

                                if row_texts:

                                    print(f"      Ë°åÂÜÖÂÆπ: {' | '.join(row_texts)}")

                                

                                # ÁÆÄÂåñÈÄâÊã©Âô®ÔºåÂè™‰ΩøÁî®ÊúÄÂü∫Êú¨ÁöÑÈÄâÊã©Âô®

                                title = ""

                                date = ""

                                title_element = None

                                

                                # Â∞ùËØïÂ§öÁßçÊñπÂºèËé∑ÂèñÊ†áÈ¢ò

                                try:

                                    # ÊñπÊ≥ï1: Êü•ÊâæÈìæÊé•

                                    title_element = row.find_element(By.CSS_SELECTOR, "td a")

                                    title = title_element.text.strip()

                                    print(f"      ÊâæÂà∞Ê†áÈ¢òÈìæÊé•: {title[:40]}...")

                                except:

                                    try:

                                        # ÊñπÊ≥ï2: Êü•Êâæ‰ªª‰ΩïÈìæÊé•

                                        title_element = row.find_element(By.CSS_SELECTOR, "a")

                                        title = title_element.text.strip()

                                        print(f"      ÊâæÂà∞ÈìæÊé•: {title[:40]}...")

                                    except:

                                        try:

                                            # ÊñπÊ≥ï3: Â¶ÇÊûúÊ≤°ÊúâÈìæÊé•ÔºåÂèñÁ¨¨‰∫åÂàóÁöÑÊñáÊú¨(ÈÄöÂ∏∏ÊòØÊ†áÈ¢òÂàó)

                                            if len(tds) >= 2:

                                                title = tds[1].text.strip()

                                                if title:

                                                    print(f"      ÊâæÂà∞ÊñáÊú¨Ê†áÈ¢ò: {title[:40]}...")

                                                    # ÂØªÊâæËØ•Ë°å‰∏≠ÁöÑÈìæÊé•ÂÖÉÁ¥†

                                                    try:

                                                        title_element = tds[1].find_element(By.CSS_SELECTOR, "a")

                                                    except:

                                                        title_element = None

                                        except:

                                            print(f"      Á¨¨{i+1} Ë°åÊó†Ê≥ïËé∑ÂèñÊ†áÈ¢ò")

                                            continue

                                

                                if not title:

                                    print(f"      Á¨¨{i+1} Ë°åÊ†áÈ¢ò‰∏∫Á©∫ÔºåË∑≥Ëøá")

                                    continue

                                    

                                # ÊòæÁ§∫ÊâÄÊúâÊù°ÁõÆÔºå‰æø‰∫éË∞ÉËØï

                                print(f"    [{i+1}] Ê†áÈ¢ò: {title[:60]}... Êó•Êúü: {date}")

                                

                                # ‰∏•Ê†ºÁöÑÂπ¥Êä•ÂåπÈÖçÊù°‰ª∂

                                is_annual_report = (

                                    str(year) in title and 

                                    ('Âπ¥Â∫¶Êä•Âëä' in title or 'Âπ¥Êä•' in title or 'Annual Report' in title.title()) and

                                    'ÊëòË¶Å' not in title and  # ÊéíÈô§ÊëòË¶Å

                                    'ÁõëÁÆ°' not in title and  # ÊéíÈô§ÁõëÁÆ°

                                    'ÂõûÂ§ç' not in title and  # ÊéíÈô§ÂõûÂ§ç

                                    'ÈóÆËØ¢' not in title and  # ÊéíÈô§ÈóÆËØ¢

                                    'ÂêÑÁßçÂáΩ‰ª∂' not in title and    # ÊéíÈô§ÂêÑÁßçÂáΩ‰ª∂

                                    'ÂÆ°ËÆ°ÊÑèËßÅ' not in title and  # ÊéíÈô§ÂÆ°ËÆ°ÊÑèËßÅ

                                    'Êõ¥Ê≠£' not in title and  # ÊéíÈô§Êõ¥Ê≠£ÂÖ¨Âëä

                                    'Ë°•ÂÖÖ' not in title and  # ÊéíÈô§Ë°•ÂÖÖÂÖ¨Âëä

                                    'ÂÖ≥‰∫éxxÂπ¥Êä•ÁöÑÂÖ¨Âëä' not in title and  # ÊéíÈô§"ÂÖ≥‰∫éxxÂπ¥Êä•ÁöÑÂÖ¨Âëä"

                                    'Ëá™ÊÑøÊÄßÊä´Èú≤ÂÖ¨Âëä' not in title and  # ÊéíÈô§Ëá™ÊÑøÊÄßÊä´Èú≤ÂÖ¨Âëä

                                    'Ëã±Êñá' not in title and  # ÊéíÈô§Ëã±Êñá

                                    'ÁÆÄÊä•' not in title     # ÊéíÈô§ÁÆÄÊä•

                                )

                                

                                if is_annual_report:

                                    print(f"    üîÑ ÊâæÂà∞Âπ¥Êä•: {title}")

                                    

                                    # ÁßëÂàõÊùø/Âàõ‰∏öÊùø/Ê∏ØËÇ°ÔºöËé∑ÂèñÈìæÊé•hrefÂπ∂ËÆøÈóÆËØ¶ÊÉÖÈ°µ

                                    if title_element:

                                        # Ëé∑ÂèñÈìæÊé•ÁöÑhrefÂ±ûÊÄß

                                        try:

                                            detail_href = title_element.get_attribute('href')

                                            print(f"      ÈìæÊé•href: {detail_href}")

                                            

                                            if detail_href:

                                                # Áõ¥Êé•ËÆøÈóÆËØ¶ÊÉÖÈ°µ

                                                self.driver.get(detail_href)

                                                time.sleep(3)

                                                

                                                # Ëé∑ÂèñÂΩìÂâçÈ°µÈù¢URL

                                                detail_url = self.driver.current_url

                                                print(f"      ËØ¶ÊÉÖÈ°µURL: {detail_url}")

                                            else:

                                                # Â¶ÇÊûúÊ≤°ÊúâhrefÔºåÂ∞ùËØïÁÇπÂáª

                                                title_element.click()

                                                time.sleep(3)

                                                detail_url = self.driver.current_url

                                                print(f"      ËØ¶ÊÉÖÈ°µURL: {detail_url}")

                                        except:

                                            # Â§áÁî®ÊñπÊ°àÔºöÁõ¥Êé•ÁÇπÂáª

                                            title_element.click()

                                            time.sleep(3)

                                            detail_url = self.driver.current_url

                                            print(f"      ËØ¶ÊÉÖÈ°µURL: {detail_url}")

                                        

                                        # ‰ªéURL‰∏≠ÊèêÂèñannouncementIdÂíåannouncementTime

                                        try:

                                            from urllib.parse import urlparse, parse_qs

                                            parsed_url = urlparse(detail_url)

                                            query_params = parse_qs(parsed_url.query)

                                            

                                            announcement_id = query_params.get('announcementId', [None])[0]

                                            announcement_time = query_params.get('announcementTime', [None])[0]

                                            

                                            if announcement_id and announcement_time:

                                                # ‰ªéannouncementTime‰∏≠Âè™ÊèêÂèñÊó•ÊúüÈÉ®ÂàÜÔºàÂéªÊéâÊó∂Èó¥Ôºâ

                                                announcement_date = announcement_time.split(' ')[0] if ' ' in announcement_time else announcement_time

                                                

                                                # ÊûÑÈÄ†PDF‰∏ãËΩΩURL

                                                pdf_url = f"https://static.cninfo.com.cn/finalpage/{announcement_date}/{announcement_id}.PDF"

                                                print(f"      ÊûÑÈÄ†PDF‰∏ãËΩΩÈìæÊé•: {pdf_url}")

                                                

                                                # Â∞ùËØïËé∑ÂèñËÇ°Á•®ÂêçÁß∞Ôºà‰ªéÊ†áÈ¢ò‰∏≠ÊèêÂèñÔºâ
                                                company_name = stock_code  # ÈªòËÆ§‰ΩøÁî®ËÇ°Á•®‰ª£Á†Å
                                                try:
                                                    # ‰ªéÊ†áÈ¢ò‰∏≠ÊèêÂèñÂÖ¨Âè∏ÂêçÁß∞
                                                    if "Ôºö" in title:
                                                        company_name = title.split("Ôºö")[0].strip()
                                                    elif title.startswith("ÂÖ≥‰∫é"):
                                                        # Â§ÑÁêÜ"ÂÖ≥‰∫éXXXÂÖ¨Âè∏"Ê†ºÂºè
                                                        parts = title.split("Âπ¥Â∫¶Êä•Âëä")
                                                        if len(parts) > 0:
                                                            name_part = parts[0].replace("ÂÖ≥‰∫é", "").replace(f"{year}", "").strip()
                                                            if name_part:
                                                                company_name = name_part
                                                except:
                                                    pass
                                                
                                                # ÊûÑÈÄ†Êñá‰ª∂Âêç
                                                filename = f"{stock_code}_{company_name}_{year}Âπ¥Êä•.pdf"

                                                

                                                # ‰ΩøÁî®requests‰∏ãËΩΩPDF

                                                filepath = self.download_dir / filename
                                                download_success = self.download_pdf(pdf_url, str(filepath))

                                                

                                                if download_success:

                                                    print(f"    ÊàêÂäü‰∏ãËΩΩ: {filename}")

                                                    results.append({

                                                        'stock_code': stock_code,

                                                        'year': year,

                                                        'status': 'success',

                                                        'filename': filename,

                                                        'title': title,

                                                        'pdf_url': pdf_url

                                                    })

                                                else:

                                                    print(f"üîÑ ‰∏ãËΩΩÂ§±Ë¥•: {filename}")

                                                    results.append({

                                                        'stock_code': stock_code,

                                                        'year': year,

                                                        'status': 'download_failed',

                                                        'error': f'PDF‰∏ãËΩΩÂ§±Ë¥•: {pdf_url}',

                                                        'title': title

                                                    })

                                            else:

                                                print(f"      ‚ö†Ô∏è Êó†Ê≥ï‰ªéURL‰∏≠ÊèêÂèñÂøÖË¶ÅÂèÇÊï∞")

                                                results.append({

                                                    'stock_code': stock_code,

                                                    'year': year,

                                                    'status': 'url_parse_failed',

                                                    'error': 'Êó†Ê≥ïËß£ÊûêËØ¶ÊÉÖÈ°µURLÂèÇÊï∞',

                                                    'title': title

                                                })

                                        except Exception as url_error:

                                            print(f"      üîÑ URLËß£ÊûêÂá∫Èîô: {url_error}")

                                            results.append({

                                                'stock_code': stock_code,

                                                'year': year,

                                                'status': 'url_error',

                                                'error': str(url_error),

                                                'title': title

                                            })

                                        

                                        found_report = True

                                        break

                                    

                            except Exception as e:

                                print(f"    Ëß£ÊûêÁ¨¨{i+1}Ë°åÊó∂Âá∫Èîô: {e}")

                                continue

                    

                    # Ëß£ÊûêÊêúÁ¥¢ÁªìÊûú
                    if not found_report:
                        # Â¶ÇÊûúÂâç50Ë°åÊ≤°ÊâæÂà∞ÔºåÂ∞ùËØïÁøªÈ°µÊêúÁ¥¢
                        print(f"    üîÑ Ââç50Ë°åÊú™ÊâæÂà∞Âπ¥Êä•ÔºåÂ∞ùËØïÁøªÈ°µÊêúÁ¥¢...")
                        
                        # Â∞ùËØïÁøªÈ°µÔºåÊúÄÂ§öÁøª3È°µ
                        for page_num in range(2, 5):  # Á¨¨2È°µÂà∞Á¨¨4È°µ
                            try:
                                # Êü•Êâæ‰∏ã‰∏ÄÈ°µÊåâÈíÆ
                                next_page_selectors = [
                                    f"a[title='Á¨¨{page_num}È°µ']",
                                    f"a[data-page='{page_num}']",
                                    f".page-item:nth-child({page_num + 1}) a",
                                    f".pagination a:contains('{page_num}')",
                                    f"a:contains('Á¨¨{page_num}È°µ')",
                                    f"a:contains('{page_num}')"
                                ]
                                
                                next_button = None
                                for selector in next_page_selectors:
                                    try:
                                        next_button = self.driver.find_element(By.CSS_SELECTOR, selector)
                                        if next_button and next_button.is_displayed() and next_button.is_enabled():
                                            print(f"      ÊâæÂà∞Á¨¨{page_num}È°µÊåâÈíÆ: {selector}")
                                            break
                                    except:
                                        continue
                                
                                if not next_button:
                                    print(f"      Êú™ÊâæÂà∞Á¨¨{page_num}È°µÊåâÈíÆÔºåÂÅúÊ≠¢ÁøªÈ°µ")
                                    break
                                
                                # ÁÇπÂáªÁøªÈ°µ
                                self.driver.execute_script("arguments[0].click();", next_button)
                                time.sleep(3)
                                
                                print(f"      Â∑≤ÁøªÂà∞Á¨¨{page_num}È°µÔºåÈáçÊñ∞ÊêúÁ¥¢...")
                                
                                # ÈáçÊñ∞Ëé∑ÂèñË°®Ê†ºË°å
                                rows = self.driver.find_elements(By.CSS_SELECTOR, "tbody tr, .table tr, tr")
                                if not rows:
                                    print(f"      Á¨¨{page_num}È°µÊó†Êï∞ÊçÆ")
                                    continue
                                
                                # Ê£ÄÊü•Ëøô‰∏ÄÈ°µÁöÑÂâç20Ë°å
                                for i, row in enumerate(rows[:20]):
                                    try:
                                        # Ëé∑ÂèñÊ†áÈ¢ò
                                        title = ""
                                        title_element = None
                                        
                                        try:
                                            title_element = row.find_element(By.CSS_SELECTOR, "td a")
                                            title = title_element.text.strip()
                                        except:
                                            try:
                                                title_element = row.find_element(By.CSS_SELECTOR, "a")
                                                title = title_element.text.strip()
                                            except:
                                                tds = row.find_elements(By.CSS_SELECTOR, "td")
                                                if len(tds) >= 2:
                                                    title = tds[1].text.strip()
                                                    try:
                                                        title_element = tds[1].find_element(By.CSS_SELECTOR, "a")
                                                    except:
                                                        title_element = None
                                        
                                        if not title:
                                            continue
                                        
                                        # Âπ¥Êä•ÂåπÈÖçÊ£ÄÊü•
                                        is_annual_report = (
                                            str(year) in title and 
                                            ('Âπ¥Â∫¶Êä•Âëä' in title or 'Âπ¥Êä•' in title or 'Annual Report' in title.title()) and
                                            'ÊëòË¶Å' not in title and 'ÁõëÁÆ°' not in title and 'ÂõûÂ§ç' not in title and 
                                            'ÈóÆËØ¢' not in title and 'ÂêÑÁßçÂáΩ‰ª∂' not in title and 'ÂÆ°ËÆ°ÊÑèËßÅ' not in title and 
                                            'Êõ¥Ê≠£' not in title and 'Ë°•ÂÖÖ' not in title and 'ÂÖ≥‰∫éxxÂπ¥Êä•ÁöÑÂÖ¨Âëä' not in title and 
                                            'Ëá™ÊÑøÊÄßÊä´Èú≤ÂÖ¨Âëä' not in title and 'Ëã±Êñá' not in title and 'ÁÆÄÊä•' not in title
                                        )
                                        
                                        if is_annual_report:
                                            print(f"      üéâ Á¨¨{page_num}È°µÊâæÂà∞Âπ¥Êä•: {title}")
                                            found_report = True
                                            
                                            # Â§ÑÁêÜ‰∏ãËΩΩÈÄªËæëÔºàÂ§çÁî®‰πãÂâçÁöÑ‰ª£Á†ÅÔºâ
                                            if title_element:
                                                try:
                                                    detail_href = title_element.get_attribute('href')
                                                    if detail_href:
                                                        self.driver.get(detail_href)
                                                        time.sleep(3)
                                                        detail_url = self.driver.current_url
                                                        
                                                        # Ëß£ÊûêURLÂèÇÊï∞Âπ∂‰∏ãËΩΩÔºàÂ§çÁî®‰πãÂâçÁöÑÈÄªËæëÔºâ
                                                        from urllib.parse import urlparse, parse_qs
                                                        parsed_url = urlparse(detail_url)
                                                        query_params = parse_qs(parsed_url.query)
                                                        
                                                        if 'announcementId' in query_params and 'orgId' in query_params:
                                                            announcement_id = query_params['announcementId'][0]
                                                            org_id_param = query_params['orgId'][0]
                                                            
                                                            pdf_url = f"http://static.cninfo.com.cn/finalpage/{announcement_id}.PDF"
                                                            
                                                            # Â∞ùËØïËé∑ÂèñËÇ°Á•®ÂêçÁß∞Ôºà‰ªéÊ†áÈ¢ò‰∏≠ÊèêÂèñÔºâ
                                                            company_name = stock_code  # ÈªòËÆ§‰ΩøÁî®ËÇ°Á•®‰ª£Á†Å
                                                            try:
                                                                # ‰ªéÊ†áÈ¢ò‰∏≠ÊèêÂèñÂÖ¨Âè∏ÂêçÁß∞
                                                                if "Ôºö" in title:
                                                                    company_name = title.split("Ôºö")[0].strip()
                                                                elif title.startswith("ÂÖ≥‰∫é"):
                                                                    # Â§ÑÁêÜ"ÂÖ≥‰∫éXXXÂÖ¨Âè∏"Ê†ºÂºè
                                                                    parts = title.split("Âπ¥Â∫¶Êä•Âëä")
                                                                    if len(parts) > 0:
                                                                        name_part = parts[0].replace("ÂÖ≥‰∫é", "").replace(f"{year}", "").strip()
                                                                        if name_part:
                                                                            company_name = name_part
                                                            except:
                                                                pass
                                                            
                                                            filename = f"{stock_code}_{company_name}_{year}Âπ¥Êä•.pdf"
                                                            filepath = self.download_dir / filename
                                                            
                                                            if self.download_pdf(pdf_url, str(filepath)):
                                                                print(f"      ‚úì ÁøªÈ°µÊàêÂäü‰∏ãËΩΩ: {filename}")
                                                                results.append({
                                                                    'stock_code': stock_code,
                                                                    'year': year,
                                                                    'status': 'success',
                                                                    'filename': filename,
                                                                    'title': title,
                                                                    'pdf_url': pdf_url
                                                                })
                                                            else:
                                                                results.append({
                                                                    'stock_code': stock_code,
                                                                    'year': year,
                                                                    'status': 'download_failed',
                                                                    'error': f'PDF‰∏ãËΩΩÂ§±Ë¥•: {pdf_url}',
                                                                    'title': title
                                                                })
                                                        else:
                                                            results.append({
                                                                'stock_code': stock_code,
                                                                'year': year,
                                                                'status': 'url_parse_failed',
                                                                'error': 'Êó†Ê≥ïËß£ÊûêËØ¶ÊÉÖÈ°µURLÂèÇÊï∞',
                                                                'title': title
                                                            })
                                                except Exception as e:
                                                    results.append({
                                                        'stock_code': stock_code,
                                                        'year': year,
                                                        'status': 'url_error',
                                                        'error': str(e),
                                                        'title': title
                                                    })
                                            break
                                    except Exception as e:
                                        continue
                                
                                if found_report:
                                    break
                                    
                            except Exception as e:
                                print(f"      ÁøªÈ°µÂà∞Á¨¨{page_num}È°µÂ§±Ë¥•: {e}")
                                break
                        
                        if not found_report:
                            print(f"    ‚úó ÁøªÈ°µÂêé‰ªçÊú™ÊâæÂà∞{stock_code} {year}Âπ¥Âπ¥Êä•")
                            results.append({
                                'stock_code': stock_code,
                                'year': year,
                                'status': 'not_found',
                                'error': 'Êú™ÊâæÂà∞Âπ¥Êä•'
                            })
                    # Â¶ÇÊûúfound_report‰∏∫TrueÔºåËØ¥ÊòéÂ∑≤ÁªèÊâæÂà∞Âπ∂Â§ÑÁêÜ‰∫ÜÔºå‰∏çÈúÄË¶ÅÂÜçÊ∑ªÂä†not_foundËÆ∞ÂΩï
                
                except Exception as e:
                    print(f"üîÑ ÊêúÁ¥¢ËøáÁ®ãÂá∫Èîô: {e}")
                    results.append({
                        'stock_code': stock_code,
                        'year': year,
                        'status': 'search_failed',
                        'error': str(e)
                    })
        
        except Exception as e:
            print(f"üîÑ SeleniumÊìç‰ΩúÂá∫Èîô: {e}")
            results.append({
                'stock_code': stock_code,
                'year': 'all',
                'status': 'selenium_error',
                'error': str(e)
            })
        
        return results

    

    def search_hk_company_by_name(self, company_name_part: str) -> Tuple[str, str, str]:
        """
        ÈÄöËøáÂÖ¨Âè∏ÂêçÁß∞ÁâáÊÆµÊêúÁ¥¢Ê∏ØËÇ°ÔºåËé∑ÂèñorgId
        
        Args:
            company_name_part: ÂÖ¨Âè∏ÂêçÁß∞ÁâáÊÆµÊàñËÇ°Á•®‰ª£Á†Å
            
        Returns:
            Tuple[ËÇ°Á•®‰ª£Á†Å, ÂÖ¨Âè∏ÂêçÁß∞, orgId]
        """
        api_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'X-Requested-With': 'XMLHttpRequest'
        }
        
        # Â§ÑÁêÜHKÂâçÁºÄ
        search_term = company_name_part
        original_search_code = company_name_part  # ‰øùÂ≠òÂéüÂßãËæìÂÖ•Áî®‰∫éÁ≤æÁ°ÆÂåπÈÖç
        if search_term.startswith('HK'):
            search_term = search_term[2:]  # ÂéªÊéâHKÂâçÁºÄ
            original_search_code = search_term  # Êõ¥Êñ∞ÂéüÂßã‰ª£Á†Å
        
        params = {
            "stock": "",
            "tabName": "fulltext",
                            "pageSize": 50,
                "pageNum": 1,
            "column": "",
            "category": "",
            "plate": "",
            "seDate": "2020-01-01~2025-12-31",
            "searchkey": search_term,
            "secid": "",
            "sortName": "pubdate",
            "sortType": "desc",
            "isHLtitle": "true"
        }
        
        try:
            print(f"    üîç ÊêúÁ¥¢Ê∏ØËÇ°ÂÖ¨Âè∏: {search_term} (Á≤æÁ°ÆÂåπÈÖç: {original_search_code})")
            response = requests.post(api_url, headers=headers, data=params, timeout=10)
            if response.status_code == 200:
                result = response.json()
                announcements = result.get('announcements')
                
                # Â§ÑÁêÜNoneÂìçÂ∫î
                if announcements is None:
                    print(f"    ‚ö†Ô∏è APIËøîÂõûannouncements‰∏∫None")
                    return None, None, None
                
                # üîß ‰øÆÂ§çÔºöÊî∂ÈõÜÊâÄÊúâÂåπÈÖçÁªìÊûúÔºå‰ºòÂÖàÁ≤æÁ°ÆÂåπÈÖç
                exact_matches = []
                partial_matches = []
                
                for ann in announcements:
                    sec_code = ann.get('secCode', '')
                    sec_name = ann.get('secName', '')
                    org_id = ann.get('orgId', '')
                    
                    # Ê∏ÖÁêÜHTMLÊ†áÁ≠æ
                    clean_name = sec_name.replace('<em>', '').replace('</em>', '') if sec_name else ''
                    
                    # Ê£ÄÊü•ÊòØÂê¶ÊòØÊ∏ØËÇ°Ôºà‰ª£Á†ÅÈïøÂ∫¶5‰ΩçÊàñ‰ª•HKÂºÄÂ§¥Ôºâ
                    if sec_code and org_id and (len(sec_code) == 5 or sec_code.startswith('HK')):
                        # Á≤æÁ°ÆÂåπÈÖçÔºöËÇ°Á•®‰ª£Á†ÅÂÆåÂÖ®Áõ∏Âêå
                        if sec_code == original_search_code or sec_code == original_search_code.zfill(5):
                            exact_matches.append((sec_code, clean_name, org_id))
                            print(f"    ‚úÖ Á≤æÁ°ÆÂåπÈÖç: {clean_name} ({sec_code}) - orgId: {org_id}")
                        else:
                            partial_matches.append((sec_code, clean_name, org_id))
                            print(f"    üìÑ ÈÉ®ÂàÜÂåπÈÖç: {clean_name} ({sec_code}) - orgId: {org_id}")
                
                # ‰ºòÂÖàËøîÂõûÁ≤æÁ°ÆÂåπÈÖçÁªìÊûú
                if exact_matches:
                    sec_code, clean_name, org_id = exact_matches[0]
                    print(f"    üéØ ‰ΩøÁî®Á≤æÁ°ÆÂåπÈÖçÁªìÊûú: {clean_name} ({sec_code})")
                    return sec_code, clean_name, org_id
                elif partial_matches:
                    sec_code, clean_name, org_id = partial_matches[0]
                    print(f"    ‚ö†Ô∏è Êó†Á≤æÁ°ÆÂåπÈÖçÔºå‰ΩøÁî®ÈÉ®ÂàÜÂåπÈÖç: {clean_name} ({sec_code})")
                    print(f"    ‚ö†Ô∏è Ë≠¶ÂëäÔºöËæìÂÖ•‰ª£Á†Å {original_search_code} != ÊâæÂà∞‰ª£Á†Å {sec_code}")
                    return sec_code, clean_name, org_id
                        
        except Exception as e:
            print(f"    ‚úó ÊêúÁ¥¢Ê∏ØËÇ°ÂÖ¨Âè∏Â§±Ë¥•: {e}")
        
        return None, None, None

    def download_hk_reports(self, stock_code: str, years: List[int]) -> List[dict]:
        """
        ‰ΩøÁî®API‰∏ãËΩΩÊ∏ØËÇ°Âπ¥Êä•ÔºàÊñ∞ÁâàÊú¨Ôºâ
        
        Args:
            stock_code: Ê∏ØËÇ°‰ª£Á†Å
            years: Âπ¥‰ªΩÂàóË°®
            
        Returns:
            ‰∏ãËΩΩÁªìÊûúÂàóË°®
        """
        print(f"\nüöÄ ÂºÄÂßã‰∏ãËΩΩÊ∏ØËÇ° {stock_code} ÁöÑÂπ¥Êä•...")
        results = []
        
        # ÂàõÂª∫Ê∏ØËÇ°‰∏ãËΩΩÁõÆÂΩï
        hk_dir = self.download_dir / "HK"
        hk_dir.mkdir(exist_ok=True)
        
        try:
            # ÂÖàÂ∞ùËØïÊêúÁ¥¢ÂÖ¨Âè∏‰ø°ÊÅØ
            company_name = None
            org_id = None
            
            # Â§ÑÁêÜHKÂâçÁºÄÁöÑËÇ°Á•®‰ª£Á†Å
            search_code = stock_code
            if stock_code.startswith('HK'):
                search_code = stock_code[2:]  # ÂéªÊéâHKÂâçÁºÄÁî®‰∫éÊêúÁ¥¢
            
            # Â∞ùËØïÁî®ËÇ°Á•®‰ª£Á†ÅÊêúÁ¥¢
            found_code, company_name, org_id = self.search_hk_company_by_name(search_code)
            
            if not org_id:
                # Â∞ùËØïÂéªÊéâÂâçÂØº0ÊêúÁ¥¢
                search_code_no_zero = search_code.lstrip('0')
                print(f"    üîÑ Â∞ùËØïÂéªÊéâÂâçÂØº0ÊêúÁ¥¢: {search_code_no_zero}")
                found_code, company_name, org_id = self.search_hk_company_by_name(search_code_no_zero)
            
            if not org_id:
                print(f"  ‚úó Êó†Ê≥ïÊâæÂà∞Ê∏ØËÇ° {stock_code} ÁöÑÂÖ¨Âè∏‰ø°ÊÅØ")
                for year in years:
                    results.append({
                        'stock_code': stock_code,
                        'year': year,
                        'status': 'company_not_found',
                        'error': 'Êó†Ê≥ïÊâæÂà∞ÂÖ¨Âè∏‰ø°ÊÅØ'
                    })
                return results
            
            print(f"  ‚úì ÂÖ¨Âè∏‰ø°ÊÅØ: {company_name} ({found_code}) - orgId: {org_id}")
            
            # ÊêúÁ¥¢Âπ¥Êä•
            api_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
                'Accept': 'application/json, text/javascript, */*; q=0.01',
                'X-Requested-With': 'XMLHttpRequest'
            }
            
            # Â§öÁßçÊêúÁ¥¢Á≠ñÁï•
            search_strategies = [
                (f"{company_name} Âπ¥Â∫¶Êä•Âëä", "ÂÖ¨Âè∏Âêç+Âπ¥Â∫¶Êä•Âëä"),
                (f"{company_name} Âπ¥Êä•", "ÂÖ¨Âè∏Âêç+Âπ¥Êä•"),
                (f"{found_code} Âπ¥Â∫¶Êä•Âëä", "ËÇ°Á•®‰ª£Á†Å+Âπ¥Â∫¶Êä•Âëä"),
                (f"{found_code} Âπ¥Êä•", "ËÇ°Á•®‰ª£Á†Å+Âπ¥Êä•"),
                (f"{company_name} 2021", "ÂÖ¨Âè∏Âêç+2021"),
                (f"{company_name} 2022", "ÂÖ¨Âè∏Âêç+2022"),
                (f"{found_code} 2021", "ËÇ°Á•®‰ª£Á†Å+2021"),
                (f"{found_code} 2022", "ËÇ°Á•®‰ª£Á†Å+2022"),
            ]
            
            found_reports = {}
            
            for search_term, strategy_desc in search_strategies:
                print(f"  üîç ‰ΩøÁî®Á≠ñÁï•: {strategy_desc} - {search_term}")
                
                params = {
                    "stock": "",
                    "tabName": "fulltext",
                    "pageSize": 50,  # Â¢ûÂä†È°µÈù¢Â§ßÂ∞è
                    "pageNum": 1,
                    "column": "",
                    "category": "",
                    "plate": "",
                    "seDate": "2018-01-01~2025-12-31",
                    "searchkey": search_term,
                    "secid": "",
                    "sortName": "pubdate",
                    "sortType": "desc",
                    "isHLtitle": "true"
                }
                
                try:
                    # ÊîØÊåÅÁøªÈ°µÊêúÁ¥¢ÔºåÊúÄÂ§öÊêúÁ¥¢Ââç3È°µ
                    all_announcements = []
                    for page_num in range(1, 4):
                        params["pageNum"] = page_num
                        
                        response = requests.post(api_url, headers=headers, data=params, timeout=20)
                        
                        if response.status_code == 200:
                            result = response.json()
                            announcements = result.get('announcements', [])
                            
                            if announcements:
                                all_announcements.extend(announcements)
                                print(f"    Á¨¨{page_num}È°µÊâæÂà∞{len(announcements)}Êù°ÂÖ¨Âëä")
                            else:
                                if page_num == 1:
                                    print(f"    ‚ùå Êó†ÁªìÊûú")
                                else:
                                    print(f"    Á¨¨{page_num}È°µÊó†ÁªìÊûúÔºåÂÅúÊ≠¢ÁøªÈ°µ")
                                break
                        else:
                            print(f"    ‚ùå HTTPÈîôËØØ: {response.status_code}")
                            break
                    
                    if all_announcements:
                        print(f"    ‚úì ÊÄªÂÖ±ÊâæÂà∞ {len(all_announcements)} Êù°ÂÖ¨Âëä")
                        
                        for ann in all_announcements:
                            title = ann.get('announcementTitle', '')
                            sec_code = ann.get('secCode', '')
                            sec_name = ann.get('secName', '')
                            adj_url = ann.get('adjunctUrl', '')
                            
                            # Á°Æ‰øùÊòØÁõÆÊ†áÂÖ¨Âè∏ÔºàÂåπÈÖçÊ∏ØËÇ°ÂíåÂØπÂ∫îÁöÑAËÇ°‰ª£Á†ÅÔºâ
                            target_codes = [found_code]
                            # Â¶ÇÊûúÊòØÊ∏ØËÇ°Ôºå‰πüÂåπÈÖçÂØπÂ∫îÁöÑAËÇ°‰ª£Á†Å
                            if found_code == '00939':  # Âª∫ËÆæÈì∂Ë°åÊ∏ØËÇ°
                                target_codes.append('601939')  # Âª∫ËÆæÈì∂Ë°åAËÇ°
                            elif found_code == '00700':  # ËÖæËÆØÊ∏ØËÇ°
                                # ËÖæËÆØÊ≤°ÊúâAËÇ°ÔºåÂè™ÊúâÊ∏ØËÇ°
                                pass
                            
                            if sec_code not in target_codes:
                                continue
                                
                            # Ê∏ÖÁêÜHTMLÊ†áÁ≠æ
                            clean_title = title.replace('<em>', '').replace('</em>', '')
                            
                            # ‰ΩøÁî®Â¢ûÂº∫ÁöÑÂπ¥‰ªΩÂåπÈÖçÈÄªËæë
                            matched_year = None
                            if (('Âπ¥Â∫¶Êä•Âëä' in clean_title or 'Âπ¥Êä•' in clean_title or '‰ºÅ‰∏öÂπ¥Â∫¶Êä•Âëä' in clean_title) and
                                'ÂçäÂπ¥' not in clean_title and  # ÊéíÈô§ÂçäÂπ¥Êä•
                                'ÊëòË¶Å' not in clean_title and  # ÊéíÈô§ÊëòË¶Å
                                'ÈÄöÁü•‰ø°ÂáΩ' not in clean_title and  # ÊéíÈô§ÈÄöÁü•‰ø°ÂáΩ
                                'ÈÄöÂëä' not in clean_title and  # ÊéíÈô§ÈÄöÂëä
                                'ÈÄöÂáΩ' not in clean_title and  # ÊéíÈô§ÈÄöÂáΩ
                                'ÂàäÂèëÈÄöÁü•' not in clean_title and  # ÊéíÈô§ÂàäÂèëÈÄöÁü•
                                '‰ª£Ë°®Âßî‰ªªË°®Ê†º' not in clean_title and  # ÊéíÈô§‰ª£Ë°®Âßî‰ªªË°®Ê†º
                                'ËÇ°‰∏úÂë®Âπ¥Â§ß‰ºö' not in clean_title):  # ÊéíÈô§ËÇ°‰∏úÂ§ß‰ºöÁõ∏ÂÖ≥
                                matched_year = enhanced_year_matching(clean_title, years)
                            
                            if matched_year and matched_year not in found_reports:
                                found_reports[matched_year] = {
                                    'title': title,
                                    'adjunctUrl': adj_url,
                                    'search_term': search_term
                                }
                                print(f"    ‚òÖ ÊâæÂà∞ {matched_year} Âπ¥Êä•: {clean_title}")
                    
                except Exception as e:
                    print(f"    ‚ùå ÊêúÁ¥¢ÂºÇÂ∏∏: {e}")
                
                # Â¶ÇÊûúÂ∑≤ÁªèÊâæÂà∞ÊâÄÊúâÂπ¥‰ªΩÁöÑÂπ¥Êä•ÔºåÂèØ‰ª•ÊèêÂâçÁªìÊùü
                if len(found_reports) >= len(years):
                    break
            
            # ‰∏ãËΩΩÊâæÂà∞ÁöÑÂπ¥Êä•
            print(f"  üì• ÂºÄÂßã‰∏ãËΩΩÂπ¥Êä•...")
            
            for year in years:
                if year in found_reports:
                    report = found_reports[year]
                    adj_url = report['adjunctUrl']
                    
                    if adj_url:
                        # ÊûÑÈÄ†PDFÁõ¥Êé•‰∏ãËΩΩÈìæÊé•
                        pdf_url = f"http://static.cninfo.com.cn/{adj_url}"
                        # ‰ΩøÁî®Ê∏ÖÁêÜÂêéÁöÑÂÖ¨Âè∏ÂêçÁß∞
                        safe_company_name = company_name.replace('/', '_').replace('\\', '_')
                        filename = f"{found_code}_{safe_company_name}_{year}Âπ¥Âπ¥Â∫¶Êä•Âëä.pdf"
                        filepath = hk_dir / filename
                        
                        print(f"    üìÑ ‰∏ãËΩΩ {year} Âπ¥Êä•...")
                        print(f"       Êñá‰ª∂: {report['title']}")
                        
                        if self.download_pdf(pdf_url, str(filepath)):
                            print(f"    ‚úì ÊàêÂäü‰∏ãËΩΩ: {filename}")
                            results.append({
                                'stock_code': stock_code,
                                'year': year,
                                'status': 'success',
                                'filename': filename,
                                'file_path': str(filepath)
                            })
                        else:
                            print(f"    ‚úó ‰∏ãËΩΩÂ§±Ë¥•: {filename}")
                            results.append({
                                'stock_code': stock_code,
                                'year': year,
                                'status': 'download_failed',
                                'error': 'PDF‰∏ãËΩΩÂ§±Ë¥•'
                            })
                    else:
                        print(f"    ‚úó {year} Âπ¥Êä•Êó†PDFÈìæÊé•")
                        results.append({
                            'stock_code': stock_code,
                            'year': year,
                            'status': 'no_pdf_link',
                            'error': 'Êó†PDFÈìæÊé•'
                        })
                else:
                    print(f"    ‚úó Êú™ÊâæÂà∞ {year} Âπ¥Êä•")
                    results.append({
                        'stock_code': stock_code,
                        'year': year,
                        'status': 'not_found',
                        'error': 'Êú™ÊâæÂà∞Âπ¥Êä•'
                    })
            
            return results
            
        except Exception as e:
            print(f"üîÑ Ê∏ØËÇ°‰∏ãËΩΩËøáÁ®ãÂá∫Èîô: {e}")
            for year in years:
                results.append({
                    'stock_code': stock_code,
                    'year': year,
                    'status': 'error',
                    'error': str(e)
                })
            return results

    def download_hk_reports_old(self, stock_code: str, years: List[int]) -> List[dict]:
        """
        ÊóßÁâàÊ∏ØËÇ°‰∏ãËΩΩÊñπÊ≥ïÔºà‰ΩøÁî®SeleniumÔºâ
        Áé∞Âú®Â∑≤Ë¢´Êñ∞ÁâàAPIÊñπÊ≥ïÊõø‰ª£
        """
        return [{'stock_code': stock_code, 'year': 'all', 'status': 'deprecated', 'error': 'Â∑≤‰ΩøÁî®Êñ∞ÁâàAPIÊñπÊ≥ï'}]

    def download_pdf(self, url: str, filepath: str) -> bool:
        """
        ‰∏ãËΩΩPDFÊñá‰ª∂
        
        Args:
            url: ‰∏ãËΩΩURL
            filepath: ÂÆåÊï¥Êñá‰ª∂Ë∑ØÂæÑ
            
        Returns:
            ÊòØÂê¶‰∏ãËΩΩÊàêÂäü
        """
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=30, stream=True)
            response.raise_for_status()
            
            # Á°Æ‰øùÁõÆÂΩïÂ≠òÂú®
            Path(filepath).parent.mkdir(parents=True, exist_ok=True)
            
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            
            return True
            
        except Exception as e:
            print(f"    ‰∏ãËΩΩÂ§±Ë¥•: {e}")
            return False

    

    def download_stock_reports(self, stock_code: str, years: List[int]) -> List[Dict]:

        """

        ‰∏ãËΩΩÊåáÂÆöËÇ°Á•®ÁöÑÂπ¥Êä•

        

        Args:

            stock_code: ËÇ°Á•®‰ª£Á†Å

            years: Âπ¥‰ªΩÂàóË°®

            

        Returns:

            ‰∏ãËΩΩÁªìÊûúÂàóË°®

        """

        stock_type = self.identify_stock_type(stock_code)

        print(f"üìä Â§ÑÁêÜËÇ°Á•®: {stock_code} ({stock_type})")

        

        if stock_type == StockType.A_MAIN:

            return self.download_a_stock_main_reports(stock_code, years)

        elif stock_type in [StockType.A_STAR, StockType.A_GEM]:

            return self.download_a_stock_with_selenium(stock_code, years, stock_type)

        elif stock_type == StockType.HK:

            return self.download_hk_reports(stock_code, years)

        elif stock_type == StockType.US:

            return self.download_us_stock_10k_reports(stock_code, years)

        else:

            print(f"    üîÑ ‰∏çÊîØÊåÅÁöÑËÇ°Á•®Á±ªÂûã: {stock_type}")

            return [{'stock_code': stock_code, 'year': 'all', 'status': 'unsupported', 'error': f'‰∏çÊîØÊåÅÁöÑËÇ°Á•®Á±ªÂûã: {stock_type}'}]

    

    def process_stock_list(self, stock_codes: List[str], years: List[int]):

        """

        ÊâπÈáèÂ§ÑÁêÜËÇ°Á•®ÂàóË°®

        

        Args:

            stock_codes: ËÇ°Á•®‰ª£Á†ÅÂàóË°®

            years: Âπ¥‰ªΩÂàóË°®

        """

        self.stats["total"] = len(stock_codes) * len(years)

        

        print(f"üöÄ ÂºÄÂßãÊâπÈáè‰∏ãËΩΩÔºåÂÖ±{len(stock_codes)} Âè™ËÇ°Á•®Ôºå{len(years)} ‰∏™Âπ¥‰ªΩ")

        print(f"üìÅ ‰∏ãËΩΩÁõÆÂΩï: {self.download_dir.absolute()}")

        print("=" * 60)

        

        for i, stock_code in enumerate(stock_codes, 1):

            print(f"\n[{i}/{len(stock_codes)}] Â§ÑÁêÜËÇ°Á•®: {stock_code}")

            

            results = self.download_stock_reports(stock_code, years)

            

            # Êõ¥Êñ∞ÁªüËÆ°

            for result in results:

                self.stats["details"].append(result)

                if result["status"] == "success":

                    self.stats["success"] += 1

                else:

                    self.stats["failed"] += 1

            

            # ÊòæÁ§∫ÂΩìÂâçËøõÂ∫¶

            success_rate = (self.stats["success"] / (self.stats["success"] + self.stats["failed"])) * 100 if (self.stats["success"] + self.stats["failed"]) > 0 else 0

            print(f"  ÂΩìÂâçÊàêÂäüÁéá {success_rate:.1f}% ({self.stats['success']}/{self.stats['success'] + self.stats['failed']})")

            

            time.sleep(2)  # ÈÅøÂÖçËØ∑Ê±ÇËøáÂø´

    

    def print_summary(self):

        """ÊâìÂç∞‰∏ãËΩΩÊ±áÊÄªÊä•Âëä"""

        print("\n" + "=" * 60)

        print("üìà ‰∏ãËΩΩÊ±áÊÄªÊä•Âëä")

        print("=" * 60)

        

        print(f"ÊÄªËÆ°‰ªªÂä°: {self.stats['total']}")

        print(f"ÊàêÂäü‰∏ãËΩΩ: {self.stats['success']}")

        print(f"Â§±Ë¥•‰ªªÂä°: {self.stats['failed']}")

        

        if self.stats['total'] > 0:

            success_rate = (self.stats['success'] / self.stats['total']) * 100

            print(f"ÊàêÂäüÁéá {success_rate:.1f}%")

        

        # ÊåâÁä∂ÊÄÅÂàÜÁªÑÁªüËÆ°

        status_count = {}

        failed_details = []  # Â≠òÂÇ®Â§±Ë¥•ËØ¶ÊÉÖ

        

        for detail in self.stats["details"]:

            status = detail.get("status", "unknown")

            status_count[status] = status_count.get(status, 0) + 1

            

            # Êî∂ÈõÜÂ§±Ë¥•ËØ¶ÊÉÖ

            if status != "success":

                failed_details.append({

                    'stock_code': detail.get('stock_code', ''),

                    'year': detail.get('year', ''),

                    'status': status,

                    'error': detail.get('error', ''),

                    'title': detail.get('title', '')

                })

        

        if status_count:

            print(f"\nüìä ËØ¶ÁªÜÁªüËÆ°:")

            for status, count in status_count.items():

                print(f"  {status}: {count}")

        

        # ËØ¶ÁªÜÂàóÂá∫Â§±Ë¥•‰ªªÂä°

        if failed_details:

            print(f"\nÂ§±Ë¥•‰ªªÂä°ËØ¶ÊÉÖ ({len(failed_details)}‰∏™):")

            

            # ÊåâÂ§±Ë¥•Á±ªÂûãÂàÜÁªÑ

            failure_groups = {}

            for failure in failed_details:

                status = failure['status']

                if status not in failure_groups:

                    failure_groups[status] = []

                failure_groups[status].append(failure)

            

            for status, failures in failure_groups.items():

                print(f"\nüî∏ {status} ({len(failures)}‰∏™):")

                for failure in failures:

                    stock_year = f"{failure['stock_code']} {failure['year']}"

                    error_msg = failure['error']

                    if failure.get('title'):

                        print(f"  {stock_year}: {error_msg} (ÊâæÂà∞Ê†áÈ¢ò: {failure['title'][:50]}...)")

                    else:

                        print(f"  {stock_year}: {error_msg}")

        

        # ÊàêÂäü‰ªªÂä°ÂàóË°®ÔºàÂ¶ÇÊûú‰∏çÂ§öÁöÑËØùÔºâ

        success_details = [d for d in self.stats["details"] if d.get("status") == "success"]

        if success_details and len(success_details) <= 10:  # Âè™Êúâ‰∏çË∂ÖËøá10‰∏™ÊàêÂäüÊó∂ÊâçÊòæÁ§∫

            print(f"\nÊàêÂäü‰∏ãËΩΩËØ¶ÊÉÖ ({len(success_details)}‰∏™):")

            for success in success_details:

                stock_year = f"{success.get('stock_code', '')} {success.get('year', '')}"

                filename = success.get('filename', '')

                print(f"  {stock_year}: {filename}")

        

        print(f"\nüìÅ ‰∏ãËΩΩÊñá‰ª∂‰øùÂ≠òÁõÆÂΩï {self.download_dir.absolute()}")

        print("="*60)
        print("  Annual Report Crawler - Developed by Terence WANG")
        print("="*60)
        print()

    def download_us_stock_10k_reports(self, stock_symbol, years):
        """
        ‰∏ãËΩΩÁæéËÇ°10-KÂπ¥Êä•
        
        Args:
            stock_symbol (str): ÁæéËÇ°ËÇ°Á•®‰ª£Á†ÅÔºåÂ¶Ç 'AAPL', 'MSFT'
            years (list): Âπ¥‰ªΩÂàóË°®ÔºåÂ¶Ç [2023, 2022, 2021]
        
        Returns:
            List[Dict]: ‰∏ãËΩΩÁªìÊûúÂàóË°®Ôºå‰∏éÂÖ∂‰ªñÂáΩÊï∞Ê†ºÂºè‰∏ÄËá¥
        """
        print(f"\nüá∫üá∏ ÂºÄÂßã‰∏ãËΩΩÁæéËÇ° {stock_symbol} ÁöÑ10-KÂπ¥Êä•...")
        
        # ÂàõÂª∫USÊñá‰ª∂Â§π
        us_folder = os.path.join(self.download_dir, "US")
        if not os.path.exists(us_folder):
            os.makedirs(us_folder)
            print(f"    üìÅ ÂàõÂª∫USÊñá‰ª∂Â§π: {us_folder}")
        
        results = []  # Êîπ‰∏∫ÂàóË°®Ê†ºÂºèÔºå‰∏éÂÖ∂‰ªñÂáΩÊï∞‰øùÊåÅ‰∏ÄËá¥
        successful_downloads = 0
        failed_downloads = 0
        
        try:
            # Á¨¨‰∏ÄÊ≠•ÔºöËé∑ÂèñÂÖ¨Âè∏CIK
            cik = self._get_us_stock_cik(stock_symbol)
            if not cik:
                print(f"    ‚ùå Êó†Ê≥ïÊâæÂà∞ËÇ°Á•®‰ª£Á†Å {stock_symbol} ÂØπÂ∫îÁöÑCIK")
                # ‰∏∫ÊØè‰∏™Âπ¥‰ªΩÂàõÂª∫Â§±Ë¥•ËÆ∞ÂΩï
                for year in years:
                    results.append({
                        'stock_code': stock_symbol,
                        'year': year,
                        'status': 'failed',
                        'error': f'Êó†Ê≥ïÊâæÂà∞ËÇ°Á•®‰ª£Á†Å {stock_symbol} ÂØπÂ∫îÁöÑCIK',
                        'filename': None
                    })
                return results
            
            print(f"    ‚úì ÊâæÂà∞CIK: {cik}")
            
            # Á¨¨‰∫åÊ≠•ÔºöËé∑Âèñ10-KÊä•ÂëäÂàóË°®
            filings = self._get_us_10k_filings(cik, years)
            if not filings:
                print(f"    ‚ùå Êú™ÊâæÂà∞‰ªª‰Ωï10-KÊä•Âëä")
                for year in years:
                    results.append({
                        'stock_code': stock_symbol,
                        'year': year,
                        'status': 'failed',
                        'error': 'Êú™ÊâæÂà∞‰ªª‰Ωï10-KÊä•Âëä',
                        'filename': None
                    })
                return results
            
            print(f"    ‚úì ÊâæÂà∞ {len(filings)} ‰∏™10-KÊä•Âëä")
            
            # ‰∏∫ÊØè‰∏™ËØ∑Ê±ÇÁöÑÂπ¥‰ªΩÂàõÂª∫ÁªìÊûúËÆ∞ÂΩï
            filing_dict = {filing['year']: filing for filing in filings}
            
            # Á¨¨‰∏âÊ≠•Ôºö‰∏ãËΩΩÊØè‰∏™Âπ¥Êä•
            for year in years:
                if year in filing_dict:
                    filing = filing_dict[year]
                    try:
                        filing_date = filing['filing_date']
                        document_url = filing['document_url']
                        
                        print(f"    üìÑ ‰∏ãËΩΩ {year} Âπ¥10-KÊä•Âëä...")
                        
                        # ‰∏ãËΩΩHTMLÂÜÖÂÆπ
                        html_content = self._download_us_filing_content(document_url)
                        if not html_content:
                            print(f"    ‚ùå {year} Âπ¥Êä•‰∏ãËΩΩÂ§±Ë¥•")
                            results.append({
                                'stock_code': stock_symbol,
                                'year': year,
                                'status': 'failed',
                                'error': 'ÊñáÊ°£ÂÜÖÂÆπ‰∏ãËΩΩÂ§±Ë¥•',
                                'filename': None
                            })
                            failed_downloads += 1
                            continue
                        
                        # ‰øùÂ≠òÊñá‰ª∂ÔºàHTMLÊ†ºÂºèÔºâ
                        filename = f"{stock_symbol}_{year}_10K_{filing_date}.html"
                        filepath = os.path.join(us_folder, filename)
                        
                        # Áõ¥Êé•‰øùÂ≠ò‰∏∫HTML
                        success = self._save_us_filing_as_html(html_content, filepath, stock_symbol, year)
                        
                        if success:
                            print(f"    ‚úÖ {year} Âπ¥Êä•‰∏ãËΩΩÊàêÂäü: {filename}")
                            results.append({
                                'stock_code': stock_symbol,
                                'year': year,
                                'status': 'success',
                                'error': None,
                                'filename': filename
                            })
                            successful_downloads += 1
                        else:
                            print(f"    ‚ùå {year} Âπ¥Êä•‰øùÂ≠òÂ§±Ë¥•")
                            results.append({
                                'stock_code': stock_symbol,
                                'year': year,
                                'status': 'failed',
                                'error': 'Êñá‰ª∂‰øùÂ≠òÂ§±Ë¥•',
                                'filename': None
                            })
                            failed_downloads += 1
                            
                        # Ê∑ªÂä†Âª∂ËøüÈÅøÂÖçËØ∑Ê±ÇËøáÂø´
                        time.sleep(0.5)
                        
                    except Exception as e:
                        print(f"    ‚ùå {year} Âπ¥Êä•Â§ÑÁêÜÂ§±Ë¥•: {str(e)}")
                        results.append({
                            'stock_code': stock_symbol,
                            'year': year,
                            'status': 'failed',
                            'error': str(e),
                            'filename': None
                        })
                        failed_downloads += 1
                else:
                    # Êú™ÊâæÂà∞ËØ•Âπ¥‰ªΩÁöÑÊä•Âëä
                    results.append({
                        'stock_code': stock_symbol,
                        'year': year,
                        'status': 'failed',
                        'error': f'Êú™ÊâæÂà∞ {year} Âπ¥ÁöÑ10-KÊä•Âëä',
                        'filename': None
                    })
                    failed_downloads += 1
            
        except Exception as e:
            print(f"    ‚ùå ‰∏ãËΩΩËøáÁ®ã‰∏≠ÂèëÁîüÈîôËØØ: {str(e)}")
            for year in years:
                results.append({
                    'stock_code': stock_symbol,
                    'year': year,
                    'status': 'failed',
                    'error': str(e),
                    'filename': None
                })
            failed_downloads = len(years)
        
        # ËæìÂá∫ÁªìÊûúÁªüËÆ°
        print(f"\nüìä ÁæéËÇ° {stock_symbol} 10-KÂπ¥Êä•‰∏ãËΩΩÂÆåÊàê:")
        print(f"    ‚úÖ ÊàêÂäü‰∏ãËΩΩ: {successful_downloads} ‰∏™")
        print(f"    ‚ùå ‰∏ãËΩΩÂ§±Ë¥•: {failed_downloads} ‰∏™")
        
        return results
    
    def _get_us_stock_cik(self, stock_symbol):
        """Ëé∑ÂèñÁæéËÇ°ÂÖ¨Âè∏ÁöÑCIK"""
        try:
            # ‰ΩøÁî®SECÂÖ¨Âè∏tickerÊò†Â∞ÑAPI
            url = "https://www.sec.gov/files/company_tickers.json"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                companies = response.json()
                
                # Êü•ÊâæÂåπÈÖçÁöÑËÇ°Á•®‰ª£Á†Å
                for company_data in companies.values():
                    if company_data.get('ticker', '').upper() == stock_symbol.upper():
                        cik = str(company_data.get('cik_str', '')).zfill(10)
                        return cik
                        
        except Exception as e:
            print(f"    ‚ö†Ô∏è Ëé∑ÂèñCIKÊó∂Âá∫Èîô: {str(e)}")
        
        return None
    
    def _get_us_10k_filings(self, cik, years):
        """Ëé∑ÂèñÊåáÂÆöÂπ¥‰ªΩÁöÑ10-KÊä•ÂëäÂàóË°®"""
        try:
            # ‰ΩøÁî®SEC submissions API
            url = f"https://data.sec.gov/submissions/CIK{cik}.json"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=15)
            if response.status_code != 200:
                return []
            
            data = response.json()
            filings_data = data.get('filings', {}).get('recent', {})
            
            if not filings_data:
                return []
            
            # Ëß£ÊûêÊä•ÂëäÊï∞ÊçÆ
            forms = filings_data.get('form', [])
            filing_dates = filings_data.get('filingDate', [])
            accession_numbers = filings_data.get('accessionNumber', [])
            primary_documents = filings_data.get('primaryDocument', [])
            
            filings = []
            for i, form in enumerate(forms):
                if form == '10-K' and i < len(filing_dates):
                    filing_date = filing_dates[i]
                    year = int(filing_date.split('-')[0])
                    
                    if year in years:
                        accession_no = accession_numbers[i].replace('-', '')
                        primary_doc = primary_documents[i]
                        
                        # ÊûÑÂª∫ÊñáÊ°£URL
                        document_url = f"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_no}/{primary_doc}"
                        
                        filings.append({
                            'year': year,
                            'filing_date': filing_date,
                            'accession_number': accession_numbers[i],
                            'document_url': document_url,
                            'primary_document': primary_doc
                        })
            
            # ÊåâÂπ¥‰ªΩÊéíÂ∫è
            filings.sort(key=lambda x: x['year'], reverse=True)
            return filings
            
        except Exception as e:
            print(f"    ‚ö†Ô∏è Ëé∑Âèñ10-KÊä•ÂëäÂàóË°®Êó∂Âá∫Èîô: {str(e)}")
            return []
    
    def _download_us_filing_content(self, document_url):
        """‰∏ãËΩΩSECÊñáÊ°£ÂÜÖÂÆπ"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive',
            }
            
            response = requests.get(document_url, headers=headers, timeout=30)
            if response.status_code == 200:
                return response.text
            else:
                print(f"    ‚ö†Ô∏è HTTPÈîôËØØ: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"    ‚ö†Ô∏è ‰∏ãËΩΩÊñáÊ°£ÂÜÖÂÆπÊó∂Âá∫Èîô: {str(e)}")
            return None
    
    def _save_us_filing_as_html(self, html_content, filepath, stock_symbol, year):
        """Â∞ÜHTMLÂÜÖÂÆπ‰øùÂ≠ò‰∏∫HTMLÊñá‰ª∂"""
        try:
            # Ê∏ÖÁêÜHTMLÂÜÖÂÆπ
            cleaned_html = self._clean_html_for_pdf(html_content)
            
            # Ê∑ªÂä†Âü∫Êú¨Ê†∑Âºè
            styled_html = f"""
            <!DOCTYPE html>
            <html>
            <head>
                <meta charset="utf-8">
                <title>{stock_symbol} {year} 10-K Annual Report</title>
                <style>
                    body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.4; }}
                    .header {{ text-align: center; margin-bottom: 30px; border-bottom: 2px solid #333; padding-bottom: 10px; }}
                    .content {{ max-width: 100%; }}
                    table {{ border-collapse: collapse; width: 100%; margin: 10px 0; }}
                    th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                    th {{ background-color: #f2f2f2; }}
                    .page-break {{ page-break-before: always; }}
                </style>
            </head>
            <body>
                <div class="header">
                    <h1>{stock_symbol} - 10-K Annual Report ({year})</h1>
                    <p>Downloaded from SEC EDGAR Database</p>
                </div>
                <div class="content">
                    {cleaned_html}
                </div>
            </body>
            </html>
            """
            
            # Áõ¥Êé•‰øùÂ≠ò‰∏∫HTMLÊñá‰ª∂
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(styled_html)
            return True
                    
        except Exception as e:
            print(f"    ‚ö†Ô∏è ‰øùÂ≠òHTMLÊó∂Âá∫Èîô: {str(e)}")
            return False

    def _save_us_filing_as_pdf(self, html_content, filepath, stock_symbol, year):
        """Â∞ÜHTMLÂÜÖÂÆπ‰øùÂ≠ò‰∏∫PDF"""
        try:
            # Ê∏ÖÁêÜHTMLÂÜÖÂÆπ
            cleaned_html = self._clean_html_for_pdf(html_content)
            
            # Ê∑ªÂä†Âü∫Êú¨Ê†∑Âºè
            styled_html = f"""
            <!DOCTYPE html>
            <html>
            <head>
                <meta charset="utf-8">
                <title>{stock_symbol} {year} 10-K Annual Report</title>
                <style>
                    body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.4; }}
                    .header {{ text-align: center; margin-bottom: 30px; border-bottom: 2px solid #333; padding-bottom: 10px; }}
                    .content {{ max-width: 100%; }}
                    table {{ border-collapse: collapse; width: 100%; margin: 10px 0; }}
                    th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                    th {{ background-color: #f2f2f2; }}
                    .page-break {{ page-break-before: always; }}
                </style>
            </head>
            <body>
                <div class="header">
                    <h1>{stock_symbol} - 10-K Annual Report ({year})</h1>
                    <p>Downloaded from SEC EDGAR Database</p>
                </div>
                <div class="content">
                    {cleaned_html}
                </div>
            </body>
            </html>
            """
            
            # ‰ΩøÁî®pdfkitËΩ¨Êç¢‰∏∫PDF
            try:
                import pdfkit
                
                # ÈÖçÁΩÆwkhtmltopdfË∑ØÂæÑÔºàWindowsÔºâ
                config = pdfkit.configuration(wkhtmltopdf=r'C:\Program Files\wkhtmltopdf\bin\wkhtmltopdf.exe')
                
                options = {
                    'page-size': 'A4',
                    'margin-top': '0.75in',
                    'margin-right': '0.75in',
                    'margin-bottom': '0.75in',
                    'margin-left': '0.75in',
                    'encoding': "UTF-8",
                    'no-outline': None,
                    'enable-local-file-access': None
                }
                
                pdfkit.from_string(styled_html, filepath, options=options, configuration=config)
                return True
                
            except ImportError:
                print("    ‚ö†Ô∏è pdfkitÊú™ÂÆâË£ÖÔºåÂ∞ùËØï‰ΩøÁî®weasyprint...")
                try:
                    from weasyprint import HTML, CSS
                    HTML(string=styled_html).write_pdf(filepath)
                    return True
                except ImportError:
                    print("    ‚ö†Ô∏è weasyprint‰πüÊú™ÂÆâË£ÖÔºå‰øùÂ≠ò‰∏∫HTMLÊñá‰ª∂...")
                    # Â¶ÇÊûúÈÉΩÊ≤°ÊúâÂÆâË£ÖÔºå‰øùÂ≠ò‰∏∫HTML
                    html_filepath = filepath.replace('.pdf', '.html')
                    with open(html_filepath, 'w', encoding='utf-8') as f:
                        f.write(styled_html)
                    print(f"    üí° Â∑≤‰øùÂ≠ò‰∏∫HTMLÊñá‰ª∂: {html_filepath}")
                    return True
                    
        except Exception as e:
            print(f"    ‚ö†Ô∏è ‰øùÂ≠òPDFÊó∂Âá∫Èîô: {str(e)}")
            return False
    
    def _clean_html_for_pdf(self, html_content):
        """Ê∏ÖÁêÜHTMLÂÜÖÂÆπ‰ª•‰æøËΩ¨Êç¢‰∏∫PDF"""
        try:
            from bs4 import BeautifulSoup
            
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # ÁßªÈô§ËÑöÊú¨ÂíåÊ†∑ÂºèÊ†áÁ≠æ
            for script in soup(["script", "style"]):
                script.decompose()
            
            # ÁßªÈô§‰∏Ä‰∫õÂèØËÉΩÂØºËá¥ÈóÆÈ¢òÁöÑÂ±ûÊÄß
            for tag in soup.find_all():
                if tag.name:
                    # ‰øùÁïôÂü∫Êú¨Â±ûÊÄßÔºåÁßªÈô§ÂèØËÉΩÊúâÈóÆÈ¢òÁöÑÂ±ûÊÄß
                    attrs_to_keep = ['href', 'src', 'alt', 'title', 'colspan', 'rowspan']
                    new_attrs = {}
                    for attr in attrs_to_keep:
                        if attr in tag.attrs:
                            new_attrs[attr] = tag.attrs[attr]
                    tag.attrs = new_attrs
            
            # Ëé∑ÂèñbodyÂÜÖÂÆπÔºåÂ¶ÇÊûúÊ≤°ÊúâbodyÂ∞±ËøîÂõûÂÖ®ÈÉ®
            body = soup.find('body')
            if body:
                return str(body)
            else:
                return str(soup)
                
        except Exception as e:
            print(f"    ‚ö†Ô∏è Ê∏ÖÁêÜHTMLÊó∂Âá∫Èîô: {str(e)}")
            # Â¶ÇÊûúÊ∏ÖÁêÜÂ§±Ë¥•ÔºåËøîÂõûÂéüÂßãÂÜÖÂÆπ
            return html_content
    
    def enhanced_year_matching(self, title, target_year):
        """
        Â¢ûÂº∫ÁöÑÂπ¥‰ªΩÂåπÈÖçÂáΩÊï∞ÔºåÊîØÊåÅÊï∞Â≠óÂíå‰∏≠ÊñáÂπ¥‰ªΩÊ†ºÂºè
        
        Args:
            title (str): ÂÖ¨ÂëäÊ†áÈ¢ò
            target_year (int): ÁõÆÊ†áÂπ¥‰ªΩ
            
        Returns:
            bool: ÊòØÂê¶ÂåπÈÖç
        """
        if not title or not target_year:
            return False
        
        title_lower = title.lower()
        year_str = str(target_year)
        
        # 1. Áõ¥Êé•Êï∞Â≠óÂåπÈÖç
        if year_str in title:
            return True
        
        # 2. ‰∏≠ÊñáÊï∞Â≠óÊò†Â∞Ñ
        chinese_digits = {
            '0': ['„Äá', 'Èõ∂'],
            '1': ['‰∏Ä'],
            '2': ['‰∫å'],
            '3': ['‰∏â'],
            '4': ['Âõõ'],
            '5': ['‰∫î'],
            '6': ['ÂÖ≠'],
            '7': ['‰∏É'],
            '8': ['ÂÖ´'],
            '9': ['‰πù']
        }
        
        def generate_chinese_patterns(year_str):
            """ÈÄíÂΩíÁîüÊàêÊâÄÊúâÂèØËÉΩÁöÑ‰∏≠ÊñáÊï∞Â≠óÁªÑÂêà"""
            if not year_str:
                return ['']
            
            first_digit = year_str[0]
            rest_patterns = generate_chinese_patterns(year_str[1:])
            
            patterns = []
            for chinese_char in chinese_digits.get(first_digit, [first_digit]):
                for rest_pattern in rest_patterns:
                    patterns.append(chinese_char + rest_pattern)
            
            return patterns
        
        # 3. ÁîüÊàêÊâÄÊúâÂèØËÉΩÁöÑ‰∏≠ÊñáÂπ¥‰ªΩÊ†ºÂºè
        chinese_patterns = generate_chinese_patterns(year_str)
        
        for pattern in chinese_patterns:
            if pattern in title:
                return True
        
        # 4. Ê∏ØËÇ°ÁâπÊÆäÊ†ºÂºèÂåπÈÖç
        hk_patterns = [
            f"{year_str}Âπ¥Â∫¶Êä•Âëä",
            f"{year_str}Âπ¥Âπ¥Â∫¶Êä•Âëä", 
            f"{year_str}Âπ¥Êä•",
            f"{year_str} annual report",
            f"annual report {year_str}",
            f"Âπ¥Â∫¶Êä•Âëä{year_str}",
            f"‰ºÅ‰∏öÂπ¥Â∫¶Êä•Âëä{year_str}",
            f"hËÇ°ÂÖ¨ÂëäÂπ¥Â∫¶Êä•Âëä{year_str}"
        ]
        
        for pattern in hk_patterns:
            if pattern in title_lower:
                return True
        
        # 5. ‰∏≠ÊñáÂπ¥‰ªΩ + Âπ¥Â∫¶Êä•ÂëäÊ†ºÂºè
        for pattern in chinese_patterns:
            chinese_year_patterns = [
                f"{pattern}Âπ¥Â∫¶Êä•Âëä",
                f"{pattern}Âπ¥Âπ¥Â∫¶Êä•Âëä",
                f"{pattern}Âπ¥Êä•",
                f"Âπ¥Â∫¶Êä•Âëä{pattern}",
                f"‰ºÅ‰∏öÂπ¥Â∫¶Êä•Âëä{pattern}"
            ]
            
            for chinese_pattern in chinese_year_patterns:
                if chinese_pattern in title:
                    return True
        
        return False





def parse_year_range(year_str: str) -> List[int]:

    """

    Ëß£ÊûêÂπ¥‰ªΩËåÉÂõ¥Â≠óÁ¨¶‰∏≤

    

    Args:

        year_str: Âπ¥‰ªΩÂ≠óÁ¨¶‰∏≤ÔºåÊîØÊåÅÊ†ºÂºè: "2020", "2020-2022", "2020,2021,2022"

        

    Returns:

        Âπ¥‰ªΩÂàóË°®

    """

    years = []

    

    if '-' in year_str:

        # ËåÉÂõ¥Ê†ºÂºè: 2020-2022

        start, end = year_str.split('-')

        years = list(range(int(start), int(end) + 1))

    elif ',' in year_str:

        # ÂàóË°®Ê†ºÂºè: 2020,2021,2022

        years = [int(y.strip()) for y in year_str.split(',')]

    else:

        # Âçï‰∏™Âπ¥‰ªΩ: 2020

        years = [int(year_str)]

    

    return years





def load_stock_codes_from_file(filepath: str) -> List[str]:
    """
    ‰ªéÊñá‰ª∂Âä†ËΩΩËÇ°Á•®‰ª£Á†ÅÂàóË°®
    
    Args:
        filepath: Êñá‰ª∂Ë∑ØÂæÑ
        
    Returns:
        ËÇ°Á•®‰ª£Á†ÅÂàóË°®
    """
    stock_codes = []
    
    try:
        # Â∞ùËØïÂ§öÁßçÁºñÁ†ÅÊñπÂºè
        encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312']
        content = None
        used_encoding = None
        
        for encoding in encodings:
            try:
                with open(filepath, 'r', encoding=encoding) as f:
                    content = f.read()
                used_encoding = encoding
                break
            except UnicodeDecodeError:
                continue
        
        if content is None:
            raise Exception("Êó†Ê≥ïËß£Á†ÅÊñá‰ª∂ÔºåÂ∞ùËØï‰∫ÜÂ§öÁßçÁºñÁ†ÅÊñπÂºè")
        
        for line in content.splitlines():
            code = line.strip()
            if code and not code.startswith('#'):  # Ë∑≥ËøáÁ©∫Ë°åÂíåÊ≥®Èáä
                stock_codes.append(code)
        
        print(f"üîÑ ‰ªéÊñá‰ª∂{filepath} Âä†ËΩΩ‰∫Ü{len(stock_codes)} ‰∏™ËÇ°Á•®‰ª£Á†Å (ÁºñÁ†Å: {used_encoding})")
        
    except Exception as e:
        print(f"üîÑ ËØªÂèñÊñá‰ª∂ {filepath} Â§±Ë¥•: {e}")
        sys.exit(1)
    
    return stock_codes





def main():
    # ÊâìÂç∞Ê¨¢Ëøé‰ø°ÊÅØ
    print("="*60)
    print("  Annual Report Crawler - Developed by Terence WANG")
    print("="*60)
    
    parser = argparse.ArgumentParser(description="Âπ¥Êä•‰∏ãËΩΩÂô®ÔºåÊîØÊåÅAËÇ°„ÄÅÊ∏ØËÇ°ÂíåÁæéËÇ°„ÄÇ")
    
    # Ê∑ªÂä†ÂèÇÊï∞
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('-s', '--stock', type=str, help='ËÇ°Á•®‰ª£Á†ÅÔºàAËÇ°6‰Ωç‰ª£Á†ÅÊàñ5‰ΩçÊ∏ØËÇ°‰ª£Á†ÅÔºâ')
    group.add_argument('-f', '--file', type=str, help='ÂåÖÂê´ËÇ°Á•®‰ª£Á†ÅÁöÑÊñáÊú¨Êñá‰ª∂Ë∑ØÂæÑ')
    
    parser.add_argument('-y', '--years', type=str, required=True,
                       help='Âπ¥‰ªΩËåÉÂõ¥ÔºåÊîØÊåÅÊ†ºÂºè 2020 | 2020-2022 | 2020,2021,2022')
    parser.add_argument('-d', '--dir', type=str, default='annual_reports',
                       help='‰∏ãËΩΩÁõÆÂΩï (ÈªòËÆ§: annual_reports)')
    
    args = parser.parse_args()
    
    # Ëß£ÊûêÂπ¥‰ªΩ
    try:
        years = parse_year_range(args.years)
        print(f"üìÖ ÁõÆÊ†áÂπ¥‰ªΩ: {years}")
    except Exception as e:
        print(f"üîÑ Âπ¥‰ªΩÊ†ºÂºèÈîôËØØ: {e}")
        sys.exit(1)
    
    # Ëé∑ÂèñËÇ°Á•®‰ª£Á†ÅÂàóË°®
    if args.stock:
        stock_codes = [args.stock]
    else:
        stock_codes = load_stock_codes_from_file(args.file)
    
    if not stock_codes:
        print("üîÑ Ê≤°ÊúâÊâæÂà∞ÊúâÊïàÁöÑËÇ°Á•®‰ª£Á†Å")
        sys.exit(1)
    
    # ÂºÄÂßã‰∏ãËΩΩ
    with AnnualReportDownloader(args.dir) as downloader:
        downloader.process_stock_list(stock_codes, years)
        downloader.print_summary()





if __name__ == "__main__":

    main()

